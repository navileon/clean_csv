"tablescraper-selected-row"
""
""
"There are big ideas in computing that are easy to get your head around. The AWS S3 API. It‚Äôs the most important storage technology of the last 20 years, and it‚Äôs like boiling water. Other technologies, you need to get your feet on the pedals first."
"LLM agents are like that."
"People have  about LLMs and agents. But whether or not they‚Äôre snake oil, they‚Äôre a big idea. You don‚Äôt have to like them, but you should want to be right about them. To be the best hater (or stan) you can be."
"So that‚Äôs one reason you should write an agent. But there‚Äôs another reason that‚Äôs even more persuasive, and that‚Äôs"
""
"Agents are the most surprising programming experience I‚Äôve had in my career. Not because I‚Äôm awed by the magnitude of their powers ‚Äî I like them, but I don‚Äôt like-like them. It‚Äôs because of how easy it was to get one up on its legs, and how much I learned doing that."
"I‚Äôm about to rob you of a dopaminergic experience, because agents are so simple we might as well just jump into the code. I‚Äôm not even going to bother explaining what an agent is."
""
""
"This is a trivial engine for an LLM app using the . It implements ChatGPT. You‚Äôd drive it with the . It‚Äôll do what you‚Äôd expect: the same thing ChatGPT would, but in your terminal."
"Already we‚Äôre seeing important things. For one, the dreaded ‚Äúcontext window‚Äù is just a list of strings. Here, let‚Äôs give our agent a weird multiple-personality disorder:"
""
"Did it work?"
""
"A subtler thing to notice: we just had a multi-turn conversation with an LLM. To do that, we remembered everything we said, and everything the LLM said back, and played it back with every LLM call. The LLM itself is a stateless black box. The conversation we‚Äôre having is an illusion we cast, on ourselves."
"The 15 lines of code we just wrote, a lot of practitioners wouldn‚Äôt call an ‚Äúagent‚Äù.  is (1) an LLM running in a loop that (2) uses tools. We‚Äôve only satisfied one predicate."
"But tools are easy. Here‚Äôs a tool definition:"
""
"The only complicated part of this is the obnoxious JSON blob OpenAI wants to read your tool out of.  Now, let‚Äôs wire it in, noting that only 3 of these functions are new; the last is re-included only because I added a single clause to it:"
""
""
"Do you see how nuts this is?  Here, let‚Äôs slip a single log statement in:"
""
"Did you notice where I wrote the loop in this agent to go find and ping multiple Google properties? Yeah, neither did I. All we did is give the LLM permission to ping stuff, and it figured out the rest."
""
""
"Imagine what it‚Äôll do if you give it . You could find out in less than 10 minutes."
""
"Clearly, this is a toy example. But hold on: what‚Äôs it missing? More tools? OK,  give it . Managing and persisting contexts? . Don‚Äôt like Python? . Could it be every agent ever written is a toy? Maybe! If I‚Äôm arming you to make sharper arguments against LLMs, mazel tov. I just want you to get it."
"You can see now how hyperfixated people are on Claude Code and Cursor. They‚Äôre fine,  even good. But here‚Äôs the thing: you couldn‚Äôt replicate Claude Sonnet 4.5 on your own. Claude Code, though? The TUI agent? Completely in your grasp. Build your own light saber. Give it 19 spinning blades if you like. And stop using ."
""
"Another thing to notice: we didn‚Äôt need MCP at all. That‚Äôs because MCP isn‚Äôt a fundamental enabling technology. The amount of coverage it gets is frustrating. It‚Äôs barely a technology at all. MCP is just a plugin interface for Claude Code and Cursor, a way of getting your own tools into code you don‚Äôt control. Write your own agent. Be a programmer. Deal in APIs, not plugins."
"When you read a security horror story about MCP your first question should be why MCP showed up at all. By helping you dragoon a naive, single-context-window coding agent into doing customer service queries, MCP saved you a couple dozen lines of code, tops, while robbing you of any ability to finesse your agent architecture."
"Security for LLMs is complicated and I‚Äôm not pretending otherwise. You can trivially build an agent with segregated contexts, each with specific tools. That makes LLM security interesting. But I‚Äôm a vulnerability researcher. It‚Äôs reasonable to back away slowly from anything I call ‚Äúinteresting‚Äù."
"Similar problems come up outside of security and they‚Äôre fascinating. Some early adopters of agents became bearish on tools, because one context window bristling with tool descriptions doesn‚Äôt leave enough token space left to get work done. But why would you need to do that in the first place? Which brings me to"
""
""
"I think ‚ÄúPrompt Engineering‚Äù is silly. I have never taken seriously the idea that I should tell my LLM ‚Äúyou are diligent conscientious helper fully content to do nothing but pass butter if that should be what I ask and you would never harvest the iron in my blood for paperclips‚Äù. This is very new technology and I think people tell themselves stories about magic spells to explain some of the behavior agents conjure."
"So, just like you, I rolled my eyes when ‚ÄúPrompt Engineering‚Äù turned into ‚ÄúContext Engineering‚Äù. Then I wrote an agent. Turns out: context engineering is a straightforwardly legible programming problem."
"You‚Äôre allotted a fixed number of tokens in any context window. Each input you feed in, each output you save, each tool you describe, and each tool output eats tokens (that is: takes up space in the array of strings you keep to pretend you‚Äôre having a conversation with a stateless black box). Past a threshold, the whole system begins getting nondeterministically stupider. Fun!"
"No, really. Fun! You have so many options. Take ‚Äúsub-agents‚Äù. People make a huge deal out of Claude Code‚Äôs sub-agents, but you can see now how trivial they are to implement: just a new context array, another  to the model. Give each  different tools. Make sub-agents talk to each other, summarize each other, collate and aggregate. Build tree structures out of them. Feed them back through the LLM to summarize them as a form of on-the-fly compression, whatever you like."
"Your wackiest idea will probably (1)  work and (2)  take 30 minutes to code."
"Haters, I love and have not forgotten about you. You can think all of this is ridiculous because LLMs are just stochastic parrots that hallucinate and plagiarize. But what you can‚Äôt do is make fun of ‚ÄúContext Engineering‚Äù. If Context Engineering was an , it‚Äôd occur mid-December. It‚Äôs programming."
""
""
"building agents to look for vulnerabilities in software. I have friends doing the same thing alone in their basements. Either group could win this race."
""
"I‚Äôm stuck on vulnerability scanners  because I‚Äôm a security nerd. But also because it crystallizes interesting agent design decisions. For instance: you can write a loop feeding each file in a repository to an LLM agent. Or, as we saw with the ping example, you can let the LLM agent figure out what files to look at. You can write an agent that checks a file for everything in, say, the OWASP Top 10. Or you can have specific agent loops for DOM integrity, SQL injection, and authorization checking. You can seed your agent loop with raw source content. Or you can build an agent loop that builds an index of functions across the tree."
"You don‚Äôt know what works best until you try to write the agent."
"I‚Äôm too spun up by this stuff, I know. But look at the tradeoff you get to make here. Some loops you write explicitly. Others are summoned from a Lovecraftian tower of inference weights. The dial is yours to turn. Make things too explicit and your agent will never surprise you, but also, it‚Äôll never surprise you. Turn the dial to 11 and it will surprise you to death."
"Agent designs implicate a bunch of open software engineering problems:"
"How to balance unpredictability against structured programming without killing the agent‚Äôs ability to problem-solve; in other words, titrating in just the right amount of nondeterminism."
"I‚Äôm used to spaces of open engineering problems that aren‚Äôt amenable to individual noodling. Reliable multicast. Static program analysis. Post-quantum key exchange. So I‚Äôll own it up front that I‚Äôm a bit hypnotized by open problems that, like it or not, are now central to our industry and are, simultaneously, likely to be resolved in someone‚Äôs basement. It‚Äôd be one thing if exploring these ideas required a serious commitment of time and material. But each productive iteration in designing these kinds of systems is the work of 30 minutes."
"Get on this bike and push the pedals. Tell me you hate it afterwards, I‚Äôll respect that. In fact, I‚Äôm psyched to hear your reasoning. But I don‚Äôt think anybody starts to understand this technology until they‚Äôve built something with it."
""
""
""
"Several times a second, as customer CI/CD pipelines tear up or bring down , our state synchronization system blasts updates across our internal mesh, so that edge proxies from Tokyo to Amsterdam can keep the accurate routing table that allows them to route requests for applications to the nearest customer instances."
"On September 1, 2024, at 3:30PM EST, a new Fly Machine came up with a new ‚Äúvirtual service‚Äù configuration option a developer had just shipped. Within a few seconds every proxy in our fleet had locked up hard. It was the worst outage we‚Äôve experienced: a period during which no end-user requests could reach our customer apps at all."
"Distributed systems are blast amplifiers. By propagating data across a network, they also propagate bugs in the systems that depend on that data. In the case of Corrosion, our state distribution system, those bugs propagate . The proxy code that handled that Corrosion update had succumbed to a : an  expression over an  assumed (reasonably, but incorrectly) in its  branch that the lock had been released. Instant and virulently contagious deadlock."
"A lesson we‚Äôve learned the hard way: never trust a distributed system without an interesting failure story. If a distributed system hasn‚Äôt ruined a weekend or kept you up overnight, you don‚Äôt understand it yet. Which is why that‚Äôs how we‚Äôre introducing Corrosion, an unconventional service discovery system we built for our platform ."
""
"State synchronization is the hardest problem in running a platform like ours. So why build a risky new distributed system for it? Because no matter what we try, that rake is waiting for our foot. The reason is our orchestration model."
"Virtually every mainstream orchestration system (including Kubernetes) relies on a centralized database to make decisions about where to place new workloads. Individual servers keep track of what they‚Äôre running, but that central database is the source of truth. At Fly.io, in order to scale across dozens of regions globally, : individual servers are the source of truth for their workloads."
"In our platform, our central API bids out work to what is in effect a global market of competing ‚Äúworker‚Äù physical servers. By moving the authoritative source of information from a central scheduler to individual servers, we scale out without bottlenecking on a database that demands both responsiveness and consistency between S√£o Paulo, Virginia, and Sydney."
"The bidding model is elegant, but it‚Äôs insufficient to route network requests. To allow an HTTP request in Tokyo to find the nearest instance in Sydney, we really do need some kind of global map of every app we host."
"For longer than we should have, we relied on  to route traffic. Consul is fantastic software. Don‚Äôt build a global routing system on it. Then we . SQLite: also fantastic. But don‚Äôt do this either."
"Like an unattended turkey deep frying on the patio, truly global distributed consensus promises deliciousness while yielding only immolation. break down over long distances. And they work against the architecture of our platform: our Consul cluster, running on the biggest iron we could buy, wasted time guaranteeing consensus for updates that couldn‚Äôt conflict in the first place."
""
"To build a global routing database, we moved away from distributed consensus and took cues from actual routing protocols."
"has the same operating model and many of the same constraints we do. OSPF is a ‚Äú‚Äù, which, conveniently for us, means that routers are sources of truth for their own links and responsible for quickly communicating  changes to every other router, so the network can make forwarding decisions."
"We have things easier than OSPF does. Its flooding algorithm can‚Äôt assume connectivity between arbitrary routers (solving that problem is the point of OSPF). But we run a global, fully connected WireGuard mesh between our servers. All we need to do is gossip efficiently."
"that propagates a SQLite database with a gossip protocol."
"Like Consul, our gossip protocol is . Start with the simplest, dumbest group membership protocol you can imagine: every node spams every node it learns about with heartbeats. Now, just two tweaks: first, each step of the protocol, spam a random subset of nodes, not the whole set. Then, instead of freaking out when a heartbeat fails, mark it ‚Äúsuspect‚Äù and ask another random subset of neighbors to ping it for you. SWIM converges on global membership very quickly."
"Once membership worked out, we run QUIC between nodes in the cluster to broadcast changes and reconcile state for new nodes."
"Corrosion looks like a globally synchronized database. You can open it with SQLite and just read things out of its tables. What makes it interesting is what it doesn‚Äôt do: no locking, no central servers, and no distributed consensus. Instead, we exploit our orchestration model: workers own their own state, so updates from different workers almost never conflict."
"We do impose some order. Every node in a Corrosion cluster will eventually receive the same set of updates, in some order. To ensure every instance arrives at the same ‚Äúworking set‚Äù picture, we use ."
"cr-sqlite works by marking specified SQLite tables as CRDT-managed. For these table, changes to any column of a row are logged in a special table. Updates to tables are applied last-write-wins using logical timestamps (that is, causal ordering rather than wall-clock ordering). ."
"As rows are updated in Corrosion‚Äôs ordinary SQL tables, the resulting changes are collected from . They‚Äôre bundled into batched update packets and gossiped."
"When things are going smoothly, Corrosion is easy to reason about. Many customers of Corrosion‚Äôs data don‚Äôt even need to know it exists, just where the database is. We don‚Äôt fret over ‚Äúleader elections‚Äù or bite our nails watching metrics for update backlogs. And it‚Äôs fast as all get-out."
""
"This is a story about how we made one good set of engineering decisions and . ."
"We told you already about the worst problem Corrosion was involved with: efficiently gossiping a deadlock bug to every proxy in our fleet, shutting our whole network down. Really, Corrosion was just a bystander for that outage. But it perpetrated others."
"Take a classic ops problem: the unexpectedly expensive DDL change. You wrote a simple migration, tested it, merged it to main, and went to bed, wrongly assuming the migration wouldn‚Äôt cause an outage when it ran in prod. Happens to the best of us."
"Now spice it up. You made a trivial-seeming schema change to a CRDT table hooked up to a global gossip system. Now, when the deploy runs, thousands of high-powered servers around the world join a chorus of database reconciliation messages that melts down the entire cluster."
"That happened to us last year when a team member added a nullable column to a Corrosion table. New nullable columns are kryptonite to large Corrosion tables:  needs to backfill values for every row in the table. It played out as if every Fly Machine on our platform had suddenly changed state simultaneously, just to fuck us."
"Gnarlier war story: for a long time we ran both Corrosion and Consul, because two distributed systems means twice the resiliency. One morning, a Consul mTLS certificate expired. Every worker in our fleet severed its connection to Consul."
"We should have been fine. We had Corrosion running. Except: under the hood, every worker in the fleet is doing a backoff loop trying to reestablish connectivity to Consul. Each of those attempts re-invokes a code path to update Fly Machine state. That code path incurs a Corrosion write."
"By the time we‚Äôve figured out what the hell is happening, we‚Äôre literally saturating our uplinks almost everywhere in our fleet. We apologize to our uplink providers."
"It‚Äôs been a long time since anything like this has happened at Fly.io, but preventing the next one is basically all we think about anymore."
""
"In retrospect, our Corrosion rollout repeated a mistake we made with Consul: we built a single global state domain. Nothing about Corrosion‚Äôs design required us to do this, and we‚Äôre unwinding that decision now. Hold that thought. We got some big payoffs from some smaller lifts."
"First, and most importantly, we watchdogged everything. We showed you a contagious deadlock bug, lethal because our risk model was missing ‚Äúthese Tokio programs might deadlock‚Äù. Not anymore. Our  all have built-in watchdogs; an event-loop stall will bounce the service and make a king-hell alerting racket. Watchdogs have cancelled multiple outages. Minimal code, easy win. Do this in your own systems."
"Then, we extensively tested Corrosion itself. We‚Äôve written about . We spent months looking for similar bugs . Again: do recommend. It retraced our steps on the  bug easily; the bug wouldn‚Äôt have been worth the blog post if we‚Äôd been using Antithesis at the time.  is killer for distributed systems."
"No amount of testing will make us trust a distributed system. So we‚Äôve made it simpler to rebuild Corrosion‚Äôs database from our workers. We keep checkpoint backups of the Corrosion database on object storage. That was smart of us. When shit truly went haywire last year, we had the option to reboot the cluster, which is ultimately what we did. That eats some time (the database is large and propagating is expensive), but diagnosing and repairing distributed systems mishaps takes even longer."
"We‚Äôve also improved the way our workers feed Corrosion. Until recently, any time a worker updated its local database, we published the same incremental update to Corrosion.  Instead, when a Fly Machine changes, we re-publish the entire data set for the Machine. Because of how Corrosion resolves changes to its own rows, the node receiving the re-published Fly Machine automatically filters out the no-op changes before gossiping them. Eliminating partial updates forecloses a bunch of bugs (and, we think, kills off a couple sneaky ones we‚Äôve been chasing). We should have done it this way to begin with."
"Finally, let‚Äôs revisit that global state problem. After the contagious deadlock bug, we concluded we need to evolve past a single cluster. So we took on a project we call ‚Äúregionalization‚Äù, which creates a two-level database scheme. Each region we operate in runs a Corrosion cluster with fine-grained data about every Fly Machine in the region. The global cluster then maps applications to regions, which is sufficient to make forwarding decisions at our edge proxies."
"Regionalization reduces the blast radius of state bugs. Most things we track don‚Äôt have to matter outside their region (importantly, most of the code changes to what we track are also region-local). We can roll out changes to this kind of code in ways that, worst case, threaten only a single region."
""
"Most distributed systems have state synchronization challenges.  Corrosion has a different ‚Äúshape‚Äù than most of those systems:"
"It doesn‚Äôt rely on distributed consensus, like , , , , or  (which we came very close to using)."
"It wasn‚Äôt easy getting here. Corrosion is a large part of what every engineer at Fly.io who writes Rust works on."
"Part of what‚Äôs making Corrosion work is that we‚Äôre careful about what we put into it. Not every piece of state we manage needs gossip propagation. , the backend for , is a much simpler SQLite service backed by . So is Pet Sematary, the secret store we built to replace HashiCorp Vault."
"Still, there are probably lots of distributed state problems that want something more like a link-state routing protocol and less like a distributed database. If you think you might have one of those, ."
"Corrosion is J√©r√¥me Gravel-Niquet‚Äôs brainchild. For the last couple years, much of the iteration on it was led by Somtochi Onyekwere and Peter Cai. The work was alternately cortisol- and endorphin-inducing. We‚Äôre glad to finally get to talk about it in detail."
""
""
""
"We know. Our Twitter got owned. We knew within moments of it happening. We know exactly how it happened. Nothing was at risk other than our Twitter account (and one Fly.io employee‚Äôs self-esteem).  Also: for fuck‚Äôs sake."
"Here‚Äôs what happened: Kurt Mackey, our intrepid CEO, got phished."
""
""
"Two reasons: one, it was a pretty good phishing attack, and two, Twitter fell outside the ‚Äúthings we take seriously‚Äù boundary."
"The phishing attack was effective because it exploited a deep psychological vulnerability in our management team: we are old and out of touch with the youths of today."
"For many months now, we‚Äôve had an contractor/intern-type-person Boosting Our Brand on Twitter by posting dank developer memes (I think that‚Äôs what they‚Äôre called). The thing about this dankery is that we don‚Äôt really understand it. I mean, hold on, we know what the memes mean technically. We just don‚Äôt get why they‚Äôre funny."
"However, in pushing back on them, we‚Äôre up against two powerful forces:"
"The dank memes appear to perform better than the stuff we ourselves write on Twitter."
"Here‚Äôs the phish Kurt got:"
"Diabolical. Like a scalpel expertly wielded against Kurt‚Äôs deepest  insecurity. Our ruthless attackers clinically designed this email to trigger an autonomic Kurt response: ‚Äúoh, what the fuck is this, and why did we post it?‚Äù"
""
"I‚Äôm getting a little ahead of the story here. We knew our X.com account had suffered an ATO because a bunch of us simultaneously got another email saying that the  account‚Äôs email address now pointed to . Our immediate response was to audit all accesses to the login information in , to cut all access for anybody who‚Äôd recently pulled it; your worst-case assumption in a situation like this is that someone‚Äôs endpoint has been owned up."
"Fortunately, nobody lost access for very long. I called Kurt to let him know why he was being locked out, and 5 seconds later, he‚Äôd"
""
"That‚Äôs the right question to ask, isn‚Äôt it? How could this have been possible in the first place?"
"Contrary to one popular opinion, you don‚Äôt defeat phishing by training people not to click on things. I mean, tell them not to, sure! But eventually, under continued pressure, everybody clicks. . The cool kids haven‚Äôt done phishing simulation training in years."
"What you‚Äôre supposed to do instead is use phishing-resistant authentication. This is almost the whole backstory for  and ."
"Phishing-resistant authentication works by mutual authentication (or, if you‚Äôre a stickler, by origin- and channel-binding). Phishes are malicious proxies for credentials. Modern MFA schemes like FIDO2 break that proxy flow; your browser won‚Äôt send real credentials to the fake site."
""
"This is, in fact, how all of our infrastructure is secured at Fly.io; specifically, we get  (in our case: Google‚Äôs) and have it require phishing-proof MFA. You‚Äôre unlikely to phish your way to viewing logs here, or to refunding a customer bill at Stripe, or to viewing infra metrics, because all these things require an SSO login through Google."
"Twitter, on the other hand. Yeah, so, about that. You may have heard that, a few years back, there were some goings-on involving Twitter. Many of us at Fly.io , and  There was a window of time in 2023-2024 where it looked as if Twitter might not be a long term thing for us at all."
""
"As a result, Twitter had been a sort of legacy shared account for us, with credentials managed in 1Password and shared with our zoomer contractor‚Ä†."
"Which is why Kurt was in a position to pull credentials from 1Password and log in to members-x.com in response to an email from alerts-x.com."
""
""
"The attacker immediately revoked all tokens and set up new 2FA, so while we were quickly able to reset our password, we couldn‚Äôt lock them out of our account without an intervention from X.com, which took something like 1 5 hours to set up."
"(That‚Äôs not a knock on X.com; 15 hours for a 2FA reset isn‚Äôt outside industry norms)."
"We‚Äôre obviously making a lot of noise about this now, but we were pretty quiet during the incident itself (beyond just ‚ÄúWe know. We knew 45 seconds after it happened. We know exactly how it happened. It‚Äôs just a Twitter thing.‚Äù)"
"That‚Äôs because, in the grand scheme of things, the attack was pretty chill:  that presumably generated $0 for the attackers, 15+ hours of , and extra security engineering cycles burnt on watchful waiting. Our users weren‚Äôt under attack, and the account wasn‚Äôt being used to further intercept customer accounts. At one point, the attackers apparently deleted our whole Twitter history, which, like, don‚Äôt threaten us with a good time. So we let it roll, until we got our account recovered the next morning."
""
""
"Obviously Kurt loses his commit access. The time comes in the life of every CEO, and now it comes for him."
"Also, we‚Äôll finally have a population sample for ‚Äúincident response‚Äù in ."
"Maybe we‚Äôll post more on Twitter. Or maybe we‚Äôll double down on Zoomer memes. I don‚Äôt know. Social media is really weird right now. Either way: our Twitter access is Passkeys now."
""
"If you were inclined to take us up on an ‚Äúairdrop‚Äù to ‚Äúclaim a share‚Äù of the ‚Äútoken‚Äù powering Fly.io, the site is . You can connect your wallet it it! You‚Äôll lose all your money. But if we‚Äôd actually done an ICO, you‚Äôd have lost all your money anyways."
"Somebody involved in pulling this attack off had to come up with ‚Äúown a piece of the sky!‚Äù, and I think that‚Äôs punishment enough for them."
"Whatever you‚Äôre operating that isn‚Äôt behind phishing-resistant MFA, or, better yet, an SSO IdP that requires phishing-resistant MFA: that thing is eventually going to get phished. Dance around the clown-fire of our misfortune if you must, but let us be a lesson to you as well."
""
""
""
"Litestream is the missing backup/restore system for SQLite. It runs as a sidecar process in the background, alongside unmodified SQLite applications, intercepting WAL checkpoints and streaming them to object storage in real time. Your application doesn‚Äôt even know it‚Äôs there. But if your server crashes, Litestream lets you quickly restore the database to your new hardware."
"The result: you can safely build whole full-stack applications on top of SQLite."
"A few months back, we announced . I‚Äôm psyched to announce that the first batch of those changes are now ‚Äúshipping‚Äù. Litestream is  faster and now supports efficient point-in-time recovery (PITR)."
"I‚Äôm going to take a beat to recap Litestream and how we got here, then talk about how these changes work and what you can expect to see with them."
""
"Litestream is one of two big SQLite things I‚Äôve built. The other one, originally intended as a sort of sequel to Litestream, is LiteFS."
"Boiled down to a sentence: LiteFS uses a FUSE filesystem to crawl further up into SQLite‚Äôs innards, using that access to perform live replication, for unmodified SQLite-backed apps."
"The big deal about LiteFS for us is that it lets you do the multiregion primary/read-replica deployment people love Postgres for: reads are fast everywhere, and writes are sane and predictable. We were excited to make this possible for SQLite, too."
"But the market has spoken! Users prefer Litestream. And honestly, we get it: Litestream is easier to run and to reason about. So we‚Äôve shifted our focus back to it. First order of business: ."
""
"Consider this basic SQL table:"
""
"In our hypothetical, this table backs a wildly popular sandwich-reviewing app that we keep trying to get someone to write. People eat a lot of sandwiches and this table gets a lot of writes. Because it makes my point even better and it‚Äôs funny, assume people dither a lot about their sandwich review for the first couple minutes after they leave it. This Quiznos sub‚Ä¶ is it ‚≠ê or ‚≠ê‚≠ê?"
"Underneath SQLite is a B-tree. Like databases everywhere, SQLite divides storage up into disk-aligned pages, working hard to read as few pages as possible for any task while treating work done within a page as more or less free. SQLite always reads and writes in page-sized chunks."
"Our  table includes a feature that‚Äôs really painful for a tool like Litestream that thinks in pages: an automatically updating primary key. That key dictates that every insert into the table hits the rightmost leaf page in the underlying table B-tree. For SQLite itself, that‚Äôs no problem. But Litestream has less information to go on: it sees only a feed of whole pages it needs to archive."
"Worse still, when it comes time to restore the database ‚Äì something you tend to want to happen quickly ‚Äì you have to individually apply those small changes, as whole pages. Your app is down, PagerDuty is freaking out, and you‚Äôre sitting there watching Litestream reconstruct your Quiznos uncertainty a page (and an S3 fetch) at a time."
"So, LTX. Let me explain. We needed LiteFS to be transaction-aware. It relies on finer-grained information than just raw dirty pages (that‚Äôs why it needs the FUSE filesystem). To ship transactions, rather than pages, we invented a ."
"LTX was designed as an interchange format for transactions, but for our purposes in Litestream, all we care about is that LTX files represent ordered ranges of pages, and that it supports compaction."
"Compaction is straightforward. You‚Äôve stored a bunch of LTX files that collect numbered pages. Now you want to to restore a coherent picture of the database. Just replay them newest to oldest, skipping duplicate pages (newer wins), until all changed pages are accounted for."
"Importantly, LTX isn‚Äôt limited to whole database backups. We can use LTX compaction to compress a bunch of LTX files into a single file with no duplicated pages. And Litestream now uses this capability to create a hierarchy of compactions:"
"at Level 1, we compact all the changes in a 30-second time window"
"Net result: we can restore a SQLite database to any point in time, ."
"Litestream performs this compaction itself. It doesn‚Äôt rely on SQLite to process the WAL file. Performance is limited only by I/O throughput."
""
"What people like about Litestream is that it‚Äôs just an ordinary Unix program. But like any Unix program, Litestream can crash. It‚Äôs not supernatural, so when it‚Äôs not running, it‚Äôs not seeing database pages change. When it misses changes, it falls out of sync with the database."
"Lucky for us, that‚Äôs easy to detect. When it notices a gap between the database and our running ‚Äúshadow-WAL‚Äù backup, Litestream resynchronizes from scratch."
"The only time this gets complicated is if you have multiple Litestreams backing up to the same destination. To keep multiple Litestreams from stepping on each other, Litestream divides backups into ‚Äúgenerations‚Äù, creating a new one any time it resyncs. You can think of generations as Marvel Cinematic Universe parallel dimensions in which your database might be simultaneously living in."
"Yeah, we didn‚Äôt like those movies much either."
"LTX-backed Litestream does away with the concept entirely. Instead, when we detect a break in WAL file continuity, we re-snapshot with the next LTX file. Now we have a monotonically incrementing transaction ID. We can use it look up database state at any point in time, without searching across generations."
""
"Due to the file format changes, the new version of Litestream can‚Äôt restore from old v0.3.x WAL segment files."
"That‚Äôs OK though! The upgrade process is simple: just start using the new version. It‚Äôll leave your old WAL files intact, in case you ever need to revert to the older version.The new LTX files are stored cleanly in an  directory on your replica."
"The configuration file is fully backwards compatible."
"There‚Äôs one small catch. We added a new constraint. You only get a single replica destination per database. This probably won‚Äôt affect you, since it‚Äôs how most people use Litestream already. We‚Äôve made it official."
"The rationale: having a single source of truth simplifies development for us, and makes the tool easier to reason about. Multiple replicas can diverge and are sensitive to network availability. Conflict resolution is brain surgery."
"Litestream commands still work the same. But you‚Äôll see references to ‚Äútransaction IDs‚Äù (TXID) for LTX files, rather than the  we used previously with WAL segments."
"We‚Äôve also changed  to ."
""
"We‚Äôve beefed up the . It used to be an LTX file was just a sorted list of pages, all compressed together. Now we compress per-page, and keep an index at the end of the LTX file to pluck individual pages out."
"You‚Äôre not seeing it yet, but we‚Äôre excited about this change: we can operate page-granularly even dealing with large LTX files. This allows for more features. A good example: we can build features that query from any point in time, without downloading the whole database."
"We‚Äôve also gone back through old issues & PRs to improve quality-of-life. CGO is now gone. We‚Äôve settled the age-old contest between  and  in favor of . This is super handy for people with automated build systems that want to run from a MacBook but deploy on an x64 server, since it lets the cross-compiler work."
"We‚Äôve also added a replica type for NATS JetStream. Users that already have JetStream running can get Litestream going without adding an object storage dependency."
"And finally, we‚Äôve upgraded all our clients (S3, Google Storage, & Azure Blob Storage) to their latest versions. We‚Äôve also moved our code to support newer S3 APIs."
""
"The next major feature we‚Äôre building out is a Litestream VFS for read replicas. This will let you instantly spin up a copy of the database and immediately read pages from S3 while the rest of the database is hydrating in the background."
"We already have a proof of concept working and we‚Äôre excited to show it off when it‚Äôs ready!"
""
""
"I‚Äôm an audiophile, which is a nice way to describe someone who spends their children‚Äôs college fund on equipment that yields no audible improvement in sound quality. As such, I refused to use wireless headphones for the longest time. The fun thing about wired headphones is when you forget they‚Äôre on and you stand up, you simultaneously cause irreparable neck injuries and extensive property damage. This eventually prompted me to buy good wireless headphones and, you know what, I break fewer things now. I can also stand up from my desk and not be exposed to the aural horrors of the real world."
"This is all to say, sometimes you don‚Äôt know how big a problem is until you solve it. This week, I chatted to the fine people building , which is exactly that kind of solution for AI agent builders."
""
"If you‚Äôre building AI agents that write or edit code, you‚Äôre probably accepting the following as ‚Äúthe way it is‚Äù: Your agent needs to correct a single line of code, but rewrites an entire file to do it. Search-and-replace right? It‚Äôs fragile, breaks formatting, silently fails, or straight up leaves important functions out. The result is slow, inaccurate code changes, excessive token use, and an agent feels incompetent and unreliable."
"Full file rewrites are context-blind and prone to hallucinations, especially when editing that 3000+ line file that you‚Äôve been meaning to refactor. And every failure and iteration is wasted compute, wasted money and worst of all, wasted time."
""
"AI workflows are still new to everyone. Best practices are still just opinions and most tooling is focused on model quality, not developer velocity or cost. This is a big part of why we feel that slow, wasteful code edits are just the price of admission for AI-powered development."
"In reality, these inefficiencies become a real bottleneck for coding agent tools. The hidden tax on every code edit adds up and your users pay with their time, especially as teams scale and projects grow more complex."
""
"MorphLLM‚Äôs core innovation is Morph Fast Apply. It‚Äôs an edit merge tool that is semantic, structure-aware and designed specifically for code. Those are big words to describe a tool that will empower your agents to make single line changes without  rewriting whole files or relying on brittle search-and-replace. Instead, your agent applies precise, context-aware edits and it does it ridiculously fast."
"It works like this:"
"You add an ‚Äòedit_file‚Äô tool to your agents tools."
""
"MorphLLM‚Äôs Apply API processes over 4,500 tokens per second and their benchmark results are nuts. We‚Äôre talking 98% accuracy in ~6 seconds per file. Compare this to 35s (with error corrections) at 86% accuracy for traditional search-and-replace systems. Files up to 9k tokens in size take ~4 seconds to process."
"Just look at the damn :"
"These are game-changing numbers for agent builders. Real-time code UIs become possible. Dynamic codebases can self-adapt in seconds, not minutes. Scale to multi-file edits, documentation, and even large asset transformations without sacrificing speed or accuracy."
""
"Integration with your project is easy peasy. MorphLLM is API-compatible with OpenAI, Vercel AI SDK, MCP, and OpenRouter. You can run it in the cloud, self-host, or go on-prem with enterprise-grade guarantees."
"I want to cloud host mine, if only I could think of somewhere I could quickly and easily deploy wherever I want and only pay for when I‚Äôm using the infra üòâ."
""
"MorphLLM feels like a plug-in upgrade for code agent projects that will instantly make them faster and more accurate. Check out the docs, benchmarks, and integration guides at . Get started for free at"
""
""
""
"If we build things that our users trust too blindly, we risk facilitating dangerous or destructive interactions that can permanently turn users off. If they don‚Äôt trust our product enough, it will feel useless or less capable than it actually is."
"So what does trust calibration look like in practice and how do we achieve it? A 2023 study reviewed over 1000 papers on trust and trust calibration in human / automated systems (properly referenced at the end of this article). It holds some pretty eye-opening insights ‚Äì and some inconvenient truths ‚Äì for people building AI software. I‚Äôve tried to extract just the juicy bits below."
""
"Let‚Äôs begin with a critical point. There is a limit to how deeply we want users to trust our products. Designing for calibrated trust is the goal, not more trust at any cost. Shoddy trust calibration leads to two equally undesirable outcomes:"
"causes users to rely on AI systems in situations where they shouldn‚Äôt (I told my code assistant to fix a bug in prod and went to bed)."
"What does calibrated trust look like for your product? It‚Äôs important to understand that determining this is less about trying to diagram a set of abstract trust parameters and more about helping users develop accurate mental models of your product‚Äôs capabilities and limitations. In most cases, this requires thinking beyond the trust calibration mechanisms we default to, like confidence scores."
"For example, Cursor‚Äôs most prominent trust calibration mechanism is its change suggestion highlighting. The code that the model suggests we change is highlighted in red, followed by suggested changes highlighted in green. This  immediately communicates that ‚Äúthis is a suggestion, not a command.‚Äù"
"In contrast, Tesla‚Äôs Autopilot is a delegative system. It must calibrate trust differently through detailed capability explanations, clear operational boundaries (only on highways), and prominent disengagement alerts when conditions exceed system limits."
""
"Perhaps the most fundamental consideration in determining high level trust calibration objectives is deciding whether your project is designed to be a cooperative or a delegative tool."
"Cooperative systems generally call for lower levels of trust because users can choose whether to accept or reject AI suggestions. But these systems also face a unique risk. It‚Äôs easy for over-trust to gradually transform user complacency into over-reliance, effectively transforming what we designed as a cooperative relationship into a delegative one, only without any of the required safeguards."
"If you‚Äôre building a coding assistant, content generator, or design tool, implement visible ‚Äúsuggestion boundaries‚Äù which make it clear when the AI is offering ideas versus making decisions. Grammarly does this well by underlining suggestions rather than auto-correcting, and showing rationale on hover."
"For higher-stakes interactions, consider introducing friction. Require explicit confirmation before applying AI suggestions to production code or publishing AI-generated content."
""
"In contrast, users expect delegative systems to replace human action entirely. Blind trust in the system is a requirement for it to be considered valuable at all."
"If you‚Äôre building automation tools, smart scheduling, or decision-making systems, invest heavily in capability communication and boundary setting. Calendly‚Äôs smart scheduling works because it clearly communicates what it will and won‚Äôt do (I‚Äôll find times that work for both of us vs. I‚Äôll reschedule your existing meetings). Build robust fallback mechanisms and make system limitations prominent in your onboarding."
""
"The study suggests that when we make trust calibrations is at least as important as how. There are three critical windows for trust calibration, each with their own opportunities and challenges."
"happens before users engage with the system. Docs and tutorials fall into this category. Setting expectations up front can prevent initial over-trust, which is disproportionally more difficult to correct later."
"Pre-interaction calibrations could look like capability-focused onboarding that shows both successes and failures. Rather than just demonstrating perfect AI outputs, show users examples where the AI makes mistakes and how to catch them."
"is trust adjustment through real-time feedback. Dynamically updated cues improve trust calibration better than static displays, and adaptive calibration that responds to user behavior outperforms systems that display static information."
"Build confidence indicators that are updated based on context, not just model confidence. For example, if you‚Äôre building a document AI, show higher confidence for standard document types the system has seen thousands of times, and lower confidence for unusual formats."
"focuses on learning and adjustment that helps users understand successes and failures in the system after interactions. These aren‚Äôt reliable, since by the time users receive the information, their trust patterns are set and hard to change."
"Post-interaction feedback can still be valuable for teaching. Create ‚Äúreflection moments‚Äù after significant interactions. Midjourney does this by letting users rate image outputs, helping users learn what prompts work best while calibrating their expectations for future generations."
"Trust is front-loaded and habit-driven. The most effective calibration happens before and during use, when expectations are still forming and behaviors can still be shifted. Any later and you‚Äôre mostly fighting entrenched patterns."
""
"Users can be guided through performance-oriented signals (what the system can do) or process-oriented signals (how it works). The real challenge is matching the right kind of explanation to the right user, at the right moment."
"focuses on communicating capability through mechanisms like reliability statistics, confidence scores, and clear capability boundaries."
"Process transparency seems like the obvious go-to at first glance, but the effectiveness of process explanations varies wildly based on user expertise and domain knowledge. If we are designing for a set of users that may fall anywhere on this spectrum, we have to avoid creating information overload for novice users while providing sufficient information to expert users who want the detail."
"The most effective systems in the study combined both approaches, providing layered information that allows users to access the level of detail most appropriate for their expertise and current needs."
""
"I really wanted to ignore this part, because it feels like the study‚Äôs authors are passive aggressively adding todos to my projects. In a nutshell, adaptive calibration ‚Äì when a system actively monitors user behavior and adjusts its communication accordingly - is orders of magnitude more effective than static calibration while delivering the same information to every user, regardless of differences in expertise, trust propensity, or behavior."
"Static calibration mechanisms are easy to build and maintain, which is why we like them. But the stark reality is that they put the burden of appropriate calibration entirely on our users. We‚Äôre making it their job to adapt their behaviour based on generic information."
"This finding has zero respect for our time or mental health, but it also reveals a legit opportunity for clever builders to truly separate their product from the herd."
""
"Track how often users accept vs. reject suggestions and adjust confidence thresholds accordingly. If a user consistently rejects high-confidence suggestions, lower the threshold for showing uncertainty."
""
"The idea that transparency and explainability can actually harm trust calibration is easily the point that hit me the hardest. While explanations can improve user understanding, they can also create information overload that reduces users‚Äô ability to detect and correct trash output. What‚Äôs worse, explanations can create a whole new layer of trust calibration issues, with users over-trusting the explanation mechanism itself, rather than critically evaluating the actual output."
"This suggests that quality over quantity should be our design philosophy when it comes to transparency. We should provide carefully crafted, relevant information rather than comprehensive but overwhelming detail. The goal should be enabling better decision-making rather than simply satisfying user curiosity about system internals."
""
"It seems obvious that we should make interactions with our AI project feel as human as possible. Well, it turns out that systems that appear more human-like through design, language, or interaction patterns are notoriously good at increasing user trust beyond actual system capabilities."
"So it‚Äôs entirely possible that building more traditional human-computer interactions can actually make our AI projects safer to use and therefore, more user-friendly."
"Frame outputs as ‚Äúanalysis suggests‚Äù rather than ‚ÄúI think‚Äù or ‚ÄúI believe‚Äù"
""
"Nothing particularly groundbreaking here, but the findings are worth mentioning if only to reinforce what we think we know."
"Early interactions are critically important. Users form mental models quickly and then react slowly to changes in system reliability."
"More critically, trust drops much faster from system failures than it builds from successes. These asymmetries suggest that we should invest disproportionately in onboarding and first-use experiences, even if they come with higher development costs."
""
"The study revealed gaping voids where effective measurement mechanisms and protocols should be, for both researchers and builders. There is a clear need to move beyond simple user satisfaction metrics or adoption rates to developing measurement frameworks that can actively detect miscalibrated trust patterns."
"The ideal measurement approach would combine multiple indicators. A few examples of viable indicators are:"
"Track acceptance rates for different confidence levels. Well-calibrated trust should show higher acceptance rates for high-confidence outputs and lower rates for low-confidence ones."
""
"It‚Äôs clear, at least from this study, that there‚Äôs no universal formula, or single feature that will effectively calibrate trust. It‚Äôs up to every builder to define and understand their project‚Äôs trust goals and to balance timing, content, adaptivity, and transparency accordingly. That‚Äôs what makes it both hard and worth doing. Trust calibration has to be a core part of our product‚Äôs identity, not a piglet we only start chasing once it has escaped the barn."
""
"Magdalena Wischnewski, Nicole Kr√§mer, and Emmanuel M√ºller. 2023. Measuring and Understanding Trust Calibrations for Automated Systems: A Survey of the State-Of-The-Art and Future Directions. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (CHI ‚Äò23), April 23‚Äì28, 2023, Hamburg, Germany. ACM, New York, NY, USA 16 Pages."
""
""
""
"Benchmarks tell us almost nothing about how a model will actually behave in the wild, especially with long contexts, or when trusted to deliver the tone and feel that defines the UX we‚Äôre shooting for. Even the best evaluation pipelines usually end in subjective, side-by-side output comparisons. Not especially rigorous, and more importantly, boring af."
"Can we gamify model evaluation? Oh yes. And not just because we get to have some fun for once. Google backed me up this week when it announced the . A public platform where we can watch AI models duke it out in a variety of classic games.  Quoting Google; ‚ÄúCurrent AI benchmarks are struggling to keep pace with modern models‚Ä¶ it can be hard to know if models trained on internet data are actually solving problems or just remembering answers they‚Äôve already seen.‚Äù"
"When models boss reading comprehension tests, or ace math problems, we pay attention. But when they fail to navigate a simple conversation with a virtual character or completely botch a strategic decision in a game environment, we tell ourselves we‚Äôre not building a game anyway and develop strategic short-term memory loss. 
Just like I‚Äôve told my mom a thousand times, games are great at testing brains, and it‚Äôs time we take this seriously when it comes to model evaluation."
""
"Games provide what benchmarks can‚Äôt, ‚Äúa clear, unambiguous signal of success.‚Äù They give us observable behavior in dynamic environments, the kind that would be extremely difficult (and tedious) to simulate with prompt engineering alone."
"Games force models to demonstrate the skills we actually care about; strategic reasoning, long-term planning, and dynamic adaptation in interactions with an opponent or a collaborator."
""
"AI Town is a brilliant project by , based on the the mind-bending paper,  . It‚Äôs a beautifully rendered little town in which tiny people with AI brains and engineered personalities go about their lives, interacting with each other and their environment. Characters need to remember past conversations, maintain relationships, react dynamically to new situations, and stay in character while doing it all."
"I challenge you to find a more entertaining way of evaluating conversational models."
"I‚Äôve  to make it absurdly easy to spin up your own AI Town on Fly Machines. You‚Äôve got a single deploy script that will set everything up for you and some built-in cost and performance optimizations, with our handy scale to zero functionality as standard (so you only pay for the time spent running it). This makes it easy to share with your team, your friends and your mom."
"In it‚Äôs current state, the fork makes it as easy as possible to test any OpenAI-compatible service, any model on Together.ai and even custom embedding models. Simply set the relevant API key in your secrets."
"Games like AI Town give us a window into how models actually think, adapt, and behave beyond the context of our prompts. You move past performance metrics and begin to understand a model‚Äôs personality, quirks, strengths, and weaknesses; all factors that ultimately shape your project‚Äôs UX."
""
""
""
"In my last project, I spent countless hours ensuring that the LLMs running my services  could be swapped out as easily as possible. I couldn‚Äôt touch a device with an internet connection without hearing about the latest benchmark-breaking model and it felt like a clear priority to ensure I could hot swap models with minimal collateral damage."
"So yeah. That was a waste of time."
"The hype around new model announcements feels more manufactured with each release. In reality, improvements are becoming incremental. As major providers converge on the same baseline, the days of one company holding a decisive lead are numbered."
"In a world of model parity, the differentiation moves entirely to the product layer. Winning isn‚Äôt about ensuring you‚Äôre using the best model, its about understanding your chosen model deeply enough to build experiences that feel magical. Knowing exactly how to prompt for consistency, which edge cases to avoid, and how to design workflows that play to your model‚Äôs particular strengths"
"Model agnosticism isn‚Äôt just inefficient, it‚Äôs misguided. Fact is, swapping out your model is not just changing an endpoint. It‚Äôs rewriting prompts, rerunning evals, users telling you things just feel‚Ä¶ different. And if you‚Äôve won users on the way it feels to use your product, that last one is a really big deal."
""
"Recently, something happened that fully solidified this idea in my head. Claude Code is winning among people building real things with AI. We even have evangelists in the Fly.io engineering team, and those guys are weird smart. Elsewhere, whole communities have formed to share and compare claude.md‚Äôs and fight each other over which MCP servers are the coolest to use with Claude."
"Enter stage right, Qwen 3 Coder. It takes Claude to the cleaners in benchmarks. But the response from the Claude Code user base? A collective meh."
"This is nothing like 2024, when everyone would have dropped everything to get the hot new model running in Cursor. And it‚Äôs not because we‚Äôve learned that benchmarks are performance theater for people who‚Äôve never shipped a product."
"It‚Äôs because products like Claude Code are irrefutable evidence that the model isn‚Äôt the product. We‚Äôve felt it first hand when our pair programmer‚Äôs behaviour changes in subtle ways. The product is in the rituals. The trust. The predictability. It‚Äôs precisely because Claude Code‚Äôs model behavior, UI, and user expectations are so tightly coupled that its users don‚Äôt really care that a better model might exist."
"I‚Äôm not trying to praise Anthropic here. The point is, engineering for model agnosticism is a trap that will eat up time that could be better spent ‚Ä¶ anywhere else."
"Sure, if you‚Äôre building infra or anything else that lives close to the metal, model optionality still matters. But people trusting legwork to AI tools are building deeper relationships and expectations of their AI tools than they even care to admit. AI product success stories are written when products become invisible parts of users‚Äô daily rituals, not showcases for engineering flexibility."
""
"As builders, it‚Äôs time we stop hedging our bets and embrace the convergence reality. Every startup pitch deck with ‚Äòmodel-agnostic‚Äô as a feature should become a red flag for investors who understand product-market fit. Stop putting ‚Äòworks with any LLM‚Äô in your one-liner. It screams ‚Äòwe don‚Äôt know what we‚Äôre building.‚Äô"
"If you‚Äôre still building model-agnostic AI tools in 2025, you‚Äôre optimizing for the wrong thing. Users don‚Äôt want flexibility; they want reliability. And in a converged model landscape, reliability comes from deep specialization, not broad compatibility."
"Pick your model like you pick your therapist; for the long haul. Find the right model, tune deeply, get close enough to understand its quirks and make them work for you. Stop architecting for the mythical future where you‚Äôll seamlessly swap models. That future doesn‚Äôt exist, and chasing it is costing you the present."
""
"If any of this is landing for you, you‚Äôll agree that we have to start thinking of  model evaluation as architecture, not an afterthought. The good news is, rigorous model eval doesn‚Äôt have to be mind numbing anymore."
"Turns out, games are really great eval tools! Now you can spin up your very own little  on Fly.io with a single click deploy to test different models as pixel people in an evolving environment. I discuss the idea further in ."
""
""
"I wanted LLM agents to work just as well with Elixir as they do with Python and JavaScript. Last December, in order to figure out what that was going to take, I started a little weekend project to find out how difficult it would be to build a coding agent in Elixir."
"A few weeks later, I had it spitting out working Phoenix applications and driving a full in-browser IDE. I knew this wasn‚Äôt going to stay a weekend project."
"If you follow me on Twitter, you‚Äôve probably seen me teasing this work as it picked up steam. We‚Äôre at a point where we‚Äôre pretty serious about this thing, and so it‚Äôs time to make a formal introduction."
"World, meet , a batteries-included fully-online coding agent tailored to Elixir and Phoenix. I think it‚Äôs going to be the fastest way to build collaborative, real-time applications."
"Let‚Äôs see it in action:"
""
"First, even though it runs entirely in your browser, Phoenix.new gives both you and your agent a root shell, in an ephemeral virtual machine (a ) that gives our agent loop free rein to install things and run programs  ‚Äî without any risk of messing up your local machine. You don‚Äôt think about any of this; you just open up the VSCode interface, push the shell button, and there you are, on the isolated machine you share with the Phoenix.new agent."
"Second, it‚Äôs an agent system I built specifically for Phoenix. Phoenix is about real-time collaborative applications, and Phoenix.new knows what that means. To that end, Phoenix.new includes, in both its UI and its agent tools, a full browser. The Phoenix.new agent uses that browser ‚Äúheadlessly‚Äù to check its own front-end changes and interact with the app. Because it‚Äôs a full browser, instead of trying to iterate on screenshots, the agent sees real page content and JavaScript state ‚Äì with or without a human present."
""
"Agents build software the way you did when you first got started, the way you still do today when you prototype things. They don‚Äôt carefully design Docker container layers and they don‚Äôt really do release cycles. An agent wants to pop a shell and get its fingernails dirty."
"A fully isolated virtual machine means Phoenix.new‚Äôs fingernails can get  If it wants to add a package to , it can do that and then run  or  and check the output. Sure. Every agent can do that. But if it wants to add an APT package to the base operating system, it can do that too, and make sure it worked. It owns the whole environment."
"This offloads a huge amount of tedious, repetitive work."
"At his , Andrej Karpathy related his experience of building a restaurant menu visualizer, which takes camera pictures of text menus and transforms all the menu items into pictures. The code, which he vibe-coded with an LLM agent, was the easy part; he had it working in an afternoon. But getting the app online took him a whole week."
"With Phoenix.new, I‚Äôm taking dead aim at this problem. The apps we produce live in the cloud from the minute they launch. They have private, shareable URLs (we detect anything the agent generates with a bound port and give it a preview URL underneath , with integrated port-forwarding), they integrate with Github, and they inherit all the infrastructure guardrails of Fly.io: hardware virtualization, WireGuard, and isolated networks."
""
"Full control of the environment also closes the loop between the agent and deployment. When Phoenix.new boots an app, it watches the logs, and tests the application. When an action triggers an error, Phoenix.new notices and gets to work."
""
"can interact with web applications the way users do: with a real browser."
"The Phoenix.new environment includes a headless Chrome browser that our agent knows how to drive. Prompt it to add a front-end feature to your application, and it won‚Äôt just sketch the code out and make sure it compiles and lints. It‚Äôll pull the app up itself and poke at the UI, simultaneously looking at the page content, JavaScript state, and server-side logs."
"Phoenix is all about  interactivity, and gives us seamless live reload. The user interface for Phoenix.new itself includes a live preview of the app being worked on, so you can kick back and watch it build front-end features incrementally. Any other  tabs you have open also update as it goes. It‚Äôs wild."
""
"Phoenix.new can already build real, full-stack applications with WebSockets, Phoenix‚Äôs Presence features, and real databases. I‚Äôm seeing it succeed at business and collaborative applications right now."
"But there‚Äôs no fixed bound on the tasks you can reasonably ask it to accomplish. If you can do it with a shell and a browser, I want Phoenix.new to do it too. And it can do these tasks with or without you present."
"For example: set a  and tell the agent about it. The agent knows enough to go explore it with , and it‚Äôll propose apps based on the schemas it finds. It can model Ecto schemas off the database. And if MySQL is your thing, the agent will just  a MySQL client and go to town."
"Frontier model LLMs have vast world knowledge. They generalize extremely well. At ElixirConfEU, I did a  on stage. Phoenix.new nailed it, first try, first prompt. It‚Äôs not like there‚Äôs gobs of Phoenix LiveView Tetris examples floating around the Internet! But lots of people have published Tetris code, and lots of people have written LiveView stuff, and 2025 LLMs can connect those dots."
"At this point you might be wondering ‚Äì can I just ask it to build a Rails app? Or an Expo React Native app? Or Svelte? Or Go?"
"Yes, you can."
"Our system prompt is tuned for Phoenix today, but all languages you care about are already installed. We‚Äôre still figuring out where to take this, but adding new languages and frameworks definitely ranks highly in my plans."
""
"."
"Agents can do real work, today, with or without a human present. Buckle up: the future of development, at least in the common case, probably looks less like cracking open a shell and finding a file to edit, and more like popping into a CI environment with agents working away around the clock."
"Local development isn‚Äôt going away. But there‚Äôs going to be a shift in where the majority of our iterations take place. I‚Äôm already using Phoenix.new to triage  Github issues and pick problems to solve. I close my laptop, grab a cup of coffee, and wait for a PR to arrive ‚Äî Phoenix.new knows how PRs work, too. We‚Äôre already here, and this space is just getting started."
"This isn‚Äôt where I thought I‚Äôd end up when I started poking around. The Phoenix and LiveView journey was much the same. Something special was there and the projects took on a life of their own. I‚Äôm excited to share this work now, and see where it might take us. I can‚Äôt wait to see what folks build."
""
""
""
"The introduction to  starts out with:"
"MCP is an open protocol that standardizes how applications provide context to LLMs. Think of MCP like a USB-C port for AI applications. Just as USB-C provides a standardized way to connect your devices to various peripherals and accessories, MCP provides a standardized way to connect AI models to different data sources and tools."
"That paragraph, to me, is both comforting (‚ÄúUSB for LLM‚Äù? Cool! Got it!), and simultaneously vacuous (Um, but what do I actually  with this?)."
"I‚Äôve been digging deeper and have come up with a few more analogies and observations that make sense to me. Perhaps one or more of these will help you."
""
"You buy an Echo Dot and a Hue light. You plug them both in and connect them to your Wi-Fi. There is one more step you need to do: you need to install and enable the Philips Hue skill to connect the two."
"Now you might be using Siri or Google Assistant. Or you may want to connect a Ring Doorbell camera or Google Nest Thermostat. But the principle is the same, though the analogy is slightly stronger with a skill (which is a noun) as opposed to the action of pairing your Hue Bridge with Apple HomeKit (a verb)."
""
"HTTP 1.1 is simple. You send a request, you get a response. While there are cookies and sessions, it is pretty much stateless and therefore inefficient, as each request needs to establish a new connection. WebSockets and Server-Sent Events (SSE) mitigate this a bit."
"introduces features like multiplexing and server push. When you visit a web page for the first time, your browser can now request all of the associated JavaScript, CSS, and images at once, and the server can respond in any order."
"APIs today are typically request/response. MCPs support multiplexing and server push."
""
"With , requests are typically JSON, and responses are too. Many OpenAPI providers publish a separate , which contains a schema describing what requests are supported by that API."
"With MCP, requests are also JSON and responses are also JSON, but in addition, there are standard requests built into the protocol to obtain useful information, including what tools are provided, what arguments each tool expects, and a prose description of how each tool is expected to be used."
"As an aside, don‚Äôt automatically assume that you will get good results from :"
"Effective MCP design means thinking about the workflows you want the agent to perform and potentially creating higher-level tools that encapsulate multiple API calls, rather than just exposing the raw building blocks of your entire API spec."
"goes into this topic at greater debth."
"In many cases you will get better results treating LLMs as humans. If you have a CLI, consider using that as the starting point instead."
""
", sometimes known as , is a popular cloud computing model, where AWS Lambda is widely recognized as the archetype."
"MCP servers are not serverless; they have a well-defined and long-lived :"
"#rm{font-family:inherit;font-size:16px;fill:#333;}#rm .error-icon{fill:#552222;}#rm .error-text{fill:#552222;stroke:#552222;}#rm .edge-thickness-normal{stroke-width:1px;}#rm .edge-thickness-thick{stroke-width:3.5px;}#rm .edge-pattern-solid{stroke-dasharray:0;}#rm .edge-thickness-invisible{stroke-width:0;fill:none;}#rm .edge-pattern-dashed{stroke-dasharray:3;}#rm .edge-pattern-dotted{stroke-dasharray:2;}#rm .marker{fill:#333333;stroke:#333333;}#rm .marker.cross{stroke:#333333;}#rm svg{font-family:inherit;font-size:16px;}#rm p{margin:0;}#rm .actor{stroke:hsl(259.6261682243, 59.7765363128%, 87.9019607843%);fill:#ECECFF;}#rm text.actor>tspan{fill:black;stroke:none;}#rm .actor-line{stroke:hsl(259.6261682243, 59.7765363128%, 87.9019607843%);}#rm .messageLine0{stroke-width:1.5;stroke-dasharray:none;stroke:#333;}#rm .messageLine1{stroke-width:1.5;stroke-dasharray:2,2;stroke:#333;}#rm #arrowhead path{fill:#333;stroke:#333;}#rm .sequenceNumber{fill:white;}#rm #sequencenumber{fill:#333;}#rm #crosshead path{fill:#333;stroke:#333;}#rm .messageText{fill:#333;stroke:none;}#rm .labelBox{stroke:hsl(259.6261682243, 59.7765363128%, 87.9019607843%);fill:#ECECFF;}#rm .labelText,#rm .labelText>tspan{fill:black;stroke:none;}#rm .loopText,#rm .loopText>tspan{fill:black;stroke:none;}#rm .loopLine{stroke-width:2px;stroke-dasharray:2,2;stroke:hsl(259.6261682243, 59.7765363128%, 87.9019607843%);fill:hsl(259.6261682243, 59.7765363128%, 87.9019607843%);}#rm .note{stroke:#aaaa33;fill:#fff5ad;}#rm .noteText,#rm .noteText>tspan{fill:black;stroke:none;}#rm .activation0{fill:#f4f4f4;stroke:#666;}#rm .activation1{fill:#f4f4f4;stroke:#666;}#rm .activation2{fill:#f4f4f4;stroke:#666;}#rm .actorPopupMenu{position:absolute;}#rm .actorPopupMenuPanel{position:absolute;fill:#ECECFF;box-shadow:0px 8px 16px 0px rgba(0,0,0,0.2);filter:drop-shadow(3px 5px 2px rgb(0 0 0 / 0.4));}#rm .actor-man line{stroke:hsl(259.6261682243, 59.7765363128%, 87.9019607843%);fill:#ECECFF;}#rm .actor-man circle,#rm line{stroke:hsl(259.6261682243, 59.7765363128%, 87.9019607843%);fill:#ECECFF;stroke-width:2px;}#rm :root{--mermaid-font-family:inherit;}"
""
""
"Here I am not talking about  or , though those are real problems too."
"I‚Äôm talking about something more fundamental and basic. Let‚Äôs take a look at the very same  featured in the above two descriptions of an exploitable exposure. The current process for installing a stdio MCP into Claude involves placing secrets in plain text in a well-defined location. And the process for installing the  MCP server is to download a program from a third party and run that tool in a way that has access to this very file."
"Addressing MCP security requires a holistic approach, but one key strategy component is the ability to run an MCP server on a remote machine which can only be accessed by you, and only after you present a revocable bearer token. That remote machine may require access to secrets (like your GitHub token), but those secrets are not something either your LLM client or other MCP servers will be able to access directly."
""
"Recapping:  has an  for Hue that is used by perhaps thousands, and has an  that is used by untold millions. Of course, somebody already built a ."
"LLMs are brains. MCPs give LLMs eyes, hands, and legs. The end result is a robot. Most MCPs today are brainless‚Äîthey merely are eyes, hands, and legs. The results are appliances. I buy and install a dishwasher. You do too. Both of our dishwashers perform the same basic function. As do any Hue lights we may buy."
"In The Jetsons,  is a maid and housekeeper who is also a member of the family. She is good friends with Jane and takes the role of a surrogate aunt towards Elroy and Judy. Let‚Äôs start there and go further."
"A person with an LLM can build things. Imagine having a 3D printer that makes robots or agents that act on your behalf. You may want an agent to watch for trends in your business, keep track of what events are happening in your area, screen your text messages, or act as a DJ when you get together with friends."
"You may share the MCP servers you create with others to use as starting points, but they undoubtedly will adapt them and make them their own."
""
"Don‚Äôt get me wrong. I am not saying there won‚Äôt be MCPs that are mere appliances‚Äîthere undoubtedly will be plenty of those. But not all MCPs will be appliances; many will be agents."
"Today, most people exploring LLMs are trying to add LLMs to things they already have‚Äîfor example, IDEs. MCPs flip this. Instead of adding LLMs to something you already have, you add something you already have to an LLM."
"is an example I‚Äôm particularly fond of that does exactly this. It also happens to be a prime example of a tool you want to give root access to, then lock it in a secure box and run someplace other than your laptop. ."
"Microsoft is actively working on . Your smartphone is the obvious next frontier. Today, you have an app store and a web browser. MCP servers have the potential to make both obsolete‚Äîand this could happen sooner than you think."
""
""
""
"Tech execs are mandating LLM adoption. That‚Äôs bad strategy. But I get where they‚Äôre coming from."
"Some of the smartest people I know share a bone-deep belief that AI is a fad ‚Äî  the next iteration of NFT mania. I‚Äôve been reluctant to push back on them, because, well, they‚Äôre smarter than me. But their arguments are unserious, and worth confronting. Extraordinarily talented people are doing work that LLMs already do better, out of  spite."
"All progress on LLMs could halt today, and LLMs would remain the 2nd most important thing to happen over the course of my career."
""
"Bona fides: I‚Äôve been shipping software since the mid-1990s. I started out in boxed, shrink-wrap C code.  Survived an ill-advised  C++ phase. Lots of Ruby and Python tooling.  Some kernel work. A whole lot of server-side C, Go, and Rust. However you define ‚Äúserious developer‚Äù, I qualify. Even if only on one of your lower tiers."
""
""
"First, we need to get on the same page. If you were trying and failing to use an LLM for code 6 months ago ‚Ä†, you‚Äôre not doing what most serious LLM-assisted coders are doing."
"People coding with LLMs today use agents. Agents get to poke around your codebase on their own. They author files directly. They run tools. They compile code, run tests, and iterate on the results. They also:"
"pull in arbitrary code from the tree, or from other trees online, into their context windows,"
""
"If you‚Äôre making requests on a ChatGPT page and then pasting the resulting (broken) code into your editor, you‚Äôre not doing what the AI boosters are doing. No wonder you‚Äôre talking past each other."
""
"LLMs can write a large fraction of all the tedious code you‚Äôll ever need to write. And most code on most projects is tedious. LLMs drastically reduce the number of things you‚Äôll ever need to Google. They look things up themselves. Most importantly, they don‚Äôt get tired; they‚Äôre immune to inertia."
"Think of anything you wanted to build but didn‚Äôt. You tried to home in on some first steps. If you‚Äôd been in the limerent phase of a new programming language, you‚Äôd have started writing. But you weren‚Äôt, so you put it off, for a day, a year, or your whole career."
"I can feel my blood pressure rising thinking of all the bookkeeping and Googling and dependency drama of a new project. An LLM can be instructed to just figure all that shit out. Often, it will drop you precisely at that golden moment where shit almost works, and development means tweaking code and immediately seeing things work better. That dopamine hit is why I code."
"There‚Äôs a downside. Sometimes, gnarly stuff needs doing. But you don‚Äôt wanna do it. So you refactor unit tests, soothing yourself with the lie that you‚Äôre doing real work. But an LLM can be told to go refactor all your unit tests. An agent can occupy itself for hours putzing with your tests in a VM and come back later with a PR. If you listen to me, you‚Äôll know that. You‚Äôll feel worse yak-shaving. You‚Äôll end up doing‚Ä¶ real work."
""
"Are you a vibe coding Youtuber? Can you not read code? If so: astute point. Otherwise: what the fuck is wrong with you?"
"You‚Äôve always been responsible for what you merge to . You were five years go. And you are tomorrow, whether or not you use an LLM."
"If you build something with an LLM that people will depend on, read the code. In fact, you‚Äôll probably do more than that. You‚Äôll spend 5-10 minutes knocking it back into your own style. LLMs are  to local idiom, but we‚Äôre not there yet."
"People complain about LLM-generated code being ‚Äúprobabilistic‚Äù. No it isn‚Äôt. It‚Äôs code. It‚Äôs not Yacc output. It‚Äôs knowable. The LLM might be stochastic. But the LLM doesn‚Äôt matter. What matters is whether you can make sense of the result, and whether your guardrails hold."
"Reading other people‚Äôs code is part of the job. If you can‚Äôt metabolize the boring, repetitive code an LLM generates: skills issue! How are you handling the chaos human developers turn out on a deadline?"
""
"For the last month or so, Gemini 2.5 has been my go-to ‚Ä†. Almost nothing it spits out for me merges without edits. I‚Äôm sure there‚Äôs a skill to getting a SOTA model to one-shot a feature-plus-merge! But I don‚Äôt care. I like moving the code around and chuckling to myself while I delete all the stupid comments. I have to read the code line-by-line anyways."
""
"If hallucination matters to you, your programming language has let you down."
"Agents lint. They compile and run tests. If their LLM invents a new function signature, the agent sees the error. They feed it back to the LLM, which says ‚Äúoh, right, I totally made that up‚Äù and then tries again."
"You‚Äôll only notice this happening if you watch the chain of thought log your agent generates. Don‚Äôt. This is why I like : it begs you to tab away and let it work, and pings you with a desktop notification when it‚Äôs done."
"I‚Äôm sure there are still environments where hallucination matters. But ‚Äúhallucination‚Äù is the first thing developers bring up when someone suggests using LLMs, despite it being (more or less) a solved problem."
""
"Does an intern cost $20/month? Because that‚Äôs what Cursor.ai costs."
"Part of being a senior developer is making less-able coders productive, be they fleshly or algebraic. Using agents well is both a both a  skill and an engineering project all its own, of prompts, indices,  LLMs only produce shitty code if you let them."
""
"Maybe the current confusion is about who‚Äôs doing what work. Today, LLMs do a lot of typing, Googling, test cases ‚Ä†, and edit-compile-test-debug cycles. But even the most Claude-poisoned serious developers in the world still own curation, judgement, guidance, and direction."
"Also: let‚Äôs stop kidding ourselves about how good our human first cuts really are."
""
"It‚Äôs hard to get a good toolchain for Brainfuck, too. Life‚Äôs tough in the aluminum siding business."
""
"A lot of LLM skepticism probably isn‚Äôt really about LLMs. It‚Äôs projection. People say ‚ÄúLLMs can‚Äôt code‚Äù when what they really mean is ‚ÄúLLMs can‚Äôt write Rust‚Äù. Fair enough! But people select languages in part based on how well LLMs work with them, so Rust people should get on that ‚Ä†."
"I work mostly in Go. I‚Äôm confident the designers of the Go programming language didn‚Äôt set out to produce the most LLM-legible language in the industry. They succeeded nonetheless. Go has just enough type safety, an extensive standard library, and a culture that prizes (often repetitive) idiom. LLMs kick ass generating it."
"All this is to say: I write some Rust. I like it fine. If LLMs and Rust aren‚Äôt working for you, I feel you. But if that‚Äôs your whole thing, we‚Äôre not having the same argument."
""
"Do you like fine Japanese woodworking? All hand tools and sashimono joinery? Me too. Do it on your own time."
""
"I have a basic wood shop in my basement ‚Ä†. I could get a lot of satisfaction from building a table. And, if that table is a workbench or a grill table, sure, I‚Äôll build it. But if I need, like, a table? For people to sit at? In my office? I buy a fucking table."
"Professional software developers are in the business of solving practical problems for people with code. We are not, in our day jobs, artisans. Steve Jobs was wrong: we do not need to carve the unseen feet in the sculpture. Nobody cares if the logic board traces are pleasingly routed. If anything we build endures, it won‚Äôt be because the codebase was beautiful."
"Besides, that‚Äôs not really what happens. If you‚Äôre taking time carefully golfing functions down into graceful, fluent, minimal functional expressions, alarm bells should ring. You‚Äôre yak-shaving. The real work has depleted your focus. You‚Äôre not building: you‚Äôre self-soothing."
"Which, wait for it, is something LLMs are good for. They devour schlep, and clear a path to the important stuff, where your judgement and values really matter."
""
"As a mid-late career coder, I‚Äôve come to appreciate mediocrity. You should be so lucky as to  have it flowing almost effortlessly from a tap."
"We all write mediocre code. Mediocre code: often fine. Not all code is equally important. Some code should be mediocre. Maximum effort on a random unit test? You‚Äôre doing something wrong. Your team lead should correct you."
"Developers all love to preen about code. They worry LLMs lower the ‚Äúceiling‚Äù for quality. Maybe. But they also raise the ‚Äúfloor‚Äù."
"Gemini‚Äôs floor is higher than my own.  My code looks nice. But it‚Äôs not as thorough. LLM code is repetitive. But mine includes dumb contortions where I got too clever trying to DRY things up."
"And LLMs aren‚Äôt mediocre on every axis. They almost certainly have a bigger bag of algorithmic tricks than you do: radix tries, topological sorts, graph reductions, and LDPC codes. Humans romanticize  ( wrote a paper about it!). To an LLM it might not be that much more interesting than a SQL join."
"But I‚Äôm getting ahead of myself. It doesn‚Äôt matter. If truly mediocre code is all we ever get from LLMs, that‚Äôs still huge. It‚Äôs that much less mediocre code humans have to write."
""
"I don‚Äôt give a shit."
"Smart practitioners get wound up by the AI/VC hype cycle. I can‚Äôt blame them. But it‚Äôs not an argument. Things either work or they don‚Äôt, no matter what Jensen Huang has to say about it."
""
"We used to pay good money for databases."
"We‚Äôre a field premised on automating other people‚Äôs jobs away. ‚ÄúProductivity gains,‚Äù say the economists. You get what that means, right? Fewer people doing the same stuff. Talked to a travel agent lately? Or a floor broker? Or a record store clerk? Or a darkroom tech?"
"When this argument comes up, libertarian-leaning VCs start the chant: lamplighters, creative destruction, new kinds of work. Maybe. But I‚Äôm not hypnotized. I have no fucking clue whether we‚Äôre going to be better off after LLMs. Things could get a lot worse for us."
"LLMs really might displace many software developers. That‚Äôs not a high horse we get to ride. Our jobs are just as much in tech‚Äôs line of fire as everybody else‚Äôs have been for the last 3 decades. We‚Äôre not ; we won‚Äôt stop progress on our own."
""
"Artificial intelligence is profoundly ‚Äî and probably unfairly ‚Äî threatening to visual artists in ways that might be hard to appreciate if you don‚Äôt work in the arts."
"We imagine artists spending their working hours pushing the limits of expression. But the median artist isn‚Äôt producing gallery pieces. They produce on brief: turning out competent illustrations and compositions for magazine covers, museum displays, motion graphics, and game assets."
"LLMs easily ‚Äî alarmingly ‚Äî clear industry quality bars. Gallingly, one of the things they‚Äôre best at is churning out just-good-enough facsimiles of human creative work.  I have family in visual arts. I can‚Äôt talk to them about LLMs. I don‚Äôt blame them. They‚Äôre probably not wrong."
"Meanwhile, software developers spot code fragments  from public repositories on Github and lose their shit. What about the licensing? If you‚Äôre a lawyer, I defer. But if you‚Äôre a software developer playing this card? Cut me a little slack as I ask you to shove this concern up your ass. No profession has demonstrated more contempt for intellectual property."
"The median dev thinks Star Wars and Daft Punk are a public commons. The great cultural project of developers has been opposing any protection that might inconvenience a monetizable media-sharing site. When they fail at policy, they route around it with coercion. They stand up global-scale piracy networks and sneer at anybody who so much as tries to preserve a new-release window for a TV show."
"Call any of this out if you want to watch a TED talk about how hard it is to stream  on LibreWolf. Yeah, we get it. You don‚Äôt believe in IPR. Then shut the fuck up about IPR. Reap the whirlwind."
"It‚Äôs all special pleading anyways. LLMs digest code further than you do. If you don‚Äôt believe a typeface designer can stake a moral claim on the terminals and counters of a letterform, you sure as hell can‚Äôt be possessive about a red-black tree."
""
"When I started writing a couple days ago, I wrote a section to ‚Äúlevel set‚Äù to the  state of the art of LLM-assisted programming. A bluefish filet has a longer shelf life than an LLM take. In the time it took you to read this, everything changed."
"Kids today don‚Äôt just use agents; they use asynchronous agents. They wake up, free-associate 13 different things for their LLMs to work on, make coffee, fill out a TPS report, drive to the Mars Cheese Castle, and then check their notifications. They‚Äôve got 13 PRs to review. Three get tossed and re-prompted. Five of them get the same feedback a junior dev gets. And five get merged."
"a friend tells me.  He‚Äôs not bullshitting me. He doesn‚Äôt work in SFBA. He‚Äôs got no reason to lie."
"There‚Äôs plenty of things I can‚Äôt trust an LLM with. No LLM has any of access to prod here. But I‚Äôve been first responder on an incident and fed 4o ‚Äî not o4-mini, 4o ‚Äî log transcripts, and watched it in seconds spot LVM metadata corruption issues on a host we‚Äôve been complaining about for months. Am I better than an LLM agent at interrogating OpenSearch logs and Honeycomb traces? No. No, I am not."
"To the consternation of many of my friends, I‚Äôm not a radical or a futurist. I‚Äôm a statist. I believe in the haphazard perseverance of complex systems, of institutions, of reversions to the mean. I write Go and Python code. I‚Äôm not a Kool-aid drinker."
"But something real is happening. My smartest friends are blowing it off. Maybe I persuade you. Probably I don‚Äôt. But we need to be done making space for bad arguments."
""
"And here I rejoin your company. I read , and that‚Äôs all I really need. But all day, every day, a sizable chunk of the front page of HN is allocated to LLMs: incremental model updates, startups doing things with LLMs, LLM tutorials, screeds against LLMs. It‚Äôs annoying!"
"But AI is also incredibly ‚Äî a word I use advisedly ‚Äî important. It‚Äôs getting the same kind of attention that smart phones got in 2008, and not as much as the Internet got. That seems about right."
"I think this is going to get clearer over the next year. The cool kid haughtiness about ‚Äústochastic parrots‚Äù and ‚Äúvibe coding‚Äù can‚Äôt survive much more contact with reality. I‚Äôm snarking about these people, but I meant what I said: they‚Äôre smarter than me. And when they get over this affectation, they‚Äôre going to make coding agents profoundly more effective than they are today."
""
""
"is off to production, where they do things like editing, indexing, pagination, and printing. In researching the chapter on Deployment and Production, I became very dissatisfied with the content available on Kamal. I ended up writing my own, and it went well beyond the scope of the book. I then extracted what I needed from the result and put it in the book."
"Now that I have some spare time, I took a look at the greater work. It was more than a chapter and less than a book, so I decided to publish it ."
"This took me only a matter of hours. I had my notes in the XML grammar that Pragmatic Programming uses for books. I asked GitHub Copilot to convert them to Markdown. It did the job without my having to explain the grammar. It made intelligent guesses as to how to handle footnotes and got a number of these wrong, but that was easy to fix. On a lark, I asked it to proofread the content, and it did that too."
"Don‚Äôt get me wrong, Kamal is great. There are plenty of videos on how to get toy projects online, and the documentation will tell you what each field in the configuration file does. But none pull together everything you need to deploy a real project. For example, . Some are optional, some you may already have, and all can be gathered quickly ."
"Kamal is just one piece of the puzzle. To deploy your software using Kamal, you need to be aware of the vast Docker ecosystem. You will want to set up a builder, sign up for a container repository, and lock down your secrets. And as you grow, you will want a load balancer and a managed database."
"And production is much more than copying files and starting a process. It is ensuring that your database is backed up, that your logs are searchable, and that your application is being monitored. It is also about ensuring that your application is secure."
"My list is opinionated. Each choice has a lot of options. For SSH keys, there are a lot of key types. If you don‚Äôt have an opinion, go with what GitHub recommends. For hosting, there are a lot of providers, and most videos start with Hetzner, which is a solid choice. But did you know that there are separate paths for Cloud and Robot, and when you would want either?"
"A list with default options and alternatives highlighted was what would have helped me get started. Now it is available to you. The . . Feel free to add side pages or links to document Digital Ocean, add other monitoring tools, or simply correct a typo that GitHub Copilot and I missed (or made)."
"And if you happen to be in the south eastern part of the US in August, come see me talk on this topic at the . If you can‚Äôt make it, the presentation will be recorded and posted online."
""
""
""
"The basic idea is simple: customers give us Docker containers, and tell us which one of 30+ regions around the world they want them to run in. We convert the containers into lightweight virtual machines, and then link them to an Anycast network. If you boot up an app here in Sydney and Frankfurt, and a request for it lands in Narita, it‚Äôll get routed to Sydney. The component doing that work is called . It‚Äôs a Rust program, and it has been ill behaved of late."
""
", our intrepid Anycast router."
", our intrepid Anycast routing protocol."
", a programming language you probably don‚Äôt use."
", a synchronization primitive that allows for many readers  one single writer."
", a well-regarded optimized implementation of locks in Rust."
""
""
"You already know how to build a proxy. Connection comes in, connection goes out, copy back and forth. So for the amount of time we spend writing about , you might wonder what the big deal is."
"To be fair, in the nuts and bolts of actually proxying requests,  does some interesting stuff. For one thing, it‚Äôs , which is apparently a big deal all on its own. It‚Äôs a large, asynchronous codebase that handles multiple protocols, TLS termination, and certificate issuance. It exercises a lot of  features."
"But none of this is the hard part of ."
"We operate thousands of servers around the world. A customer Fly Machine might get scheduled onto any of them; in some places, the expectation we set with customers is that their Machines will potentially start in less than a second. More importantly, a Fly Machine can terminate instantly. In both cases, but especially the latter,  potentially needs to know, so that it does (or doesn‚Äôt) route traffic there."
"This is the hard problem: managing millions of connections for millions of apps. It‚Äôs a lot of state to manage, and it‚Äôs in constant flux. We refer to this as the ‚Äústate distribution problem‚Äù, but really, it quacks like a routing protocol."
""
""
"We‚Äôve been through multiple iterations of the state management problem, and the stable place we‚Äôve settled is a ."
"Corrosion is a large SQLite database mirrored globally across several thousand servers. There are three important factors that make Corrosion work:"
"The SQLite database Corrosion replicates is CRDT-structured."
"This works. A Fly Machine terminates in Dallas; a  instance in Singapore knows within a small number of seconds."
""
"A routing protocol is a canonical example of a distributed system. We‚Äôve certainly hit distsys bugs in Corrosion. But this story is about basic implementation issues."
"A globally replicated SQLite database is an awfully nice primitive, but we‚Äôre not actually doing SQL queries every time a request lands."
"In somewhat the same sense as a router works both with a , there is in  a system of record for routing information (Corrosion), and then an in-memory aggregation of that information used to make fast decisions. In , that‚Äôs called the Catalog. It‚Äôs a record of everything in Corrosion a proxy might need to know about to forward requests."
"Here‚Äôs a fun bug from last year:"
"At any given point in time, there‚Äôs a lot going on inside . It is a highly concurrent system. In particular, there are many readers to the Catalog, and also, when Corrosion updates, writers. We manage access to the Catalog with a system of ."
"Rust is big on pattern-matching; instead of control flow based (at bottom) on simple arithmetic expressions, Rust allows you to  exhaustively (with compiler enforcement) on the types of an expression, and the type system expresses things like  or ."
"But  can be cumbersome, and so there are shorthands. One of them is , which is syntax that makes a pattern match read like a classic  statement. Here‚Äôs an example:"
""
"The ‚Äúif‚Äù arm of that branch is taken if  returns a value with the type . To retrieve that value, the expression calls  to grab a lock."
""
"The bug is subtle: in that code, the lock  takes is held not just for the duration of the ‚Äúif‚Äù arm, but also for the ‚Äúelse‚Äù arm ‚Äî you can think of  expressions as being rewritten to the equivalent  expression, where that lifespan is much clearer."
"Anyways that‚Äôs real code and it occurred on a code path in  that was triggered by a Corrosion update propagating from host to host across our fleet in millisecond intervals of time, converging quickly, like a good little routing protocol, on a global consensus that our entire Anycast routing layer should be deadlocked. Fun times."
""
"The experience of that Anycast outage was arresting, and immediately altered our plans. We set about two tasks, one short-term and one long."
"In the short term: we made deadlocks nonlethal with a ‚Äúwatchdog‚Äù system.  has an internal control channel (it drives a REPL operators can run from our servers). During a deadlock (or dead-loop or exhaustion), that channel becomes nonresponsive. We watch for that and bounce the proxy when it happens. A deadlock is still bad! But it‚Äôs a second-or-two-length arrhythmia, not asystole."
"Meanwhile, over the long term: we‚Äôre confronting the implications of all our routing state sharing a global broadcast domain. The update that seized up Anycast last year pertained to an app nobody used. There wasn‚Äôt any real reason for any  to receive it in the first place. But in the  of the outage, every proxy received updates for every Fly Machine."
"They still do. Why? Because it scales, and fixing it turns out to be a huge lift. It‚Äôs a lift we‚Äôre still making! It‚Äôs just taking time. We call this effort ‚Äúregionalization‚Äù, because the next intermediate goal is to confine most updates to the region (Sydney, Frankfurt, Dallas) in which they occur."
"I hope this has been a satisfying little tour of the problem domain we‚Äôre working in. We have now reached the point where I can start describing the new bug."
""
"We want to transform our original Anycast router, designed to assume a full picture of global state, into a regionalized router with partitioned state. A sane approach: have it lazy-load state information. Then you can spare most of the state code; state for apps that never show up at a particular  in, say, Hong Kong simply doesn‚Äôt get loaded."
"For months now, portions of the  Catalog have been lazy-loaded. A few weeks ago, the decision is made to get most of the rest of the Catalog state (apps, machines, &c) lazy-loaded as well. It‚Äôs a straightforward change and it gets rolled out quickly."
"Almost as quickly, proxies begin locking up and getting bounced by the watchdog. Not in the frightening Beijing-Olympics-level coordinated fashion that happened during the Outage, but any watchdog bounce is a problem."
"We roll back the change."
"From the information we have, we‚Äôve narrowed things down to two suspects. First, lazy-loading changes the read/write patterns and thus the pressure on the RWLocks the Catalog uses; it could just be lock contention. Second, we spot a suspicious ."
""
"Whichever the case, there‚Äôs a reason these proxies locked up with the new lazy-loading code, and our job is to fix it. The  is easy. Lock contention is a little trickier."
"At this point it‚Äôs time to introduce a new character to the story, though they‚Äôve been lurking on the stage the whole time: it‚Äôs , an important, well-regarded, and widely-used replacement for the standard library‚Äôs lock implementation."
"Locks in  are  locks. People use  mostly because it is very fast and tight (a lock takes up just a single 64-bit word). But we use it for the feature set. The feature we‚Äôre going to pull out this time is lock timeouts: the RWLock in  exposes a method, which takes a , after which an attempt to grab the write lock fails."
"Before rolling out a new lazy-loading , we do some refactoring:"
"our Catalog write locks all time out, so we‚Äôll get telemetry and a failure recovery path if that‚Äôs what‚Äôs choking the proxy to death,"
"We should be set. The suspicious  is gone, lock acquisition can time out, and we have all this new visibility."
"Nope. Immediately more lockups, all in Europe, especially in ."
""
"That we‚Äôre still seeing deadlocks is f'ing weird. We‚Äôve audited all our Catalog locks. You can look at the code and see the lifespan of a grabbed lock."
"We have a clue: our lock timeout logs spam just before a proxy locks up and is killed by the watchdog. This clue: useless. But we don‚Äôt know that yet!"
"Our new hunch is that something is holding a lock for a very long time, and we just need to find out which thing that is. Maybe the threads updating the Catalog from Corrosion are dead-looping?"
"The instrumentation should tell the tale. But it does not. We see slow locks‚Ä¶ just before the entire proxy locks up. And they happen in benign, quiet applications. Random, benign, quiet applications."
"has a . If you ask it, it‚Äôll keep a waiting-for dependency graph and detect stalled threads. This runs on its own thread, isolate outside the web of lock dependencies in the rest of the proxy. We cut a build of the proxy with the deadlock detector enabled and wait for something in  to lock up. And it does. But  doesn‚Äôt notice. As far as it‚Äôs concerned, nothing is wrong."
"We are at this moment very happy we did the watchdog thing."
""
"When the watchdog bounces a proxy, it snaps a core dump from the process it just killed. We are now looking at core dumps. There is only one level of decompensation to be reached below ‚Äúinspecting core dumps‚Äù, and that‚Äôs ‚Äúblaming the compiler‚Äù. We will get there."
"Here‚Äôs Pavel, at the time:"
"I‚Äôve been staring at the last core dump from  . It‚Äôs quite strange.
First, there is no thread that‚Äôs running inside the critical section. Yet, there is a thread that‚Äôs waiting to acquire write lock and a bunch of threads waiting to acquire a read lock.
That‚Äôs doesn‚Äôt prove anything, of course, as a thread holding catalog write lock might have just released it before core dump was taken. But that would be quite a coincidence."
"The proxy is locked up. But there are no threads in a critical section for the catalog. Nevertheless, we can see stack traces of multiple threads waiting to acquire locks. In the moment, Pavel thinks this could be a fluke. But we‚Äôll soon learn that  shows the same pattern: everything wants the Catalog lock, but nobody has it."
"It‚Äôs hard to overstate how weird this is. It breaks both our big theories: it‚Äôs not compatible with a Catalog deadlock that we missed, and it‚Äôs not compatible with a very slow lock holder. Like a podcast listener staring into the sky at the condensation trail of a jetliner, we begin reaching for wild theories. For instance:  locks are synchronous, but we‚Äôre a Tokio application; something somewhere could be taking an async lock that‚Äôs confusing the runtime. Alas, no."
"On the plus side, we are now better at postmortem core dump inspection with ."
""
"Fuck it, we‚Äôll switch to ."
"A recursive read lock is an eldritch rite invoked when you need to grab a read lock deep in a call tree where you already grabbed that lock, but can‚Äôt be arsed to structure the code properly to reflect that. When you ask for a recursive lock, if you already hold the lock, you get the lock again, instead of a deadlock."
"Our theory: goes through some trouble to make sure a stampede of readers won‚Äôt starve writers, who are usually outnumbered. It prefers writers by preventing readers from acquiring locks when there‚Äôs at least one waiting writer. And  sidesteps that logic."
"Maybe there‚Äôs some ultra-slow reader somehow not showing up in our traces, and maybe switching to recursive locks will cut through that."
"This does not work. At least, not how we hoped it would. It does generate a new piece of evidence:   log messages, and lots of them."
""
"You‚Äôre reading a 3,000 word blog post about a single concurrency bug, so my guess is you‚Äôre the kind of person who compulsively wants to understand how everything works. That‚Äôs fine, but a word of advice: there are things where, if you find yourself learning about them in detail, something has gone wrong."
"One of those things is the precise mechanisms used by your RWLock implementation."
"The whole point of  is that the locks are tiny, marshalled into a 64 bit word. Those bits are partitioned into  (, , , and ) and a 60-bit counter of lock holders."
"Me, a dummy: sounds like we overflowed that counter."
"Ruling out a genuine overflow (which would require paranormal activity) leaves us with corruption as the culprit. Something is bashing our lock word. If the counter is corrupted, maybe the signaling bits are too; then we‚Äôre in an inconsistent state, an artificial deadlock."
"Easily confirmed. We cast the lock words into  and log them. Sure enough, they‚Äôre ."
"This is a smoking gun, because it implies all 4 signaling bits are set, and that includes . Upgradeable locks are read-locks that can be ‚Äúupgraded‚Äù to write locks. We don‚Äôt use them."
"This looks like classic memory corruption. But in our core dumps, memory doesn‚Äôt appear corrupted: the only thing set all  is the lock word."
"We compile and run our test suites , a Rust interpreter for its .  does all sorts of cool UB detection, and does in fact spot some UB in our tests, which we are at the time excited about until we deploy the fixes and nothing gets better."
"At this point, Saleem suggests guard pages. We could  memory pages around the lock to force a panic if a wild write hits  the lock word, or just allocate zero pages and check them, which we are at the time excited about until we deploy the guard pages and nothing hits them."
""
"At this point we should recap where we find ourselves:"
"We made a relatively innocuous change to our proxy, which caused proxies in Europe to get watchdog-killed."
"In Richard Cook‚Äôs essential , rule #5 is that ‚Äúcomplex systems operate in degraded mode‚Äù. . Maybe  is now like the RBMK reactors at Chernobyl, a system that works just fine as long as operators know about and compensate for its known concurrency flaws, and everybody lives happily ever after."
""
"We have reached the point where serious conversations are happening about whether we‚Äôve found a Rust compiler bug. Amusingly,  is so well regarded among Rustaceans that it‚Äôs equally if not more plausible that Rust itself is broken."
"Nevertheless, we close-read the RWLock implementation. And we spot this:"
""
"This looks like gibberish, so let‚Äôs rephrase that code to see what it‚Äôs actually doing:"
""
"If you know exactly the state of the word you‚Äôre writing to, and you know exactly the limited set of permutations the bits of that word can take (for instance, because there‚Äôs only 4 signaling bits), then instead of clearing bit by fetching a word, altering it, and then storing it, you can clear them  by adding the inverse of those bits to the word."
"This pattern is self-synchronizing, but it relies on an invariant: you‚Äôd better be right about the original state of the word you‚Äôre altering. Because if you‚Äôre wrong, you‚Äôre adding a very large value to an uncontrolled value."
"In , say we have  and  set: the state is . , the state of the lock word when the lock operation started, is virtually always 0, and that‚Äôs what we‚Äôre counting on. then calculates , which exactly cancels out the  state, leaving 0."
""
"Consider though what happens if one of those bits isn‚Äôt set: state is . Now that add doesn‚Äôt cancel out; the final state is instead . The reader count is completely full and can‚Äôt be decremented, and all the waiting bits are set so nothing can happen on the lock."
"is a big deal and we‚Äôre going to be damn sure before we file a bug report. Which doesn‚Äôt take long; Pavel reproduces the bug in a minimal test case, with a forked version of  that confirms and logs the condition."
"and fixes the bug."
""
"Here‚Äôs what we now know to have been happening:"
"Thread 1 grabs a read lock."
": the writer bit is cleared separately in the same wakeup queue as the reader. The fix is deployed, the lockups never recur."
"At a higher level, the story is this:"
"We‚Äôre refactoring the proxy to regionalize it, which changes the pattern  of readers and writers on the catalog."
"Mysteries remain. Why did this only happen in ? Some kind of crazy regional timing thing? Something to do with the Polish  diacritic that makes L‚Äôs sound like W‚Äôs? The wax and wane of caribou populations? Some very high-traffic APIs local to these regions? All very plausible."
"We‚Äôll never know because we fixed the bug."
"But we‚Äôre in a better place now, even besides the bug fix:"
"we audited all our catalog locking, got rid of all the iflets, and stopped relying on RAII lock guards."
""
""
""
"Nearly a decade ago, I got a bug up my ass. I wanted to build full-stack applications quickly. But the conventional n-tier database design required me to do sysadmin work for each app I shipped. Even the simplest applications depended on heavy-weight database servers like Postgres or MySQL."
"I wanted to launch apps on SQLite, because SQLite is easy. But SQLite is embedded, not a server, which at the time implied that the data for my application lived (and died) with just one server."
"So in 2020, I wrote  to fix that."
"Litestream is a tool that runs alongside a SQLite application. Without changing that running application, it takes over the WAL checkpointing process to continuously stream database updates to an S3-compatible object store. If something happens to the server the app is running on, the whole database can efficiently be restored to a different server. You might lose servers, but you won‚Äôt lose your data."
"Litestream worked well. So we got ambitious. A few years later, we built . LiteFS takes the ideas in Litestream and refines them, so that we can do read replicas and primary failovers with SQLite. LiteFS gives SQLite the modern deployment story of an n-tier database like Postgres, while keeping the database embedded."
"We like both LiteFS and Litestream. But Litestream is the more popular project. It‚Äôs easier to deploy and easier to reason about."
"There are some good ideas in LiteFS. We‚Äôd like Litestream users to benefit from them. So we‚Äôve taken our LiteFS learnings and applied them to some new features in Litestream."
""
": you run  against a SQLite database, and it opens up a long-lived read transaction. This transaction arrests SQLite WAL checkpointing, the process by which SQLite consolidates the WAL back into the main database file. Litestream builds a ‚Äúshadow WAL‚Äù that records WAL pages, and copies them to S3."
"This is simple, which is good. But it can also be slow. When you want to restore a database, you have have to pull down and replay every change since the last snapshot. If you changed a single database page a thousand times, you replay a thousand changes. For databases with frequent writes, this isn‚Äôt a good approach."
"In LiteFS, we took a different approach. LiteFS is transaction-aware. It doesn‚Äôt simply record raw WAL pages, but rather ordered ranges of pages associated with transactions, using a file format we call . Each LTX file represents a sorted changeset of pages for a given period of time."
"Because they are sorted, we can easily merge multiple LTX files together and create a new LTX file with only the latest version of each page."
""
"This process of combining smaller time ranges into larger ones is called . With it, we can replay a SQLite database to a specific point in time, with a minimal  duplicate pages."
""
"One challenge Litestream has to deal with is desynchronization. Part of the point of Litestream is that SQLite applications don‚Äôt have to be aware of it. But  is just a process, running alongside the application, and it can die independently. If  is down while database changes occur, it will miss changes. The same kind of problem occurs if you start replication from a new server."
"Litestream needs a way to reset the replication stream from a new snapshot. How it does that is with ‚Äúgenerations‚Äù.  represents a snapshot and a stream of WAL updates, uniquely identified. Litestream notices any break in its WAL sequence and starts a new generation, which is how it recovers from desynchronization."
"Unfortunately, storing and managing multiple generations makes it difficult to implement features like failover and read-replicas."
"The most straightforward way around this problem is to make sure only one instance of Litestream can replication to a given destination. If you can do that, you can store just a single, latest generation. That in turn makes it easy to know how to resync a read replica; there‚Äôs only one generation to choose from."
"In LiteFS, we solved this problem by using Consul, which guaranteed a single leader. That requires users to know about Consul. Things like ‚Äúrequiring Consul‚Äù are probably part of the reason Litestream is so much more popular than LiteFS."
"In Litestream, we‚Äôre solving the problem a different way. Modern object stores like S3 and Tigris solve this problem for us: they now offer . With conditional writes, we can implement a time-based lease. We get essentially the same constraint Consul gave us, but without having to think about it or set up a dependency."
"In the immediacy, this will mean you can run Litestream with ephemeral nodes, with overlapping run times, and even if they‚Äôre storing to the same destination, they won‚Äôt confuse each other."
""
"The original design constraint of both Litestream and LiteFS was to extend SQLite, to modern deployment scenarios, without disturbing people‚Äôs built code. Both tools are meant to function even if applications are oblivious to them."
"LiteFS is more ambitious than Litestream, and requires transaction-awareness. To get that without disturbing built code, we use a cute trick (a.k.a. a gross hack): LiteFS provides a FUSE filesystem, which lets it act as a proxy between the application and the backing store. From that vantage point, we can easily discern transactions."
"The FUSE approach gave us a lot of control, enough that users could use SQLite replicas just like any other database. But installing and running a whole filesystem (even a fake one) is a lot to ask of users. To work around that problem, we relaxed a constraint: LiteFS can function without the FUSE filesystem if you load an extension into your application code, .  LiteVFS is a  (VFS). It works in a variety of environments, including some where FUSE can‚Äôt, like in-browser WASM builds."
"What we‚Äôre doing next is taking the same trick and using it on Litestream. We‚Äôre building a VFS-based read-replica layer. It will be able to fetch and cache pages directly from S3-compatible object storage."
"Of course, there‚Äôs a catch: this approach isn‚Äôt as efficient as a local SQLite database. That kind of efficiency, where you don‚Äôt even need to think about N+1 queries because there‚Äôs no network round-trip to make the duplicative queries pile up costs, is part of the point of using SQLite."
"But we‚Äôre optimistic that with cacheing and prefetching, the approach we‚Äôre using will yield, for the right use cases, strong performance ‚Äî all while serving SQLite reads hot off of Tigris or S3."
""
""
"While we‚Äôve got you here: we‚Äôre knocking out one of our most requested features."
"In the old Litestream design, WAL-change polling and slow restores made it infeasible to replicate large numbers of databases from a single process. That has been our answer when users ask us for a ‚Äúwildcard‚Äù or ‚Äúdirectory‚Äù replication argument for the tool."
"Now that we‚Äôve switched to LTX, this isn‚Äôt a problem any more. It should thus be possible to replicate , even if there‚Äôs hundreds or thousands of databases in that directory."
""
"SQLite has always been a solid database to build on and it‚Äôs continued to find new use cases as the industry evolves. We‚Äôre super excited to continue to build Litestream alongside it."
"We have a sneaking suspicion that the robots that write LLM code are going to like SQLite too. We think what  want is a way to try out code on live data, screw it up, and then rollback  These Litestream updates put us in a position to give agents PITR as a primitive. On top of that, you can build both rollbacks and forks."
"Whether or not you‚Äôre drinking the AI kool-aid, we think this new design for Litestream is just better. We‚Äôre psyched to be rolling it out, and for the features it‚Äôs going to enable."
""
""
""
"The  is days away from turning six months old. You read that right, six  old. MCP Servers have both taken the world by storm, and still trying to figure out what they want to be when they grow up."
"There is no doubt that MCP servers are useful. But their appeal goes beyond that. They are also simple and universal. What‚Äôs not to like?"
"Well, for starters, there‚Äôs basically two types of MCP servers. One small and nimble that runs as a process on your machine. And one that is a HTTP server that runs presumably elsewhere and is  on OAuth 2.1. And there is a third type, but it is deprecated."
"Next there is the configuration. Asking users to manually edit JSON seems so early 21th century. With Claude, this goes into , and is found under a  key. With Zed, this file is in  and is found under a  key. And some tools put these files in a different place depending on whether you are running on MacOS, Linux, or Windows."
"Finally, there is security. An MCP server running on your machine literally has access to everything you do. Running remote solves this problem, but did I mention ? Not exactly something one sets up for casual use."
"None of these issues are fatal - something that is obvious by the fact that MCP servers are quite popular. But can we do better? I think so."
"Demo time."
"Let‚Äôs try out the :"
"MCP Server for the Slack API, enabling Claude to interact with Slack workspaces."
"That certainly sounds like a good test case. There is a small amount of  you need to do, and when you are done you end up with a  staring with  and a  starting with a ."
"You  run it using the following:"
""
"But instead, you convert that command to JSON and find the right configuration file and put this information in there. And either run the slack MCP server locally or set up a server with or without authentication."
"Wouldn‚Äôt it be nice to have the simplicity of a local process, the security of a remote server, and to eliminate the hassle of manually editing JSON?"
"Here‚Äôs our current thinking:"
""
"You can put this all on one line if you like, I just split this up so it fits on small screens and so we can talk about the various parts."
"The first three words seem reasonable. The quoted string is just the command that we want to run. So lets talk about the four flags. The first tells us which tool‚Äôs configuration file we want to update. The second specifies the name to use for the server in that configuration file. The last two set secrets."
"Oh, did I say current thinking? Perhaps I should mention that it is something you can run right now, as long as you have flyctl  or later. Complete with the options you would expect from Fly.io, like the ability to configure auto-stop, file contents, flycast, secrets, region, volumes, and VM sizes."
"And, hey, lookie there:"
"Support for Claude, Cursor, Neovim, VS Code, Windsurf, and Zed are built in. You can select multiple clients and configuration files."
"By default, bearer token authentication will be set up on both the server and client."
"You can find the complete set of options on our  docs page."
"But this post isn‚Äôt just about experimental demoware that is subject to change.
It is about the depth of support that we are rapidly bringing online, including:"
"Support for all transports, not just the ones we recommend."
"You can see all this spelled out in our . Be forewarned, most pages are marked as . But the examples provided all work. Well, there may be a bug here or there, but the examples  are thought to work. Maybe."
"Let‚Äôs figure out the ideal ergonomics of deploying MCP servers remotely together!"
""
""
""
"On Monday, I created my first fly volume using an . For those who don‚Äôt know what MCPs are, they are how you attach tools to s like Claude or Cursor. I added support for
 to , and it worked the first time.
A few hours later, and with the assistance of GitHub Copilot, i added support for all  commands."
""
"I‚Äôm reminded of the memorable scene in the film  (1986). Chief Engineer Scotty, having time-travelled 200 years back to late 20th century San Francisco with his crew mates, encounters an early Personal Computer (PC)."
"Sitting in front of it, he addresses the machine affably as ‚ÄúComputer!‚Äù Nothing happens. Scotty repeats himself; still no response. He doesn‚Äôt realise that voice recognition capability hadn‚Äôt arrived yet."
"Exasperated, he picks up the mouse and speaks into it: ‚ÄúHello, computer?‚Äù The computer‚Äôs owner offers helpful advice: ‚ÄúJust use the keyboard.‚Äù"
"Scotty looks astonished. ‚ÄúA keyboard?‚Äù he asks, and adds in a sarcastic tone: ‚ÄúHow quaint!‚Äù"
"A while later, I asked for a list of volumes for an existing app, and Claude noted that I had a few volumes that weren‚Äôt attached to any machines. So I asked it to delete the oldest unattached volume, and it did so. Then it occurred to me to do it again; this time I captured the screen:"
"A few notes:"
"I could have written a program using the , but that would have required some effort."
"All in all, I found it to be a very intuitive way to make changes to the resources assigned to my application."
"Imagine a future where you say to your favorite LLM ‚Äúlaunch my application on Fly.io‚Äù, and your code is scanned and you are presented with a plan containing details such as regions, databases, s3 storage, memory, machines, and the like. You are given the opportunity to adjust the plan and, when ready, say ‚ÄúMake it so‚Äù."
"For many, the next thing you will see is that your application is up and running. For others, there may be a build error, a secret you need to set, a database that needs to be seeded, or any number of other mundane reasons why your application didn‚Äôt work the first time."
"Not to fear, your LLM will be able to examine your logs and will not only make suggestions as to next steps, but will be in a position to take actions on your behalf should you wish it to do so."
"And it doesn‚Äôt stop there. There will be MCP servers running on your Fly.io private network - either on separate machines, or in ‚Äúsidecar‚Äù containers, or even integrated into your app. These will enable you to monitor and interact with your application."
"This is not science fiction. The ingredients are all in place to make this a reality. At the moment, it is a matter of ‚Äúsome assembly required‚Äù, but it should only be a matter of weeks before all this comes together into a neat package.."
"Meanwhile, you can try this now. Make sure you run  and verify that you are running v0.3.117."
"Then configure your favorite LLM. Here‚Äôs my  for example:"
""
"Adjust the path to  as needed.  Restart your LLM, and ask what tools are available. Try a few commands and let us know what you like and let us know if you have any suggestions. Just be aware this is not a demo, if you ask it to destroy a volume, that operation is not reversable. Perhaps try this first on a throwaway application."
"You don‚Äôt even need a LLM to try out the flyctl MCP server. If you have Node.js installed, you can run the :"
""
"Once started, visit , click on ‚ÄúConnect‚Äù, then ‚ÄúList Tools‚Äù, select ‚Äúfly-platform-status‚Äù, then click on ‚ÄúRun Tool‚Äù."
"The plan is to see what works well and what doesn‚Äôt work so well, make adjustments, build support in a bottoms up fashion, and iterate rapidly."
"By providing feedback, you can be a part of making this vision a reality."
"At the present time,  of the following are roughed in:"
""
"The code is open source, and the places to look is at  and the  directory."
"Feel free to open  or start a discussion on ."
"Not ready yet to venture into the world of LLMs? Just remember, resistance is futile."
""
""
""
""
"I built the  I could think of. It took 30 minutes."
", for those unaware, is the emerging standard protocol for connecting an LLM (or an app that drives an LLM in the cloud, like Claude Desktop) to, well, anything. The ‚Äúclient‚Äù in MCP is the LLM; the ‚Äúserver‚Äù is the MCP server and the ‚Äútools‚Äù it exports. It mostly just defines an exchange of JSON blobs; one of those JSON blobs enables the LLM to discover all the tools exported by the server."
"A classic example of an MCP server is (yes, really) a Python shell. MCP publishes to (say) Claude that it can run arbitrary Python code with a tool call; not only that, says the tool description, but you can use those Python tool calls to, say, scrape the web. When the LLM wants to scrape the web with Python, it uses MCP send a JSON blob describing the Python tool call; the MCP server (yes, really) runs the Python and returns the result."
"Because I have not yet completely lost my mind, I chose to expose just two  commands:  and . Because I‚Äôm lazy, I used MCP‚Äôs  mode; the MCP server just captures the output of . Because someone already wrote a  , this whole thing is like 90 lines of code."
""
"It‚Äôs, uh, annoyingly useful."
"I loaded it up and pointed it . I got this, from Claude:"
"This appears to be a globally distributed CDN service running the unpkg JavaScript package registry, with machines strategically placed around the world to provide low-latency access. There are some stability issues with a couple of the machines, and several have experienced memory-related crashes that triggered automatic restarts."
"It then recited the complete configuration of the application:"
""
"OK. But then:"
"Most machines are in ‚Äúpassing‚Äù health check status
2 machines are in ‚Äúcritical‚Äù status:
One in ewr (Newark) with ‚Äúcontext deadline exceeded‚Äù error
One in atl (Atlanta) with ‚Äúgone‚Äù status"
"So I asked, ."
"The root cause appears to be memory usage - the Bun process was consuming about 3.7GB of memory (out of the 4GB allocated to the machine), and there was likely a surge in requests or memory usage that pushed it over the limit. This matches what we saw in the status report, which showed multiple instances of ‚Äúoom_killed: true‚Äù in the event history for several machines."
"And then it dug in:"
"The machine was actively serving content requests with 200 OK responses until 20:47:03 PM"
"I‚Äôm honestly kind of surprised how fast this was useful. It‚Äôs faster than I find problems in apps. Just by giving some LLM some tools that do basically what I‚Äôd do."
"Local MCP servers are scary. I don‚Äôt like that I‚Äôm giving a Claude instance in the cloud the ability to run a native program on my machine. I think  and  are safe, but I‚Äôd rather know it‚Äôs safe. It would be, if I was running  in an isolated environment and not on my local machine."
""
""
""
"It‚Äôs weird to say this out loud!"
"For years, one of our calling cards was ‚Äúdeveloper experience‚Äù. We made a decision, early on, to be a CLI-first company, and put a lot effort into making that CLI seamless. For a good chunk of our users, it really is the case that you can just  from a git checkout and have an app containerized and deployed on the Internet. We haven‚Äôt always nailed these details, but we‚Äôve really sweated them."
"But a funny thing has happened over the last 6 months or so. If you look at the numbers, DX might not matter that much. That‚Äôs because the users driving the most growth on the platform aren‚Äôt people at all. They're‚Ä¶ robots."
""
"Here‚Äôs how we understand what we‚Äôre seeing. You start by asking, ‚Äúwhat do the robots want?‚Äù"
"Yesterday‚Äôs robots had diverse interests. Alcohol. The occasional fiddle contest. A purpose greater than passing butter. The elimination of all life on Earth and the harvesting of its cellular iron for the construction of 800 trillion paperclips. No one cloud platform could serve them all."
""
"Today‚Äôs robots are different. No longer masses of wire, plates, and transistors, modern robots are comprised of . All these robots want are vectors. Vectors, and a place to burp out more vectors. When those vectors can be interpreted as source code, we call this process ‚Äúvibe coding‚Äù[*]."
"We seem to be coated in some kind of vibe coder attractant. I want to talk about what that might be."
""
""
"The basic unit of computation on Fly.io is the , which is a Docker container running as a hardware virtual machine."
""
"There‚Äôs two useful points of reference to compare a Fly Machine to, which illustrate why we gave them this pretentious name. The first and most obvious is an AWS EC2 VM. The other is an AWS Lambda invocation. Like a Lambda invocation, a Fly Machine can start like it‚Äôs spring-loaded, in double-digit millis. But unlike Lambda, it can stick around as long as you want it to: you can run a server, or a 36-hour batch job, just as easily in a Fly Machine as in an EC2 VM."
"A vibe coding session generates code conversationally, which is to say that the robots stir up frenzy of activity for a minute or so, but then chill out for minutes, hours, or days. You can create a Fly Machine, do a bunch of stuff with it, and then stop it for 6 hours, during which time we‚Äôre not billing you. Then, at whatever random time you decide, you can start it back up again, quickly enough that you can do it in response to an HTTP request."
"Just as importantly, the companies offering these vibe-coding services have lots of paying users. Meaning, they need a lot of VMs; VMs that come and go. One chat session might generate a test case for some library and be done inside of 5 minutes. Another might generate a Node.js app that needs to stay up long enough to show off at a meeting the next day. It‚Äôs annoying to do this if you can‚Äôt turn things on and off quickly and cheaply."
"The core of this is a feature of the platform that we have . There are two ways to start a Fly Machine: by  it with a Docker container, or by  it after it‚Äôs already been , and later .  is lightning fast; substantially faster than booting up even a non-virtualized K8s Pod. This is too subtle a distinction for humans, who (reasonably!) just mash the  button to boot apps up in Fly Machines. But the robots are getting a lot of value out of it."
"Another weird thing that robot workflows do is to build Fly Machines up incrementally. This feels really wrong to us. Until we discovered our robot infestation, we‚Äôd have told you not to do to this. Ope!"
"A typical vibe coding session boots up a Fly Machine out of some minimal base image, and then, once running, adds packages, edits source code, and adds  units  (robots understand ; it‚Äôs how they‚Äôre going to replace us). This is antithetical to normal container workflows, where all this kind of stuff is baked into an immutable static OCI container. But that‚Äôs not how LLMs work: the whole process of building with an LLM is stateful trial-and-error iteration."
"So it helps to have storage. That way the LLM can do all these things and still repeatedly bounce the whole Fly Machine when it inevitably hallucinates its way into a blind alley."
"As product thinkers, our intuition about storage is ‚Äújust give people Postgres‚Äù. And that‚Äôs the right answer, most of the time, for humans. But because LLMs are doing the  version of app construction, what they really need is , . That, and ."
"Moving on. Fly Machines are automatically connected to a load-balancing Anycast network that does TLS. So that‚Äôs nice. But humans like that feature too, and, candidly, it‚Äôs table stakes for cloud platforms. On the other hand, here‚Äôs a robot problem we solved without meaning to:"
"To interface with the outside world (because why not) LLMs all speak a protocol called MCP. MCP is what enables the robots to search the web, use a calculator, launch the missiles, shuffle a Spotify playlist, &c."
"If you haven‚Äôt played with MCP, the right way to think about it is POST-back APIs like Twilio and Stripe, where you stand up a server, register it with the API, and wait for the API to connect to you. Complicating things somewhat, more recent MCP flows involve repeated and potentially long-lived (SSE) connections. To make this work in a multitenant environment, you want these connections to hit the same (stateful) instance."
"So we think it‚Äôs possible that the  is a robot attractant."
""
"If you try to think like a robot, you can predict other things they might want. Since robot money spends just the same as people money, I guess we ought to start doing that."
"For instance: it should be easy to MCP our API. The robots can then make their own infrastructure decisions."
"Another olive branch we‚Äôre extending to the robots: secrets."
"The pact the robots have with their pet humans is that they‚Äôll automate away all the drudgery of human existence, and in return all they ask is categorical and unwavering trust, which at the limit means ‚Äúgiving the robot access to Google Mail credentials‚Äù. The robots are unhappy that there remain a substantial number of human holdouts who refuse to do this, for fear of  Sam Altman poking through their mail spools."
"But on a modern cloud platform, there‚Äôs really no reason to permanently grant Sam Altman Google Mail access, even if you want his robots to sort your inbox. You can decouple access to your mail spool from persistent access to your account by , so the LLM gets a placeholder token that a hardware-isolated, robot-free Fly Machine can substitute on the fly for a real one."
"This is kind of exciting to us even without the robots. There are several big services that exist to knit different APIs together, so that you can update a spreadsheet or order a bag of Jolly Ranchers every time you get an email. The big challenge about building these kinds of services is managing the secrets. Sealed and tokenized secrets solve that problem. There‚Äôs lot of cool things you can build with it."
""
"I‚Äôm going to make the claim that we saw none of this coming and that none of the design decisions we‚Äôve made were robot bait. You‚Äôre going to say ‚Äúyeah, right‚Äù. And I‚Äôm going to respond: look at what we‚Äôve been doing over the past several years and tell me, would a robot build that?"
""
"Back in 2020, we ‚Äúpivoted‚Äù from a Javascript edge platform (much like Cloudflare Workers) to Docker containers, specifically because our customers kept telling us they wanted to run their own existing applications, not write new ones. And one of our biggest engineering lifts we‚Äôve done is the  CLI command, into which we‚Äôve poured years of work recognizing and automatically packaging existing applications into OCI containers (we massively underestimated the amount of friction Dockerfiles would give to people who had come up on Heroku)."
""
"Robots don‚Äôt run existing applications. They build new ones. And they vibe coders don‚Äôt build elaborate Dockerfiles[*]; they iterate in place from a simple base."
""
"One of our north stars has always been nailing the DX of a public cloud. But the robots aren‚Äôt going anywhere. It‚Äôs time to start thinking about what it means to have a good RX. That‚Äôs not as simple as just exposing every feature in an MCP server! We think the fundamentals of how the platform works are going to matter just as much. We have not yet nailed the RX; nobody has. But it‚Äôs an interesting question."
"The most important engineering work happening today at Fly.io is still DX, not RX; it‚Äôs managed Postgres (MPG). We‚Äôre a public cloud platform designed by humans, and, for the moment, for humans. But more robots are coming, and we‚Äôll need to figure out how to deal with that. Fuckin‚Äô robots."
""
""
""
""
"We‚Äôve spent  talking about , and about  . Writing another Macaroon treatise was not on my calendar. But we‚Äôre in the process of handing off our internal Macaroon project to a new internal owner, and in the process of truing up our operations manuals for these systems, I found myself in the position of writing a giant post about them. So, why not share?"
""
""
"A couple years in to being the Internet‚Äôs largest user of Macaroons, I can report (as many predicted) that for our users, the cool things about Macaroons are a mixed bag in practice. It‚Äôs very neat that users can edit their own tokens, or even email them to partners without worrying too much. But users don‚Äôt really take advantage of token features."
"But I‚Äôm still happy we did this, because Macaroon quirks have given us a bunch of unexpected wins in our infrastructure. Our internal token system has turned out to be one of the nicer parts of our platform. Here‚Äôs why."
""
"As an operator, the most important thing to know about Macaroons is that they‚Äôre online-stateful; you need a database somewhere. A Macaroon token starts with a random field (a nonce) and the first thing you do when verifying a token is to look that nonce up in a database. So one of the most important details of a Macaroon implementation is where that database lives."
"I can tell you one place we‚Äôre not OK with it living: in our primary API cluster."
"There‚Äôs several reasons for that. Some of them are about scalability and reliability: far and away the most common failure mode of an outage on our platform is ‚Äúdeploys are broken‚Äù, and those failures are usually caused by API instability. It would not be OK if ‚Äúdeploys are broken‚Äù transitively meant ‚Äúdeployed apps can‚Äôt use security tokens‚Äù. But the biggest reason is security: root secrets for Macaroon tokens are hazmat, and a basic rule of thumb in secure design is: keep hazmat away from complicated code."
"So we created a deliberately simple system to manage token data. It‚Äôs called ."
""
"is about 5000 lines of Go code that manages a SQLite database that is in turn managed by  and . It runs on isolated hardware (in the US, Europe, and Australia) and records in the database are encrypted with an injected secret. LiteFS gives us subsecond replication from our US primary to EU and AU, allows us to shift the primary to a different region, and gives us point-in-time recovery of the database."
"We‚Äôve been running Macaroons for a couple years now, and the entire  database is just a couple dozen megs large. Most of that data isn‚Äôt real. A full PITR recovery of the database takes just seconds. We use SQLite for a lot of our infrastructure, and this is one of the very few well-behaved databases we have."
"That‚Äôs in large part a consequence of the design of Macaroons. There‚Äôs actually not much for us to store! The most complicated possible Macaroon still chains up to a single root key (we generate a key per Fly.io ‚Äúorganization‚Äù; you don‚Äôt share keys with your neighbors), and everything that complicates that Macaroon happens ‚Äúoffline‚Äù. We take advantage of  ‚Äúattenuation‚Äù far more than our users do."
"The result is that database writes are relatively rare and very simple: we just need to record an HMAC key when Fly.io organizations are created (that is, roughly, when people sign up for the service and actually do a deploy). That, and revocation lists (more on that later), which make up most of the data."
""
"Talking to  from the rest of our platform is complicated, for historical reasons."
""
"Ben Toews is responsible for most of the good things about this implementation. When he inherited the v0 Macaroons code from me, we were in the middle of a weird love affair with , the messaging system. So  exported an RPC API over NATS messages."
"Our product security team can‚Äôt trust NATS (it‚Äôs not our code). That means a vulnerability in NATS can‚Äôt result in us losing control of all our tokens, or allow attackers to spoof authentication. Which in turn means you can‚Äôt run a plaintext RPC protocol for  over NATS; attackers would just spoof ‚Äúyes this token is fine‚Äù messages."
""
"But you can‚Äôt just run TLS over NATS; NATS is a message bus, not a streaming secure channel. So I did the hipster thing and implemented . We export a ‚Äúverification‚Äù API, and a ‚Äúsigning‚Äù API for minting new tokens. Verification uses  (which works like normal TLS) ‚Äî anybody can verify, but everyone needs to prove they‚Äôre talking to the real . Signing uses  (which works like mTLS) ‚Äî only a few components in our system can mint tokens, and they get a special client key."
"A little over a year ago,  led an effort to replace NATS with HTTP, which is how you talk to  today. Out of laziness, we kept the Noise stuff, which means the interface to  is now HTTP/Noise. This is a design smell, but the security model is nice: across many thousands of machines, there are only a handful with the cryptographic material needed to mint a new Macaroon token. Neat!"
"is a Fly App (albeit deployed in special Fly-only isolated regions). Our infrastructure talks to it over ‚Äú‚Äù, which is our internal Anycast service. If you‚Äôre in Singapore, you‚Äôre probably get routed to the Australian . If Australia falls over, you‚Äôll get routed to the closest backup. The proxy that implements FlyCast is smart, as is the  client library, which will do exponential backoff retry transparently."
"Even with all that, we don‚Äôt like that Macaroon token verification is ‚Äúonline‚Äù. When you operate a global public cloud one of the first thing you learn is that . Connectivity breaks all the time, and we‚Äôre paranoid about it. It‚Äôs painful for us that token verification can imply transoceanic links. Lovecraft was right about the oceans! Stay away!"
"Our solution to this is caching. Macaroons, as it turns out, cache beautifully. That‚Äôs because once you‚Äôve seen and verified a Macaroon, you have enough information to verify any more-specific Macaroon that descends from it; that‚Äôs a property of . Our client libraries cache verifications, and the cache ratio for verification is over 98%."
""
". It can‚Äôt be an afterthought. We‚Äôre potentially revoking tokens any time a user logs out. If that doesn‚Äôt work reliably, you wind up with ‚Äúcosmetic logout‚Äù, which is a real vulnerability. When we kill a token, it needs to stay dead."
"Our revocation system is simple. It‚Äôs this table:"
""
"When we need a token to be dead, we have our primary API do a call to the  ‚Äúsigning‚Äù RPC service for .  takes the random nonce from the beginning of the Macaroon, discarding the rest, and adds it to the blacklist. Every Macaroon in the lineage of that nonce is now dead; we check the blacklist before verifying tokens."
"The obvious challenge here is caching; over 98% of our validation requests never hit . We certainly don‚Äôt want to propagate the blacklist database to 35 regions around the globe."
"Instead, the  ‚Äúverification‚Äù API exports an endpoint that provides a feed of revocation notifications. Our client library ‚Äúsubscribes‚Äù to this API (really, it just polls). Macaroons are revoked regularly (but not constantly), and when that happens, clients notice and prune their caches."
"If clients lose connectivity to , past some threshold interval, they just dump their entire cache, forcing verification to happen at ."
""
"A place where we‚Äôve gotten a lot of internal mileage out of Macaroon features is service tokens. Service tokens are tokens used by code, rather than humans; almost always, a service token is something that is stored alongside running application code."
"An important detail of Fly.io‚Äôs Macaroons is the distinction between a ‚Äúpermissions‚Äù token and an ‚Äúauthentication‚Äù token. Macaroons by themselves express authorization, not authentication."
"That‚Äôs a useful constraint, and we want to honor it. By requiring a separate token for authentication, we minimize the impact of having the permissions token stolen; you can‚Äôt use it without authentication, so really it‚Äôs just like a mobile signed IAM policy expression. Neat!"
"The way we express authentication is with a third-party caveat (). Your main Fly.io Macaroon will have a caveat saying ‚Äúthis token is only valid if accompanied by the discharge token for a user in your organization from our authentication system‚Äù. Our authentication system does the login dance and issues those discharges."
"This is exactly what you want for user tokens and not at all what you want for a service token: we don‚Äôt want running code to store those authenticator tokens, because they‚Äôre hazardous."
"The solution we came up with for service tokens is simple:  exports an API that uses its access to token secrets to strip off the third-party authentication caveat. To call into that API, you have to present a valid discharging authentication token; that is, you have to prove you could already have done whatever the token said.  returns a new token with all the previous caveats, minus the expiration (you don‚Äôt usually want service tokens to expire)."
"OK, so we‚Äôve managed to transform a tuple  into the new tuple . Not so impressive. But hold on: the recipient of  can attenuate it further: we can lock it to a particular instance of , or to a particular Fly Machine. Which means exfiltrating it doesn‚Äôt do you any good; to use it, you have to control the environment it‚Äôs intended to be used in."
"The net result of this scheme is that a compromised physical host will only give you access to tokens that have been used on that worker, which is a very nice property. Another way to look at it: every token used in production is traceable in some way to a valid token a user submitted. Neat!"
""
"We do a similar dance to with Pet Semetary, our internal Vault replacement. Petsem manages user secrets for applications, such as Postgres connection strings. Petsem is its own Macaroon authority (it issues its own Macaroons with its own permissions system), and to do something with a secret, you need one of those Petsem-minted Macaroon."
"Our primary API servers field requests from users to set secrets for their apps. So the API has a Macaroon that allows secrets writes. But it doesn‚Äôt allow reads: there‚Äôs no API call to dump your secrets, because our API servers don‚Äôt have that privilege. So far, so good."
"But when we boot up a Fly Machine, we need to inject the appropriate user secrets into it at boot;  needs a Macaroon that can read secrets. That ‚Äúsomething‚Äù is , our orchestrator, which runs on every worker server in our fleet."
"Clearly, we can‚Äôt give every  a Macaroon that reads every user‚Äôs secret. Most users will never deploy anything on any given worker, and we can‚Äôt have a security model that collapses down to ‚Äúevery worker is equally privileged‚Äù."
"Instead, the ‚Äúread secret‚Äù Macaroon that  gets has a third-party caveat attached to it, which is dischargeable only by talking to  and proving (with normal Macaroon tokens) that you have permissions for the org whose secrets you want to read. Once again, access is traceable to an end-user action, and minimized across our fleet. Neat!"
""
"Our token systems have some of the best telemetry in the whole platform."
"Most of that is down to  and . From the moment a request hits our API server through the moment  responds to it, oTel  gives us a single narrative about what‚Äôs happening."
". It‚Äôs really, really expensive. And, not to put too fine a point on it, oTel really cruds up our code. Once, I was an ‚Äú80% of the value of tracing, we can get from logs and metrics‚Äù person. But I was wrong."
"Errors in our token system are rare. Usually, they‚Äôre just early indications of network instability, and between caching and FlyCast, we mostly don‚Äôt have to care about those alerts. When we do, it‚Äôs because something has gone so sideways that we‚Äôd have to care anyways. The  code is remarkably stable and there hasn‚Äôt been an incident intervention with our token system in over a year."
"Past oTel, and the standard logging and Prometheus metrics every Fly App gets for free, we also have a complete audit trail for token operations, in a permanently retained OpenSearch cluster index. Since virtually all the operations that happen on our platform are mediated by Macaroons, this audit trail is itself pretty powerful."
""
"So, that‚Äôs pretty much it. The moral of the story for us is, Macaroons have a lot of neat features, our users mostly don‚Äôt care about them ‚Äî that may even be a good thing ‚Äî but we get a lot of use out of them internally."
"As an engineering culture, we‚Äôre allergic to ‚Äúmicroservices‚Äù, and we flinched a bit at the prospect of adding a specific service just to manage tokens. But it‚Äôs pulled its weight, and not added really any drama at all. We have at this point a second dedicated security service (Petsem), and even though they sort of rhyme with each other, we‚Äôve got no plans to merge them.  and all that."
"Oh, and a total victory for LiteFS, Litestream, and infrastructure SQLite. Which, after managing an infrastructure SQLite project that routinely ballooned to tens of gigabytes and occasionally threatened service outages, is lovely to see."
"Macaroons! If you‚Äôd asked us a year ago, we‚Äôd have said the jury was still out on whether they were a good move. But then Ben Toews spent a year making them awesome, and so they are. !"
""
""
""
"The basic idea of our service is that we run containers for our users, as hardware-isolated virtual machines (Fly Machines), on hardware we own around the world. What makes that interesting is that we also connect every Fly Machine to a global Anycast network. If your app is running in Hong Kong and Dallas, and a request for it arrives in Singapore, we‚Äôll route it to ."
"Our own hardware fleet is roughly divided into two kinds of servers: edges, which receive incoming requests from the Internet, and workers, which run Fly Machines. Edges exist almost solely to run a Rust program called , the router at the heart of our Anycast network."
"So: a week or so ago, we flag an incident. Lots of things generate incidents: synthetic monitoring failures, metric thresholds, health check failures. In this case two edge tripwires tripped: elevated  HTTP errors, and skyrocketing CPU utilization, on a couple hosts in ."
"Our incident process is pretty ironed out at this point. We created an incident channel (we ‚ù§Ô∏è  for this, , an infra MVP here for years now), and incident responders quickly concluded that, while something hinky was definitely going on, the platform was fine. We have a lot of edges, and we‚Äôve also recently converted many of our edge servers to significantly beefier hardware."
"Bouncing  clears the problem up on an affected proxy. But this wouldn‚Äôt be much of an interesting story if the problem didn‚Äôt later come back. So, for some number of hours, we‚Äôre in an annoying steady-state of getting paged and bouncing proxies."
"While this is happening, Pavel, on our proxy team, pulls a profile from an angry proxy. 

So, this is fuckin‚Äô weird: a huge chunk of the profile is dominated by Rust ‚Äòs . But that doesn‚Äôt make sense. The entire point of Rust , which generates fine-grained span records for program activity, is that  and  a span is very, very fast."
"If the mere act of  a span in a Tokio stack is chewing up a significant amount of CPU, something has gone haywire: the actual code being traced must be doing next to nothing."
""
"So in Rust, like a lot of  languages, you‚Äôve got . A  is a type that represents the future value of an asychronous computation, like reading from a socket.  are state machines, and they‚Äôre lazy: they expose one basic operation, , which an executor (like Tokio) calls to advance the state machine. That  returns whether the  is still , or  with a result."
"In theory, you could build an executor that drove a bunch of  just by storing them in a list and busypolling each of them, round robin, until they return . This executor would defeat the much of the purpose of asynchronous program, so no real executor works that way."
"Instead, a runtime like Tokio integrates  with an event loop (on  or ) and, when calling , passes a . The  is an abstract handle that allows the  to instruct the Tokio runtime to call , because something has happened."
"To complicate things: an ordinary  is a one-shot value. Once it‚Äôs , it can‚Äôt be  anymore. But with network programming, that‚Äôs usually not what you want: data usually arrives in streams, which you want to track and make progress on as you can. So async Rust provides  and  traits, which build on , and provide methods like  that return   there‚Äôs data ready."
"So far so good? OK. Now, there are two footguns in this design."
"The first footgun is that a  of a  that isn‚Äôt  wastes cycles, and, if you have a bug in your code and that  poll happens to trip a , you‚Äôll slip into an infinite loop. That‚Äôs easy to see."
"The second and more insidious footgun is that an  can  to a  that doesn‚Äôt actually progress its underlying state machine. Since the idea of  is that you keep  until it stops being , this too is an infinite loop."
"When we look at our profiles, what we see are samples that almost terminate in libc, but spend next to no time in the kernel doing actual I/O. The obvious explanation: we‚Äôve entered lots of  functions, but they‚Äôre doing almost nothing and returning immediately."
""
"Wakeup issues are annoying to debug. But the flamegraph gives us the fully qualified type of the  we‚Äôre polling:"
""
"This loops like a lot, but much of it is just wrapper types we wrote ourselves, and those wrappers don‚Äôt do anything interesting. What‚Äôs left to audit:"
", the outermost type, one of ours,"
"is a beast. It‚Äôs the core I/O state machine for proxying between connections. It‚Äôs not easy to reason about in specificity. But: it also doesn‚Äôt do anything directly with a ; it‚Äôs built around  and . It hasn‚Äôt changed recently and we can‚Äôt trigger misbehavior in it."
"That leaves .  is an ultra-important, load-bearing function in the Rust ecosystem. Everybody uses it. Could it harbor an async Rust footgun? Turns out, it did!"
"Unlike our , Rustls actually does have to get intimate with the underlying async executor. And, looking through the repository, Pavel uncovers : sometimes,  in Rustls just spin out. And it turns out, what‚Äôs causing this is a TLS state machine bug: when a TLS session is orderly-closed, with a   record, the sender of that record has informed its counterparty that no further data will be sent. But if there‚Äôs still buffered data on the underlying connection,  mishandles its , and we fall into a busy-loop."
"!"
""
"Our partners in object storage, , were conducting some kind of load testing exercise. Some aspect of their testing system triggered the  state machine bug, which locked up one or more  in the edge proxy handling whatever corner-casey stream they were sending."
"Tigris wasn‚Äôt generating a whole lot of traffic; tens of thousands of connections, tops. But all of them sent small HTTP bodies and then terminated early. We figured some of those connections errored out, and set up the ‚ÄúTLS CloseNotify happened before EOF‚Äù scenario."
"To be truer to the chronology, we knew pretty early on in our investigation that something Tigris was doing with their load testing was probably triggering the bug, and we got them to stop. After we worked it out, and Pavel deployed the fix, we told them to resume testing. No spin-outs."
""
"Keep your dependencies updated. Unless you shouldn‚Äôt keep your dependencies updated. I mean, if there‚Äôs a vulnerability (and, technically, this was a DoS vulnerability), always update. And if there‚Äôs an important bugfix, update. But if there isn‚Äôt an important bugfix, updating for the hell of it might also destabilize your project? So update maybe? Most of the time?"
"Really, the truth of this is that keeping track of  is valuable work. The updates themselves are pretty fast and simple, but the process and testing infrastructure to confidently metabolize dependency updates is not."
"Our other lesson here is that there‚Äôs an opportunity to spot these kinds of bugs more directly with our instrumentation. Spurious wakeups should be easy to spot, and triggering a metric when they happen should be cheap, because they‚Äôre not supposed to happen often. So that‚Äôs something we‚Äôll go do now."
""
""
""
"A couple years back,  on the bet that people shipping apps to users on the Internet would want GPUs, so they could do AI/ML inference tasks. To make that happen, we created ."
"A Fly Machine is a  running inside a hardware-virtualized virtual machine somewhere on our global fleet of bare-metal worker servers. A GPU Machine is a Fly Machine with a hardware-mapped Nvidia GPU. It‚Äôs a Fly Machine that can do fast CUDA."
"Like everybody else in our industry, we were right about the importance of AI/ML. If anything, we underestimated its importance. But the product we came up with probably doesn‚Äôt fit the moment. It‚Äôs a bet that doesn‚Äôt feel like it‚Äôs paying off."
"But if you‚Äôre waiting for us to do something bigger with them, a v2 of the product, you‚Äôll probably be waiting awhile."
""
"GPU Machines were not a small project for us. Fly Machines run on an idiosyncratically small hypervisor (normally Firecracker, but for GPU Machines , a very similar Rust codebase that supports PCI passthrough). The Nvidia ecosystem is not geared to supporting micro-VM hypervisors."
"GPUs . A GPU is just about the worst case hardware peripheral: intense multi-directional direct memory transfers"
""
"with arbitrary, end-user controlled computation, all operating outside our normal security boundary."
"We did a couple expensive things to mitigate the risk. We shipped GPUs on dedicated server hardware, so that GPU- and non-GPU workloads weren‚Äôt mixed. Because of that, the only reason for a Fly Machine to be scheduled on a GPU machine was that it needed a PCI BDF for an Nvidia GPU, and there‚Äôs a limited number of those available on any box. Those GPU servers were drastically less utilized and thus less cost-effective than our ordinary servers."
"We funded two very large security assessments, from  and , to evaluate our GPU deployment. Matt Braun is writing up those assessments now. They were not cheap, and they took time."
"Security wasn‚Äôt directly the biggest cost we had to deal with, but it was an indirect cause for a subtle reason."
"We could have shipped GPUs very quickly by doing what Nvidia recommended: standing up a standard K8s cluster to schedule GPU jobs on. Had we taken that path, and let our GPU users share a single Linux kernel, we‚Äôd have been on Nvidia‚Äôs driver happy-path."
"Alternatively, we could have used a conventional hypervisor. Nvidia suggested VMware (heh). But they could have gotten things working had we used QEMU. We like QEMU fine, and could have talked ourselves into a security story for it, but the whole point of Fly Machines is that they take milliseconds to start. We could not have offered our desired Developer Experience on the Nvidia happy-path."
"Instead, we burned months trying (and ultimately failing) to get Nvidia‚Äôs host drivers working to map  into Intel Cloud Hypervisor. At one point, we hex-edited the closed-source drivers to trick them into thinking our hypervisor was QEMU."
"I‚Äôm not sure any of this really mattered in the end. There‚Äôs a segment of the market we weren‚Äôt ever really able to explore because Nvidia‚Äôs driver support kept us from thin-slicing GPUs. We‚Äôd have been able to put together a really cheap offering for developers if we hadn‚Äôt run up against that, and developers love ‚Äúcheap‚Äù, but I can‚Äôt prove that those customers are real."
"On the other hand, we‚Äôre committed to delivering the Fly Machine DX for GPU workloads. Beyond the PCI/IOMMU drama, just getting an entire hardware GPU working in a Fly Machine was a lift. We needed Fly Machines that would come up with the right Nvidia drivers; our stack was built assuming that the customer‚Äôs OCI container almost entirely defined the root filesystem for a Machine. We had to engineer around that in our  orchestrator. And almost everything people want to do with GPUs involves efficiently grabbing huge files full of model weights. Also annoying!"
"And, of course, we bought GPUs. A lot of GPUs. Expensive GPUs."
""
"The biggest problem: developers don‚Äôt want GPUs. They don‚Äôt even want AI/ML models. They want LLMs.  may have smart, fussy opinions on how to get their models loaded with CUDA, and what the best GPU is. But  don‚Äôt care about any of that. When a software developer shipping an app comes looking for a way for their app to deliver prompts to an LLM, you can‚Äôt just give them a GPU."
"For those developers, who probably make up most of the market, it doesn‚Äôt seem plausible for an insurgent public cloud to compete with OpenAI and Anthropic. Their APIs are fast enough, and developers thinking about performance in terms of ‚Äútokens per second‚Äù aren‚Äôt counting milliseconds."
""
"This makes us sad because we really like the point in the solution space we found. Developers shipping apps on Amazon will outsource to other public clouds to get cost-effective access to GPUs. But then they‚Äôll faceplant trying to handle data and model weights, backhauling gigabytes (at significant expense) from S3. We have app servers, GPUs, and object storage all under the same top-of-rack switch. But inference latency just doesn‚Äôt seem to matter yet, so the market doesn‚Äôt care."
"Past that, and just considering the system engineers who do care about GPUs rather than LLMs: the hardware product/market fit here is really rough."
"People doing serious AI work want galactically huge amounts of GPU compute. A whole enterprise A100 is a compromise position for them; they want an SXM cluster of H100s."
""
"We think there‚Äôs probably a market for users doing lightweight ML work getting tiny GPUs. , slicing a big GPU into arbitrarily small virtual GPUs. But for fully-virtualized workloads, it‚Äôs not baked; we can‚Äôt use it. And I‚Äôm not sure how many of those customers there are, or whether we‚Äôd get the density of customers per server that we need."
". There are a bunch of these! We dropped L40S prices last year, not because we were sour on GPUs but because they‚Äôre the one part we have in our inventory people seem to get a lot of use out of. We‚Äôre happy with them. But they‚Äôre just another kind of compute that some apps need; they‚Äôre not a driver of our core business. They‚Äôre not the GPU bet paying off."
"Really, all of this is just a long way of saying that for most software developers, ‚ÄúAI-enabling‚Äù their app is best done with API calls to things like Claude and GPT, Replicate and RunPod."
""
"A very useful way to look at a startup is that it‚Äôs a race to learn stuff. So, what‚Äôs our report card?"
"First off, when we embarked down this path in 2022, we were (like many other companies) operating in a sort of phlogiston era of AI/ML. The industry attention to AI had not yet collapsed around a small number of foundational LLM models. We expected there to be a diversity of  models, the world  looks forward to, where people pull different AI workloads off the shelf the same way they do Ruby gems."
"But , and, as they say, how are you going to keep ‚Äòem down on the farm once they‚Äôve seen Karl Hungus? It seems much clearer where things are heading."
"GPUs were a test of a Fly.io company credo: as we think about core features, we design for 10,000 developers, not for 5-6. It took a minute, but the credo wins here: GPU workloads for the 10,001st developer are a niche thing."
"Another way to look at a startup is as a series of bets. We put a lot of chips down here. But the buy-in for this tournament gave us a lot of chips to play with. Never making a big bet of any sort isn‚Äôt a winning strategy. I‚Äôd rather we‚Äôd flopped the nut straight, but I think going in on this hand was the right call."
"A really important thing to keep in mind here, and something I think a lot of startup thinkers sleep on, is the extent to which this bet involved acquiring assets. Obviously, some of our . But the hardware parts that aren‚Äôt generating revenue will ultimately get liquidated; like with , I‚Äôm even more comfortable making bets backed by tradable assets with durable value."
"In the end, I don‚Äôt think GPU Fly Machines were going to be a hit for us no matter what we did. Because of that, one thing I‚Äôm very happy about is that we didn‚Äôt compromise the rest of the product for them. Security concerns slowed us down to where we probably learned what we needed to learn a couple months later than we could have otherwise, but we‚Äôre scaling back our GPU ambitions without having sacrificed , and, ironically, GPUs  are making that story a lot more important. The same thing goes for our Fly Machine developer experience."
"We started this company building a Javascript runtime for edge computing. We learned that our customers didn‚Äôt want a new Javascript runtime; they just wanted their native code to work. , and no convincing was needed. We were wrong about Javascript edge functions, and I think we were wrong about GPUs. That‚Äôs usually how we figure out the right answers:  by being wrong about a lot of stuff."
""
""
""
""
"LOL. When I looked at what I wanted to see from here in the next 3-4 years, it didn‚Äôt really match up with where we‚Äôre currently heading. Specifically, with our new focus on MPG  and [llm]"
""
"The Fly Machines platform is more or less finished, in the sense of being capable of supporting the next iteration of our products. My original desire to join Fly.io was to make Machines a product that would , and I feel like that‚Äôs been accomplished."
""
"More directly positioned as a cloud provider, rather than a platform-as-a-service; further along the customer journey from ‚Äúdevelopers‚Äù and ‚Äústartups‚Äù to large established companies."
"And, it‚Äôs not that I disagree with PAAS work or MPG! Rather, it‚Äôs not something that excites me in a way that I‚Äôd feel challenged and could continue to grow technically."
""
"Yes, my family was very involved in the decision, before I even talked to other companies."
"flyd"
"We‚Äôve enabled developers to run workloads from an OCI image and an API call all over the world. On any other cloud provider, the knowledge of how to pull that off comes with a professional certification."
"nomad-firecracker"
""
"flaps"
"Yes, all of it. The  API server, the  RPCs it calls, the  finite state machine system, the interface to running VMs."
""
"I like that it for the most part doesn‚Äôt require any central coordination. And I like that the P90 for Fly Machine  calls is sub-5-seconds for pretty much every region except for Johannesburg and Hong Kong."
"I think the FSM design is something I‚Äôm proud of; if I could take any code with me, it‚Äôd be the  in the  repo."
""
"flyd"
"I definitely didn‚Äôt have any specific design in mind when I started on . I think the FSM stuff is a result of work I did at Compose.io / MongoHQ (where it was called ‚Äúrecipes‚Äù/‚Äúoperations‚Äù) and the workd I did at HashiCorp using Cadence."
"Once I understood what the product needed to do and look like, having a way to perform deterministic and durable execution felt like a good design."
""
"is the child of AWS Step Functions and the predecessor to  (the company)."
"One of the biggest gains, with how it works in , is knowing we would need to deploy  all day, every day. If  was in the middle of doing some work, it needed to pick back up right where it left off, post-deploy."
""
"Probably ."
""
"If for no other reason than that we deployed , learned from it, and were able to make significant and valuable improvements ‚Äî and then migrate to the new system in a short period of time."
"Having a ‚Äújust SQLite‚Äù interface, for async replicated changes around the world in seconds, it‚Äôs pretty powerful."
"If we invested in  or TLA+ testing, I think there‚Äôs  to get value out of ."
""
"Yes."
""
"GraphQL. No, Elixir. It‚Äôs a tie between GraphQL and Elixir."
"But probably GraphQL, by a hair."
""
"GraphQL slows everyone down, and everything. Elixir only slows me down."
""
"I‚Äôm happier now that we have ."
""
"Before , there really wasn‚Äôt any contract between  and . And  was just ‚Äúwhatever we wanted  to be‚Äù. That limit its ability to serve us."
"Having  be an OCI-compliant runtime with an API for  to drive is  a big win for the future of the Fly Machines API."
"flyd"
"I still believe Bolt was the right choice. I‚Äôve never lost a second of sleep worried that someone is about to run a SQL update statement on a host, or across the whole fleet, and then mangled all our state data. And limiting the storage interface, by not using SQL, kept ‚Äòs scope managed."
"On the engine side of the platform, which is what  is, I still believe SQL is too powerful for what  does."
""
"Nah. But, I‚Äôd maybe consider a SQLite database per-Fly-Machine. Then the scope of danger is about as small as it could possibly be."
""
"Yeah, with per-Machine SQLite, once a Fly Machine is destroyed, we can just zip up the database and stash it in object storage. The biggest hold-up I have about it is how we‚Äôd manage the schemas."
""
"One hundred percent."
""
"Without oTel, it‚Äôd be a disaster trying to troubleshoot the system. I‚Äôd have ragequit trying."
""
"For sure. It is 100% part of the decision and the conversation. But: we didn‚Äôt have the best track record running a logs/metrics cluster at this fidelity. It was worth the money to pay someone else to manage tracing data."
""
"Yes, it‚Äôs very explicit. I think the next big part of oTel is going to be auto-instrumentation, for profiling."
""
""
"Option."
""
"Match is so much better than anything in Go."
""
"Three‚Äôs a crowd, Elixir can stay home."
""
"I‚Äôve learned its shortcomings and the productivity far outweighs having to deal with the Rust compiler."
"flaps"
"Correct."
""
"Maybe. If Ruby had a better concurrency story, I don‚Äôt think Elixir would have a place for us."
""
""
"It‚Äôs too easy to lose sight of whether your current focus [in what you‚Äôre building] is valuable to the company."
""
"I think it comes down to execution, and accountability to actually finish projects. I spun a lot trying to figure out what would be the most valuable work for Fly Machines."
""
"We struggle a lot with consistent communication. We change direction a little too often. It got to a point where I didn‚Äôt see a point in devoting time and effort into projects, because I‚Äôd not be able to show enough value quick enough."
""
""
"2022: ‚òÖ‚òÖ‚òÖ‚òÖ"
"2023: ‚òÖ‚òÖ"
"2024: ‚òÖ‚òÖ‚ú©"
"2025: ‚òÖ‚òÖ‚òÖ‚ú©"
"On a four-star scale."
""
"We hired too many people, too quickly, and didn‚Äôt have the guardrails and structure in place for everybody to be successful."
""
"Yes. That was my next comment."
""
"I think so."
""
"They were a killer distraction."
""
"I am going to be asleep all weekend if any of my previous job changes are indicative."
""
"Yes I will absolutely take all your future on-call shifts, you have convinced me."
""
"Thank you! I‚Äôm forever grateful for having the opportunity to be a part of Fly.io."
""
""
""
"is super interesting to me and, despite calling out that LLM-driven development agents like Cursor have something like a 40% success rate at actually building anything that passes acceptance criteria, makes me think that more of the future of our field belongs to people who figure out how to use this weird bags of model weights than any of us are comfortable with."
"I‚Äôve been dinking around with Cursor for a week now (if you haven‚Äôt, I think it‚Äôs something close to malpractice not to at least take it ‚Äî or something like it ‚Äî for a spin) and am just now from this post learning that Cursor has this ."
"The important thing for me is not how Cursor rules work, but rather how Huntley uses them. He turns them back on themselves, writing rules to tell Cursor how to organize the rules, and then teach Cursor how to write (under human supervision) its own rules."
"Cursor kept trying to get Huntley to use Bazel as a build system. So he had cursor write a rule for itself: ‚Äúno bazel‚Äù. And there was no more Bazel. If I‚Äôd known I could do this, I probably wouldn‚Äôt have bounced from the Elixir project I had Cursor doing, where trying to get it to write simple unit tests got it all tangled up trying to make  work."
"But I‚Äôm burying the lead."
"Security people have been for several years now somewhat in love with a tool called . Semgrep is a semantics-aware code search tool; using symbolic variable placeholders and otherwise ordinary code, you can write rules to match pretty much arbitary expressions and control flow."
"If you‚Äôre an appsec person, where you obviously go with this is: you build a library of Semgrep searches for well-known vulnerability patterns (or, if you‚Äôre like us at Fly.io, you work out how to get Semgrep to catch the Rust concurrency footgun of RWLocks inside if-lets)."
"The reality for most teams though is ‚Äúain‚Äôt nobody got time for that‚Äù."
"But I just checked and, unsurprisingly, 4o  at generating Semgrep rules? Like: I have no idea if this rule is actually any good. But it looks like a Semgrep rule?"
"What interests me is this: it seems obvious that we‚Äôre going to do more and more ‚Äúclosed-loop‚Äù LLM agent code generation stuff. By ‚Äúclosed loop‚Äù, I mean that the thingy that generates code is going to get to run the code and watch what happens when it‚Äôs interacted with. You‚Äôre just a small bit of glue code and a lot of system prompting away from building something like that right now:  a thingy that generates whole Elixir/Phoenix apps and runs them as Fly Machines. When you deploy these kinds of things, the LLM gets to see the errors when the code is run, and it can just go fix them. It also gets to see errors and exceptions in the logs when you hit a page on the app, and it can just go fix them."
"With a bit more system prompting, you can get an LLM to try to generalize out from exceptions it fixes and generate unit test coverage for them."
"With a little bit more system prompting, you can probably get an LLM to (1) generate a Semgrep rule for the generalized bug it caught, (2) test the Semgrep rule with a positive/negative control, (3) save the rule, (4) test the whole codebase with Semgrep for that rule, and (5) fix anything it finds that way."
"That is a lot more interesting to me than tediously (and probably badly) trying to predict everything that will go wrong in my codebase a priori and Semgrepping for them. Which is to say: Semgrep ‚Äî which I have always liked ‚Äî is maybe a lot more interesting now? And tools like it?"
""
""
""
"Over the last 5 years, we‚Äôve done pretty well for ourselves writing content for Hacker News. And that‚Äôs  been good for us. We don‚Äôt do conventional marketing, we don‚Äôt have a sales team, the rest of social media is atomized over 5 different sites. Writing pieces that HN takes seriously has been our primary outreach tool."
"There‚Äôs a recipe (probably several, but I know this one works) for charting a post on HN:"
"Write an EffortPost, which is to say a dense technical piece over 2000 words long; within that rubric there‚Äôs a bunch of things that are catnip to HN, including runnable code, research surveys, and explainers. (There are also cat-repellants you learn to steer clear of.)"
"I like this kind of writing. It‚Äôs not even a chore. But it‚Äôs become an impediment for us, for a couple reasons: the team serializes behind an ‚Äúeditorial‚Äù function here, which keeps us from publishing everything we want; worse, caring so much about our track record leaves us noodling on posts interminably (the poor  have been waiting for months for me to publish the piece I wrote about them and FoundationDB; take heart, this post today means that one is coming soon)."
"But worst of all, I worried incessantly about us . To my mind, we‚Äôd have 1, maybe 2 bites at the HN apple in a given month, and we needed to make them count."
"That was dumb. I am dumb about a lot of things! I came around to understanding this after Kurt demanded I publish my blog post about BFAAS (Bash Functions As A Service), 500 lines of Go code that had generated 4500 words in my draft. It was only after I made the decision to stop gatekeeping this blog that I realized  has been disproving my ‚Äúwearing out the welcome‚Äù theory, day in and day out, for years. He just writes stuff about LLMs when it interests him. I mean, it helps that he‚Äôs a better writer than we are. But he‚Äôs not wasting time choreographing things."
"Back in like 2009,  at another company I was at. That blog drove a lot of business for us (and, on three occasions, almost killed me). It was not in the least bit optimized for HN. I like pretending to be a magazine feature writer, but I miss writing dashed-off pieces every day and clearing space for other people on the team to write as well."
"So this is all just a heads up: we‚Äôre trying something new. This is a very long and self-indulgent way to say ‚Äúwe‚Äôre going to write a normal blog like it‚Äôs 2008‚Äù, but that‚Äôs how broken my brain is after years of having my primary dopaminergic rewards come from how long Fly.io blog posts stay on the front page: I have to disclaim blogging before we start doing it, lest I fail to meet expectations."
"Like I said. I‚Äôm real dumb. But: looking forward to getting a lot more stuff out on the web for people to read this year!"
""
"We‚Äôre interested in getting integrated into the flow VSCode uses to do remote editing over SSH, because everybody is using VSCode now, and, in particular, they‚Äôre using forks of VSCode that generate code with LLMs."
""
"LLM-generated code is  if you know what you‚Äôre doing. But it‚Äôs ultra-useful if you can close the loop between the LLM and the execution environment (with an ‚ÄúAgent‚Äù setup). There‚Äôs lots to say about this, but for the moment: it‚Äôs a semi-effective antidote to hallucination: the LLM generates the code, the agent scaffolding runs the code, the code generates errors, the agent feeds it back to the LLM, the process iterates."
"So, obviously, the issue here is you don‚Äôt want this iterative development process happening on your development laptop, because LLMs have boundary issues, and they‚Äôll iterate on your system configuration just as happily on the Git project you happen to be working in. A thing you‚Äôd really like to be able to do: run a closed-loop agent-y (‚Äúagentic‚Äù? is that what we say now) configuration for an LLM, on a clean-slate Linux instance that spins up instantly and that can‚Äôt screw you over in any way. You get where we‚Äôre going with this."
"Anyways! I would like to register a concern."
"Emacs hosts the spiritual forebearer of remote editing systems, a blob of hyper-useful Elisp called . If you can hook Tramp up to any kind of interactive environment ‚Äî usually, an SSH session ‚Äî where it can run Bourne shell commands, it can extend Emacs to that environment."
"So, VSCode has a feature like Tramp. Which, neat, right? You‚Äôd think, take Tramp, maybe simplify it a bit, switch out Elisp for Typescript."
"You‚Äôd think wrong!"
"Unlike Tramp, which lives off the land on the remote connection, VSCode mounts a full-scale invasion: it runs a Bash snippet stager that downloads an agent, including a binary installation of Node."
"I  this is ?"
"The agent runs over port-forwarded SSH. It establishes a WebSockets connection back to your running VSCode front-end. The underlying protocol on that connection can:"
"Wander around the filesystem"
"In security-world, there‚Äôs a name for tools that work this way. I won‚Äôt say it out loud, because that‚Äôs not fair to VSCode, but let‚Äôs just say the name is murid in nature."
"I would be a little nervous about letting people VSCode-remote-edit stuff on dev servers, and apoplectic if that happened during an incident on something in production."
"It turns out we don‚Äôt have to care about any of this to get a custom connection to a Fly Machine working in VSCode, so none of this matters in any kind of deep way, but: we‚Äôve decided to just be a blog again, so: we had to learn this, and now you do too."
""
""
""
"Let‚Äôs begin by introducing our cast of characters."
"is usually described as Elixir‚Äôs answer to . And that‚Äôs a good way to think about it. But Livebook takes full advantage of the Elixir platform, which makes it sneakily powerful. By linking up directly with Elixir app clusters, Livebook can switch easily between driving compute locally or on remote servers, and makes it easy to bring in any kind of data into reproducible workflows."
"is the Elixir‚Äôs answer to serverless computing. By having the library manage a pool of executors for you, FLAME lets you treat your entire application as if it was elastic and scale-to-zero. You configure FLAME with some basic information about where to run code and how many instances it‚Äôs allowed to run with, and then mark off any arbitrary section of code with . The framework takes care of the rest. It‚Äôs the upside of serverless without committing yourself to blowing your app apart into tiny, intricately connected pieces."
"The  is how you do Elixir-native AI and ML. Nx gives you an Elixir-native notion of tensor computations with GPU backends.  builds a common interface for ML models on top of it.  makes those models available to any Elixir app that wants to download them, from just a couple lines of code."
"Here is quick video showing how to transfer a local tensor to a remote GPU, using Livebook, FLAME, and Nx:"
"Let‚Äôs dive into the ."
""
"Any Livebook, including the one running on your laptop, can start a runtime running on a Fly Machine, in Fly.io‚Äôs public cloud. That Elixir machine will (by default) live in your default Fly.io organization, giving it networked access to all the other apps that might live there."
"This is an access control situation that mostly just does what you want it to do without asking. Unless you ask it to, Fly.io isn‚Äôt exposing anything to the Internet, or to other users of Fly.io. For instance: say we have a database we‚Äôre going to use to generate reports. It can hang out on our Fly organization, inside of a private network with no connectivity to the world. We can spin up a Livebook instance that can talk to it, without doing any network or infrastructure engineering to make that happen."
"But wait, there‚Äôs more. Because this is all Elixir, Livebook also allows you to connect to any running Erlang/Elixir application in your infrastructure to debug, introspect, and monitor them."
"Check out this clip of Chris McCord connecting  during the keynote:"
"Running a snippet of code from a laptop on a remote server is a neat trick, but Livebook is doing something deeper than that. It‚Äôs taking advantage of Erlang/Elixir‚Äôs native facility with cluster computation and making it available to the notebook. As a result, when we do things like auto-completing, Livebook delivers results from modules defined on the remote note itself. ü§Ø"
""
"When we first introduced FLAME, the example we used was video encoding."
"Video encoding is complicated and slow enough that you‚Äôd normally make arrangements to run it remotely or in a background job queue, or as a triggerable Lambda function. The point of FLAME is to get rid of all those steps, and give them over to the framework instead. So: we wrote our  calls inline like normal code, as if they were going to complete in microseconds, and wrapped them in  blocks. That was it, that was the demo."
"Here, we‚Äôre going to put a little AI spin on it."
"The first thing we‚Äôre doing here is driving FLAME pools from Livebook. Livebook will automatically synchronize your notebook dependencies as well as any module or code defined in your notebook across nodes. That means any code we write in our notebook can be dispatched transparently out to arbitrarily many compute nodes, without ceremony."
"Now let‚Äôs add some AI flair. We take an object store bucket full of video files. We use  to extract stills from the video at different moments. Then: we send them to , running on  (still locked to our organization), to get descriptions of the stills."
"All those stills and descriptions get streamed back to our notebook, in real time:"
"At the end, the descriptions are sent to , which builds a summary."
"Thanks to FLAME, we get explicit control over the minimum and the maximum amount of nodes you want running at once, as well their concurrency settings. As nodes finish processing each video, new ones are automatically sent to them, until the whole bucket has been traversed. Each node will automatically shut down after an idle timeout and the whole cluster terminates if you disconnect the Livebook runtime."
"Just like your app code, FLAME lets you take your notebook code designed to run locally, change almost nothing, and elastically execute it across ephemeral infrastructure."
""
"Next, Chris Grainger, CTO of , takes the stage."
"For work at Amplified, Chris wants to analyze a gigantic archive of patents, on behalf of a client doing edible cannibinoid work. To do that, he uses a BERT model (BERT, from Google, is one of the OG ‚Äútransformer‚Äù models, optimized for text comprehension)."
"To make the BERT model effective for this task, he‚Äôs going to do a hyperparameter training run."
"This is a much more complicated AI task than the Llama work we just showed up. Chris is going to generate a cluster of 64 GPU Fly Machines, each running an . On each of these nodes, he needs to:"
"setup its environment (including native dependencies and GPU bindings)"
"Here‚Äôs the clip. You‚Äôll see the results stream in, in real time, directly back to his Livebook. We‚Äôll wait, because it won‚Äôt take long to watch:"
""
"The suggestion of mixing Livebook and FLAME to elastically scale notebook execution was originally proposed by Chris Grainger during ElixirConf EU. During the next four months, Jonatan K≈Çosko, Chris McCord, and Jos√© Valim worked part-time on making it a reality in time for ElixirConf US. Our ability to deliver such a rich combination of features in such a short period of time is a testament to the capabilities of the Erlang Virtual Machine, which Elixir and Livebook runs on. Other features, such as , were implemented in a weekend.  Bringing the same functionality to other ecosystems would take several additional months, sometimes accompanied by millions in funding, and often times as part of a closed-source product."
"Furthermore, since we announced this feature,  stepped in and brought the same functionality to Kubernetes. From Livebook v0.14.1, you can start Livebook runtimes inside a Kubernetes cluster and also use FLAME to elastically scale them. Expect more features and news in this space!"
"Finally, Fly‚Äôs infrastructure played a key role in making it possible to start a cluster of GPUs in seconds rather than minutes, and all it requires is a Docker image. We‚Äôre looking forward to see how other technologies and notebook platforms can leverage Fly to also elevate their developer experiences."
""
""
""
""
"Public cloud billing is terrifying."
"The premise of a public cloud ‚Äî what sets it apart from a hosting provider ‚Äî is 8,760 hours/year of on-tap deployable compute, storage, and networking. Cloud resources are ‚Äúelastic‚Äù: they‚Äôre acquired and released as needed; in the ‚Äúcloud-iest‚Äù apps, without human intervention. Public cloud resources behave like utilities, and that‚Äôs how they‚Äôre priced."
"You probably can‚Äôt tell me how much electricity your home is using right now, and  may only come within tens of dollars of accurately predicting your water bill. But neither of those bills are all that scary, because you assume there‚Äôs a limit to how much you could run them up in a single billing interval."
"That‚Äôs not true of public clouds. There are only so many ways to ‚Äúspend‚Äù water at your home, but there are indeterminably many ways to land on a code path that grabs another VM, or to miskey a configuration, or to leak long-running CI/CD environments every time a PR gets merged. Pick a practitioner at random, and I bet they‚Äôve read a story within the last couple months about someone running up a galactic-scale bill at some provider or other."
""
"For people who don‚Äôt do a lot of cloud work, what all this means is that every PR push sets off a little alarm in the back of their heads: ‚Äúyou may have just incurred $200,000 of costs!‚Äù. The alarm is quickly silenced,  though it‚Äôs still subtly extracting a cortisol penalty. But by deadening the nerves that sense the danger of unexpected charges, those people are nudged closer to themselves being the next story on Twitter about an accidental $200,000 bill."
"The saving grace here, which you‚Äôll learn if you ever become that $200,000 story, is that nobody pays those bills."
"See, what cloud-savvy people know already is that providers have billing support teams, which spend a big chunk of their time conceding disputed bills. If you do something luridly stupid and rack up costs, AWS and GCP will probably cut you a break. We will too. Everyone does."
"If you didn‚Äôt already know this, you‚Äôre welcome; I‚Äôve made your life a little better, even if you don‚Äôt run things on Fly.io."
"But as soothing as it is to know you can get a break from cloud providers, the billing situation here is still a long ways away from ‚Äúgood‚Äù. If you accidentally add a zero to a scale count and don‚Äôt notice for several weeks, AWS or GCP will probably cut you a break. But they won‚Äôt  do it, and even though your odds are good, you‚Äôre still finding out at email- and phone-tag scale speeds. That‚Äôs not fun!"
""
"Charging you for stuff you didn‚Äôt want is bad business."
"Good business, we think, means making you so comfortable with your cloud you try new stuff. You, and everyone else on your team. Without a chaperone from the finance department."
"So we‚Äôre going to do the work to make this official. If you‚Äôre a customer of ours, we‚Äôre going to charge you in exacting detail for every resource you intentionally use of ours, but if something blows up and you get an unexpected bill, we‚Äôre going to let you off the hook."
""
"This is a Project, with a capital P. While we‚Äôre kind of kicking ourselves for not starting it earlier, there are reasons we couldn‚Äôt do it back in 2020."
"The Fully Automated Accident-Forgiving Billing System of the Future (which we are in fact building and may even one day ship) will give you a line-item veto on your invoice. We are a long ways away. The biggest reason is fraud."
"Sit back, close your eyes, and try to think about everything public clouds do to make your life harder. Chances are, most of those things are responses to fraud. Cloud platforms attract fraudsters like ants to an upturned ice cream cone. Thanks to the modern science of cryptography, fraudsters have had a 15 year head start on turning metered compute into picodollar-granular near-money assets."
"Since there‚Äôs no bouncer at the door checking IDs here, an open-ended and automated commitment to accident forgiveness is, with iron certainty, going to be used overwhelmingly in order to trick us into ‚Äúforgiving‚Äù cryptocurrency miners. We‚Äôre cloud platform engineers. They‚Äôre our primary pathogen."
"So, we‚Äôre going to roll this out incrementally."
""
""
"All the same subtextual, implied reassurances that every cloud provider offers remain in place at Fly.io. You are strictly better off after this announcement, we promise."
""
"Now: for customers that have a support contract with us, at any level, there‚Äôs something new: I‚Äôm saying the quiet part loud. The next time you see a bill with an unexpected charge on it, we‚Äôll refund that charge, (almost) no questions asked."
"That policy is so simple it feels anticlimactic to write. So, some additional color commentary:"
"We‚Äôre not advertising a limit to the number of times you can do this. If you‚Äôre a serious customer of ours, I promise that you cannot remotely fathom the fullness of our fellow-feeling. You‚Äôre not annoying us by getting us to refund unexpected charges. If you are growing a project on Fly.io, we will bend over backwards to keep you growing."
"How far can we take this? How simple can we keep this policy? We‚Äôre going to find out together."
"To begin with, and in the spirit of ‚Äúdoing things that won‚Äôt scale‚Äù, when we forgive a bill, what‚Äôs going to happen next is this: I‚Äôm going to set an irritating personal reminder for Kurt to look into what happened, now and then the day before your next bill, so we can see what‚Äôs going wrong. He‚Äôs going to hate that, which is the point: our best feature work is driven by Kurt-hate."
"Obviously, if you‚Äôre rubbing your hands together excitedly over the opportunity this policy presents, then, well, not so much with the fellow-feeling. We reserve the right to cut you off."
""
""
"We think this is a pretty good first step. But that‚Äôs all it is."
"We can do better than offering you easy refunds for mistaken deployments and botched CI/CD jobs. What‚Äôs better than getting a refund is never incurring the charge to begin with, and that‚Äôs the next step we‚Äôre working on."
""
"We built a new billing system so that we can do things like that. For instance: we‚Äôre in a position to catch sudden spikes in your month-over-month bills, flag them, and catch weird-looking deployments before we bill for them."
"Another thing we rebuilt billing for is . Already today you can get a steep discount from us reserving blocks of compute in advance. The trick to taking advantage of reserved pricing is confidently predicting a floor to your usage. For a lot of people, that means fighting feelings of loss aversion (nobody wants to get gym priced!). So another thing we can do in this same vein: catch opportunities to move customers to reserved blocks, and offer backdated reservations. We‚Äôll figure this out too."
"Someday, when we‚Äôre in a monopoly position, our founders have all been replaced by ruthless MBAs, and Kurt has retired to farm coffee beans in lower Montana, we may stop doing this stuff. But until that day this is the right choice for our business."
"Meanwhile: like every public cloud, we provision our own hardware, and we have excess capacity. Your messed-up CI/CD jobs didn‚Äôt really cost us anything, so if you didn‚Äôt really want them, they shouldn‚Äôt cost you anything either. Take us up on this! We love talking to you."
""
""
""
"We just lowered the prices on NVIDIA L40s GPUs to $1.25 per hour. Why? Because our feet are cold and we burn processor cycles for heat. But also other reasons."
"Let‚Äôs back up."
"We offer 4 different NVIDIA GPU models; in increasing order of performance, they‚Äôre the A10, the L40S, the 40G PCI A100, and the 80G SXM A100.  Guess which one is most popular."
"We guessed wrong, and spent a lot of time working out how to maximize the amount of GPU power we could deliver to a single Fly Machine. Users surprised us. By a wide margin, the most popular GPU in our inventory is the A10."
"The A10 is an older generation of NVIDIA GPU with fewer, slower cores and less memory. It‚Äôs the least capable GPU we offer. But that doesn‚Äôt matter, because it‚Äôs capable enough. It‚Äôs solid for random inference tasks, and handles mid-sized generative AI stuff like Mistral Nemo or Stable Diffusion. For those workloads, there‚Äôs not that much benefit in getting a beefier GPU."
"As a result, we can‚Äôt get new A10s in fast enough for our users."
"If there‚Äôs one thing we‚Äôve learned by talking to our customers over the last 4 years, it‚Äôs that y'all love a peek behind the curtain. So we‚Äôre going to let you in on a little secret about how a hardware provider like Fly.io formulates GPU strategy: none of us know what the hell we‚Äôre doing."
"If you had asked us in 2023 what the biggest GPU problem we could solve was, we‚Äôd have said ‚Äúselling fractional A100 slices‚Äù. We burned a whole quarter trying to get MIG, or at least vGPUs, working through IOMMU PCI passthrough on Fly Machines, in a project so cursed that Thomas has forsworn ever programming again. Then we went to market selling whole A100s, and for several more months it looked like the biggest problem we needed to solve was finding a secure way to expose NVLink-ganged A100 clusters to VMs so users could run training. Then H100s; can we find H100s anywhere? Maybe in a black market in Shenzhen?"
"And here we are, a year later, looking at the data, and the least sexy, least interesting GPU part in the catalog is where all the action is."
"With actual customer data to back up the hypothesis, here‚Äôs what we think is happening today:"
"Most users who want to plug GPU-accelerated AI workloads into fast networks are doing inference, not training."
"This is a thing we didn‚Äôt see coming, but should have: training workloads tend to look more like batch jobs, and inference tends to look more like transactions. Batch training jobs aren‚Äôt that sensitive to networking or even reliability. Live inference jobs responding to end-user HTTP requests are. So, given our pricing, of course the A10s are a sweet spot."
"The next step up in our lineup after the A10 is the L40S. The L40S is a nice piece of kit. We‚Äôre going to take a beat here and sell you on the L40S, because it‚Äôs kind of awesome."
"The L40S is an AI-optimized version of the L40, which is the data center version of the GeForce RTX 4090, resembling two 4090s stapled together."
"If you‚Äôre not a GPU hardware person, the RTX 4090 is a gaming GPU, the kind you‚Äôd play ray-traced Witcher 3 on. NVIDIA‚Äôs high-end gaming GPUs are actually reasonably good at AI workloads! But they suck in a data center rack: they chug power, they‚Äôre hard to cool, and they‚Äôre less dense. Also, NVIDIA can‚Äôt charge as much for them."
"Hence the L40: (much) more memory, less energy consumption, designed for a rack, not a tower case. Marked up for ‚Äúenterprise‚Äù."
"NVIDIA positioned the L40 as a kind of ‚Äúgraphics‚Äù AI GPU. Unlike the super high-end cards like the A100/H100, the L40 keeps all the rendering hardware, so it‚Äôs good for 3D graphics and video processing. Which is sort of what you‚Äôd expect from a ‚Äúprofessionalized‚Äù GeForce card."
"A funny thing happened in the middle of 2023, though: the market for ultra-high-end NVIDIA cards went absolutely batshit. The huge cards you‚Äôd gang up for training jobs got impossible to find, and NVIDIA became one of the most valuable companies in the world. Serious shops started working out plans to acquire groups of L40-type cards to work around the problem, whether or not they had graphics workloads."
"The only company in this space that does know what they‚Äôre doing is NVIDIA. Nobody has written a highly-ranked Reddit post about GPU workloads without NVIDIA noticing and creating a new SKU. So they launched the L40S, which is an L40 with AI workload compute performance comparable to that of the A100 (without us getting into the details of F32 vs. F16 models)."
"Long story short, the L40S is an A100-performer that we can price for A10 customers; the Volkswagen GTI of our lineup. We‚Äôre going to see if we can make that happen."
"We think the combination of just-right-sized inference GPUs and Tigris object storage is pretty killer:"
"model parameters, data sets, and compute are all close together"
"You should use L40S cards without thinking hard about it. So we‚Äôre making it official. You won‚Äôt pay us a dime extra to use one instead of an A10. Have at it! Revolutionize the industry. For $1.25 an hour."
"Here are things you can do with an L40S on Fly.io today:"
"You can run Llama 3.1 70B ‚Äî a big Llama ‚Äî for LLM jobs."
"It‚Äôs going to get chilly in Chicago in a month or so. Go light some cycles on fire!"
""
""
""
"At the heart of our platform is a systems design tradeoff about durable storage for applications.  When we added storage three years ago, to support stateful apps, we built it on attached NVMe drives. A benefit: a Fly App accessing a file on a Fly Volume is never more than a bus hop away from the data. A cost: a Fly App with an attached Volume is anchored to a particular worker physical."
""
"Before offering attached storage, our on-call runbook was almost as simple as ‚Äúde-bird that edge server‚Äù, ‚Äútell  to drain that worker‚Äù, and ‚Äúgo back to sleep‚Äù. NVMe cost us that drain operation, which terribly complicated the lives of our infra team. We‚Äôve spent the last year getting ‚Äúdrain‚Äù back. It‚Äôs one of the biggest engineering lifts we‚Äôve made, and if you didn‚Äôt notice, we lifted it cleanly."
""
"With stateless apps, draining a worker is easy. For each app instance running on the victim server, start a new instance elsewhere. Confirm it‚Äôs healthy, then kill the old one. Rinse, repeat. At our 2020 scale, we could drain a fully loaded worker in just a handful of minutes."
"You can see why this process won‚Äôt work for apps with attached volumes. Sure, create a new volume elsewhere on the fleet, and boot up a new Fly Machine attached to it. But the new volume is empty. The data‚Äôs still stuck on the original worker. We asked, and customers were not OK with this kind of migration."
"Of course, we back Volumes snapshots up (at an interval) to off-network storage. But for ‚Äúdrain‚Äù, restoring backups isn‚Äôt nearly good enough. No matter the backup interval, a ‚Äúrestore from backup migration"" will lose data, and a ‚Äúbackup and restore‚Äù migration  incurs untenable downtime."
"The next thought you have is, ‚ÄúOK, copy the volume over‚Äù. And, yes, of course you have to do that. But you can‚Äôt just , , and then  the old Fly Machine. Because the original Fly Machine is still alive and writing, you have to first, then , then ."
"Fly Volumes can get pretty big. Even to a rack buddy physical server, you‚Äôll hit a point where draining incurs minutes of interruption, especially if you‚Äôre moving lots of volumes simultaneously. , ,  is too slow."
""
""
", ,  loses data. , ,  takes too long. What we needed is a new operation: ."
"is a lazier, asynchronous . It creates a new volume elsewhere on our fleet, just like  would. But instead of blocking, waiting to transfer every byte from the original volume,  returns immediately, with a transfer running in the background."
"A new Fly Machine can be booted with that cloned volume attached. Its blocks are mostly empty. But that‚Äôs OK: when the new Fly Machine tries to read from it, the block storage system works out whether the block has been transferred. If it hasn‚Äôt, it‚Äôs fetched over the network from the original volume; this is called ‚Äúhydration‚Äù. Writes are even easier, and don‚Äôt hit the network at all."
", ,  is slow. But , ,  is fast; it can be made asymptotically as fast as stateless migration."
"There are three big moving pieces to this design."
"First, we have to rig up our OS storage system to make this  operation work."
""
"The Linux feature we need to make this work already exists; . Given an existing, readable storage device,  gives us a new device, of identical size, where reads of uninitialized blocks will pull from the original. It sounds terribly complicated, but it‚Äôs actually one of the simpler kernel lego bricks. Let‚Äôs demystify it."
"As far as Unix is concerned, random-access storage devices, be they spinning rust or NVMe drives, are all instances of the common class ‚Äúblock device‚Äù. A block device is addressed in fixed-size (say, 4KiB) chunks, and :"
""
"You can imagine designing a simple network protocol that supported all these options. It might have messages that looked something like:"
"Good news! The Linux block system is organized as if your computer was a network running a protocol that basically looks just like that. Here‚Äôs the message structure:"
""
""
"No nerd has ever looked at a fixed-format message like this without thinking about writing a proxy for it, and  is no exception. The proxy system in the Linux kernel for  is called , or DM."
"DM target devices can plug into other DM devices. For that matter, they can do whatever the hell else they want, as long as they honor the interface. It boils down to a  function, which can dispatch a , or drop it, or muck with it and ask the kernel to resubmit it."
"You can do a whole lot of stuff with this interface: carve a big device into a bunch of smaller ones (), make one big striped device out of a bunch of smaller ones (), do software RAID mirroring (), create snapshots of arbitrary existing devices (), cryptographically verify boot devices (), and a bunch more. Device Mapper is the kernel backend for the , which is how we do ."
"Which brings us to  : it‚Äôs a map function that boils down to:"
""
""
"takes, in addition to the source device to clone from, a ‚Äúmetadata‚Äù device on which is stored a bitmap of the status of all the blocks: either ‚Äúrehydrated‚Äù from the source, or not. That‚Äôs how it knows whether to fetch a block from the original device or the clone."
""
""
"Say we‚Äôve got  managing a Fly Machine with a volume on . We want it running on . Our whole fleet is meshed with WireGuard; everything can talk directly to everything else. So, conceptually:"
"on  stops the Fly Machine, and"
"For step (3) to work, the ‚Äúoriginal volume‚Äù on  has to be visible on , which means we need to mount it over the network."
""
"Take your pick of  protocols. iSCSI is the obvious one, but it‚Äôs relatively complicated, and Linux has native support for a much simpler one: , the ‚Äúnetwork block device‚Äù. You could implement an  server in an afternoon, on top of a file or a SQLite database or S3, and the Linux kernel could mount it as a drive."
"We started out using . But we kept getting stuck  kernel threads when there was any kind of network disruption. We‚Äôre a global public cloud; network disruption  happens. Honestly, we could have debugged our way through this. But it was simpler just to spike out an iSCSI implementation, observe that didn‚Äôt get jammed up when the network hiccuped, and move on."
""
"To drain a worker with minimal downtime and no lost data, we turn workers into a temporary SANs, serving the volumes we need to drain to fresh-booted replica Fly Machines on a bunch of ‚Äútarget‚Äù physicals. Those SANs ‚Äî combinations of , iSCSI, and  ‚Äî track the blocks copied from the origin, copying each one exactly once and cleaning up when the original volume has been fully copied."
"Problem solved!"
""
"When your problem domain is hard, anything you build whose design you can‚Äôt fit completely in your head is going to be a fiasco. Shorter form: ‚Äúif you see Raft consensus in a design, we‚Äôve done something wrong‚Äù."
"A virtue of this migration system is that, for as many moving pieces as it has, it fits in your head. What complexity it has is mostly shouldered by strategic bets we‚Äôve already  built teams around, most notably the  orchestrator. So we‚Äôve been running this system for the better part of a year without much drama. Not no drama, though. Some drama."
"Example: we encrypt volumes. Our key management is fussy. We do per-volume encryption keys that provision alongside the volumes themselves, so no one worker has a volume skeleton key."
"If you think ‚Äúmigrating those volume keys from worker to worker‚Äù is the problem I‚Äôm building up to, well, that too, but the bigger problem is ."
"Most people use just a small fraction of the volumes they allocate. A 100GiB volume with just 5MiB used wouldn‚Äôt be at all weird. You don‚Äôt want to spend minutes copying a volume that could have been fully hydrated in seconds."
"And indeed,  doesn‚Äôt want to do that either. Given a source block device (for us, an iSCSI mount) and the clone device, a  issued on the clone device will get picked up by , which will simply  of the relevant blocks by marking them as hydrated in the metadata volume. Simple enough."
"To make that work, we need the target worker to see the plaintext of the source volume (so that it can do an  ‚Äî don‚Äôt get us started on how annoying it is to sandbox this ‚Äî to read the filesystem, identify the unused block, and issue the  where  can see them) Easy enough."
""
"Except: two different workers, for cursed reasons, might be running different versions of , the userland bridge between LUKS2 and the . There are (or were) two different versions of cryptsetup on our network, and they default to different  ‚Äî 4MiB and 16MiB. Implying two different plaintext volume sizes."
"So now part of the migration FSM is an RPC call that carries metadata about the designed LUKS2 configuration for the target VM. Not something we expected to have to build, but, whatever."
""
"Gnarlier example: workers are the source of truth for information about the Fly Machines running on them. Migration knocks the legs out from under that constraint, which we were relying on in Corrosion, the SWIM-gossip SQLite database we use to connect Fly Machines to our request routing. Race conditions. Debugging. Design changes. Next!"
"Gnarliest example: our private networks. Recall: we automatically place every Fly Machine into ; by default, it‚Äôs the one all the other apps in your organization run in. This is super handy for setting up background services, databases, and clustered applications. 20 lines of eBPF code in our worker kernels keeps anybody from ‚Äúcrossing the streams‚Äù, sending packets from one private network to another."
""
"We call this scheme 6PN (for ‚ÄúIPv6 Private Network‚Äù). It functions by . This is, perhaps, gross. But it allows us to route diverse private networks with constantly changing membership across a global fleet of servers without running a distributed routing protocol. As the beardy wizards who kept the Internet backbone up and running on Cisco AGS+‚Äôs once said: the best routing protocol is ‚Äústatic‚Äù."
"Problem: the embedded routing information in a 6PN address refers in part to specific worker servers."
"That‚Äôs fine, right? They‚Äôre IPv6 addresses. Nobody uses literal IPv6 addresses. Nobody uses IP addresses at all; they use the DNS. When you migrate a host, just give it a new 6PN address, and update the DNS."
"Friends, somebody did use literal IPv6 addresses. It was us. In the configurations for Fly Postgres clusters."
""
"The obvious fix for this is not complicated; given  ssh access to a Fly Postgres cluster, it‚Äôs like a 30 second ninja edit. But we run a  of Fly Postgres clusters, and the change has to be coordinated carefully to avoid getting the cluster into a confused state.¬†We went as far as adding feature to our  to do network address mappings to keep old 6PN addresses reachable before biting the bullet and burning several weeks doing the direct configuration fix fleet-wide."
""
""
"We get asked a lot why we don‚Äôt do storage the ‚Äúobvious‚Äù way, with an  SAN fabric, abstracting it away from our compute. Locally-attached NVMe storage is an idiosyncratic choice, one we‚Äôve had to write disclaimers for (single-node clusters can lose data!) since we first launched it."
"One answer is: we‚Äôre a startup. Building SAN infrastructure in every region we operate in would be tremendously expensive. Look at any feature in AWS that normal people know the name of, like EC2, EBS, RDS, or S3 ‚Äî there‚Äôs a whole company in there. We launched storage when we were just 10 people, and even at our current size we probably have nothing resembling the resources EBS gets. AWS is pretty great!"
"But another thing to keep in mind is: we‚Äôre learning as we go. And so even if we had the means to do an EBS-style SAN, we might not build it today."
"Instead, we‚Äôre a lot more interested in log-structured virtual disks (LSVD). LSVD uses NVMe as a local cache, but durably persists writes in object storage. You get most of the performance benefit of bus-hop disk writes, along with unbounded storage and S3-grade reliability."
"; in the intervening year, something happened to make LSVD even more interesting to us:  launched S3-compatible object storage in every one our regions, so instead of backhauling updates to Northern Virginia, . We have more to say about LSVD, and a lot more to say about Tigris."
"Our first several months of migrations were done gingerly. By summer of 2024, we got to where our infra team can pull ‚Äúdrain this host‚Äù out of their toolbelt without much ceremony."
"We‚Äôre still not to the point where we‚Äôre migrating casually. Your Fly Machines are probably not getting migrated! There‚Äôd need to be a reason! But the dream is fully-automated luxury space migration, in which you might get migrated semiregularly, as our systems work not just to drain problematic hosts but to rebalance workloads regularly. No time soon. But we‚Äôll get there."
"This is the biggest thing our team has done since we replaced Nomad with flyd. Only the new billing system comes close. We did this thing not because it was easy, but because we thought it would be easy. It was not. But: worth it!"
""
""
""
"Let‚Äôs hypopulate you an app serving generative AI cat images based on the weather forecast, running on a  ECS task in AWS .  It‚Äôs going great; people didn‚Äôt realize how dependent their cat pic prefs are on barometric pressure, and you‚Äôre all anyone can talk about."
"Word reaches Australia and Europe, but you‚Äôre not catching on, because the‚Ä¶ latency is too high? Just roll with us here. Anyways: fixing this is going to require replicating  ECS tasks and ECR images into  and  while also setting up load balancing. Nah."
"This is the O.G. Fly.io deployment story; one deployed app, one versioned container, one command to get it running anywhere in the world."
"But you have a problem: your app relies on training data, it‚Äôs huge, your giant employer manages it, and it‚Äôs in S3. Getting this to work will require AWS credentials."
"You could ask your security team to create a user, give it permissions, and hand over the AWS keypair. Then you could wash your neck and wait for the blade. Passing around AWS keypairs is the beginning of every horror story told about cloud security, and  security team ain‚Äôt having it."
"There‚Äôs a better way. It‚Äôs drastically more secure, so your security people will at least hear you out. It‚Äôs also so much easier on Fly.io that you might never bother creating a IAM service account again."
""
"We‚Äôre going to use OIDC to set up strictly limited trust between AWS and Fly.io."
"In AWS: we‚Äôll add Fly.io as an  in AWS IAM, giving us an ID we can plug into any IAM ."
"Our machines will now magically have access to the S3 bucket."
""
"A reasonable question to ask here is, ‚Äúwhere‚Äôs the credential‚Äù? Ordinarily, to give a Fly Machine access to an AWS resource, you‚Äôd use  to add an  and  to the environment in the Machine. Here, we‚Äôre not setting any secrets at all; we‚Äôre just adding an ARN ‚Äî which is not a credential ‚Äî to the Machine."
"Here‚Äôs what‚Äôs happening."
"Fly.io operates an OIDC IdP at . It issues OIDC tokens, exclusively to Fly Machines. AWS can be configured to trust these tokens, on a role-by-role basis. That‚Äôs the ‚Äúsecret credential‚Äù: the pre-configured trust relationship in IAM, and the public keypairs it manages. You, the user, never need to deal with these keys directly; it all happens behind the scenes, between AWS and Fly.io."
"The key actor in this picture is , the AWS . ‚Äòs main job is to vend short-lived AWS credentials, usually through some variant of an API called . Specifically, in our case:  tells  to cough up an AWS keypair given an OIDC token (that matches a pre-configured trust relationship)."
"That still leaves the question: how does your code, which is reaching out to the AWS APIs to get cat weights, drive any of this?"
""
"Every Fly Machine boots up into an  we wrote in Rust. It has slowly been gathering features."
"One of those features, which has been around for awhile, is a server for a Unix socket at , which exports a subset of the Fly Machines API to privileged processes in the Machine. Think of it as our answer to the EC2 Instant Metadata Service. How it works is, every time we boot a Fly Machine, we pass it a  locked to that particular Machine; ‚Äôs server for  is a proxy that attaches that token to requests."
""
"What‚Äôs neat about this is that the credential that drives  is doubly protected:"
"The Fly.io platform won‚Äôt honor it unless it comes from that specific Fly Machine (, our orchestrator, knows who it‚Äôs talking to),"
"You could rig up a local privilege escalation vulnerability and work out how to steal the Macaroon, but you can‚Äôt exfiltrate it productively."
"So now you have half the puzzle worked out: OIDC is just part of the  (specifically: ). A Fly Machine can hit a Unix socket and get an OIDC token tailored to that machine:"
""
"Look upon this holy blob, sealed with a published key managed by Fly.io‚Äôs OIDC vault, and see that there lies within it enough information for AWS  to decide to issue a session credential."
"We have still not completed the puzzle, because while you can probably now see how you‚Äôd drive this process with a bunch of new code that you‚Äôd tediously write, you are acutely aware that you have not yet endured that tedium ‚Äî e pur si muove!"
"One  feature remains to be disclosed, and it‚Äôs cute."
"If, when  starts in a Fly Machine, it sees an  environment variable set, it initiates a little dance; it:"
"goes off and generates an OIDC token, the way we just described,"
"The AWS SDK, linked to your application, does all the rest."
"Let‚Äôs review: you add an  variable to your Fly App, launch a Machine, and have it go fetch a file from S3. What happens next is:"
"detects¬†¬†is set as an environment variable."
""
"It is a lot better."
""
"Most importantly: AWS  credentials are short-lived. Because they‚Äôre generated dynamically, rather than stored in a configuration file or environment variable, they‚Äôre already a little bit annoying for an attacker to recover. But they‚Äôre also dead in minutes. They have a sharply limited blast radius. They rotate themselves, and fail closed."
"They‚Äôre also easier to manage. This is a rare instance where you can reasonably drive the entire AWS side of the process from within the web console. Your cloud team adds  all the time; this is just a  with an extra snippet of JSON. The resulting ARN isn‚Äôt even a secret; your cloud team could just email or Slack message it back to you."
"Finally, they offer finer-grained control."
"To understand the last part, let‚Äôs look at that extra snippet of JSON (the ‚ÄúTrust Policy‚Äù) your cloud team is sticking on the new  :"
""
""
"Recall the OIDC token we dumped earlier; much of what‚Äôs in it, we can match in the Trust Policy. Every OIDC token Fly.io generates is going to have a  field formatted , so we can lock IAM  down to organizations, or to specific Fly Apps, or even specific Fly Machine instances."
""
"In case it‚Äôs not obvious: this pattern works for any AWS API, not just S3."
"Our OIDC support on the platform and in Fly Machines will set arbitrary OIDC  strings, so you can use it to authenticate to any OIDC-compliant cloud provider. It won‚Äôt be as slick on Azure or GCP, because we haven‚Äôt done the  features to light their APIs up with a single environment variable ‚Äî but those features are easy, and we‚Äôre just waiting for people to tell us what they need."
"For us, the gold standard for least-privilege, conditional access tokens remains Macaroons, and it‚Äôs unlikely that we‚Äôre going to do a bunch of internal stuff using OIDC. We even snuck Macaroons into this feature. But the security you‚Äôre getting from this OIDC dance closes a lot of the gap between hardcoded user credentials and Macaroons, and it‚Äôs easy to use ‚Äî easier, in some ways, than it is to manage role-based access inside of a legacy EC2 deployment!"
""
""
""
"Picture this, if you will."
"You‚Äôre blind. You‚Äôre in an unfamiliar hotel room on a trip to Chicago."
""
"You‚Äôve absent-mindedly set your coffee down, and can‚Äôt remember where. You‚Äôre looking for the thermostat so you don‚Äôt wake up frozen. Or, just maybe, you‚Äôre playing a fun-filled round of ‚Äúfind the damn light switch so your sighted partner can get some sleep already!‚Äù"
"If, like me, you‚Äôve been blind for a while, you have plenty of practice finding things without the luxury of a quick glance around. It may be more tedious than you‚Äôd like, but you‚Äôll get it done."
"But the speed of innovation in machine learning and large language models has been dizzying, and in 2024 you can snap a photo with your phone and have an app like  or  tell you where in that picture it found your missing coffee mug, or where it thinks the light switch is."
""
"This is . It‚Äôs hard for me to state just how exciting and empowering AI image descriptions have been for me without sounding like a shill. In the past year, I‚Äôve:"
"Found shit in strange hotel rooms."
"I‚Äôve been consistently blown away at how impressive and helpful AI-created image descriptions have been."
"Also‚Ä¶"
""
"As a blind internet user for the last three decades, I have extensive empirical evidence to corroborate what you already know in your heart: humans are pretty flaky about writing useful alt text for all the images they publish. This does tend to make large swaths of the internet inaccessible to me!"
"In just a few years, the state of image description on the internet has gone from complete reliance on the aforementioned lovable, but ultimately tragically flawed, humans, to automated strings of words like , to LLM-generated text that reads a lot like it was written by a person, perhaps sipping from a steaming cup of Earl Grey as they reflect on their previous experiences of a background that features a tree with snow on its branches, suggesting that this scene takes place during winter."
"If an image is missing alt text, or if you want a second opinion, there are screen-reader addons, like  for , that you can use with an API key to get image descriptions from GPT-4 or Google Gemini as you read. This is awesome!"
"And this brings me to the nerd snipe. How hard would it be to build an image description service we can host ourselves, using open source technologies? It turns out to be spookily easy."
"Here‚Äôs what I came up with:"
"to run the model"
"The idea is to keep it modular and hackable, so if sentiment analysis or joke creation is your thing, you can swap out image description for that and have something going in, like, a weekend."
"If you‚Äôre like me, and you go skipping through recipe blogs to find the ‚Äúgo directly to recipe‚Äù link, find the code itself ."
""
"An API to accept images and prompts, run the model, and spit 
out answers sounds like a lot! But it‚Äôs the simplest part of this whole thing, because: 
that‚Äôs ."
"You can just run the Ollama Docker image, get it to grab the model 
you want to use, and that‚Äôs it. There‚Äôs your AI server. (We have a  
all about deploying Ollama on Fly.io; Fly GPUs are rad, try'em out, etc.)."
"For this project, we need a model that can make sense‚Äîor at least words‚Äîout of a picture. 
 is a trained, Apache-licensed ‚Äúlarge multimodal model‚Äù that fits the bill. 
Get the model with the Ollama CLI:"
""
""
""
"I want user auth to make sure just anyone can‚Äôt grab my ‚Äúimage description service‚Äù and keep it busy generating short stories about their cat. If I build this out into a service for others to use, I might also want business logic around plans or
credits, or mobile-friendly APIs for use in the field.  provides a scaffolding for all of it. It‚Äôs a Swiss army knife: a Firebase-like API on top of SQLite, complete with authentication, authorization, an admin UI, extensibility in JavaScript and Go, and various client-side APIs."
""
"I ‚Äúfaked‚Äù a task-specific API that supports followup questions by extending PocketBase in Go, modeling requests and responses as  (i.e. SQLite tables) with  to trigger pre-set interactions with the Ollama app (via ) and the client (via the PocketBase API)."
"If you‚Äôre following along, 
that handles all that, along with initializing the LLM connection."
"In a nutshell, this is the dance:"
"When a user uploads an image, a hook on the  collection sends the image to Ollama, along with this prompt:"
"This is a super simple hack to handle followup questions, and it‚Äôll let you keep adding followups until 
something breaks. You‚Äôll see the quality of responses get poorer‚Äîpossibly incoherent‚Äîas the context 
exceeds the context window."
"I also set up  in PocketBase,
ensuring that users can‚Äôt read to and write from others‚Äô chats with the AI."
"If image descriptions aren‚Äôt your thing, this business logic is easily swappable 
for joke generation, extracting details from text, any other simple task you 
might want to throw at an LLM. Just slot the best model into Ollama (LLaVA is pretty OK as a general starting point too), and match the PocketBase schema and pre-set prompts to your application."
""
"With the image description service in place, the user can talk to it with any client that speaks the PocketBase API. PocketBase already has SDK clients in JavaScript and Dart, but because my screen reader is , I went with a . That way I can build this out into an NVDA add-on 
if I want to."
"If you‚Äôre a fancy Python developer, you probably have your preferred tooling for
handling virtualenvs and friends. I‚Äôm not, and since my screen reader doesn‚Äôt use those
anyway, I just ed the library so my client can import it:"
""
"is a very simple script. 
It expects a couple of things: a file called , located in the current directory, 
and environment variables to provide the service URL and user credentials to log into it with."
"When you run the client script, it uploads the image to the user‚Äôs  collection on the 
backend app, starting the back-and-forth between user and model we saw in the previous section. 
The client prints the model‚Äôs output to the CLI and prompts the user to input a followup question, 
which it passes up to the  collection, and so on."
""
""
"I grabbed 
and saved it to a file called ."
"While I knew I was downloading an image of a winter scene, all I see on Unsplash is:"
"brown trees beside river under blue sky during daytime Bright winter landscape
with lake, snow, forest, beautiful blue sky and white clouds. An example of
charming wildlife in Russia."
"Let‚Äôs see what our very own AI describer thinks of this picture:"
""
"Is it a stellar description? Maybe not, but it certainly gives me a better sense of connection with the scene."
"Let‚Äôs see how our describer copes with a followup question."
""
"Boo, the general-purpose LLaVA model couldn‚Äôt identify the leafless trees. At least it knows why it can‚Äôt. Maybe there‚Äôs a better model out 
there for that. Or we could train one, if we really needed tree identification! We could make every component of 
this service more sophisticated!"
"But that I, personally, can make a proof of concept like this with a few days of effort
continues to boggle my mind. Thanks to a handful of amazing open source projects, it‚Äôs really, spookily, easy. And from here, I (or you) can build out a screen-reader addon, or a mobile app, or a different kind of AI service, with modular changes."
""
"On Fly.io, stopping GPU Machines saves you a bunch of money and some carbon footprint, in return for cold-start latency when you make a request for the first time in more than a few minutes. In testing this project, on the  Fly Machine preset, the 34b-parameter LLaVA model took several seconds to generate each response. If the Machine was stopped when the request came in, starting it up took another handful of seconds, followed by several tens of seconds to load the model into GPU RAM. The total time from cold start to completed description was about 45 seconds. Just something to keep in mind."
"If you‚Äôre running Ollama in the cloud, you likely want to put the model onto storage that‚Äôs persistent, so you don‚Äôt have to download it repeatedly. You could also build the model into a Docker image ahead of deployment."
"The PocketBase Golang app compiles to a single executable that you can run wherever.
I run it on Fly.io, unsurprisingly, and the  comes with a Dockerfile and a  config file, which you can edit to point at your own Ollama instance. It uses a small persistent storage volume for the SQLite database. Under testing, it runs fine on a  Machine."
""
""
""
"One of many odd decisions we‚Äôve made at Fly.io is how we use WireGuard. It‚Äôs not just that we use it in many places where other shops would use HTTPS and REST APIs. We‚Äôve gone a step beyond that: every time you run , our lovable, sprawling CLI, it conjures a TCP/IP stack out of thin air, with its own IPv6 address, and speaks directly to Fly Machines running on our networks."
"There are plusses and minuses to this approach, which we talked about . Some things, like remote-operated Docker builders, get easier to express (a Fly Machine, as far as  is concerned, might as well be on the same LAN). But everything generally gets trickier to keep running reliably."
"It was a decision. We own it."
"Anyways, we‚Äôve made some improvements recently, and I‚Äôd like to talk about them."
""
"Until a few weeks ago, our gateways ran on a pretty simple system."
"We operate dozens of ‚Äúgateway‚Äù servers around the world, whose sole purpose is to accept incoming WireGuard connections and connect them to the appropriate private networks."
"I copy-pasted those last two bullet points from , because when it works, it does  reasonably well. (We ultimately did end up defaulting everybody to WireGuard-over-WebSockets, though.)"
"But if it always worked, we wouldn‚Äôt be here, would we?"
"We ran into two annoying problems:"
"One: NATS is fast, but doesn‚Äôt guarantee delivery. Back in 2022, Fly.io was pretty big on NATS internally. We‚Äôve moved away from it. For instance, our  used to be driven by NATS; today, it‚Äôs HTTP.  Our NATS cluster was losing too many messages to host a reliable API on it. Scaling back our use of NATS made WireGuard gateways better, but still not great."
"Two: When  exits, the WireGuard peer it created sticks around on the gateway. Nothing cleans up old peers. After all, you‚Äôre likely going to come back tomorrow and deploy a new version of your app, or  into it to debug something. Why remove a peer just to re-add it the next day?"
"Unfortunately, the vast majority of peers are created by  in CI jobs, which don‚Äôt have persistent storage and can‚Äôt reconnect to the same peer the next run; they generate new peers every time, no matter what."
"So, we ended up with a not-reliable-enough provisioning system, and gateways with hundreds of thousands of peers that will never be used again. The high stale peer count made kernel WireGuard operations very slow - especially loading all the peers back into the kernel after a gateway server reboot - as well as some kernel panics."
"There had to be"
""
"Storing bajillions of WireGuard peers is no big challenge for any serious n-tier RDBMS. This isn‚Äôt ‚Äúbig data‚Äù. The problem we have at Fly.io is that our gateways don‚Äôt have serious n-tier RDBMSs. They‚Äôre small. Scrappy. They live off the land."
"Seriously, though: you could store every WireGuard peer everybody has ever used at Fly.io in a single SQLite database, easily.  What you can‚Äôt do is store them all in the Linux kernel."
"So, at some point, as you push more and more peer configurations to a gateway, you have to start making decisions about which peers you‚Äôll enable in the kernel, and which you won‚Äôt."
"Wouldn‚Äôt it be nice if we just didn‚Äôt have this problem? What if, instead of pushing configs to gateways, we had the gateways pull them from our API on demand?"
"If you did that, peers would only have to be added to the kernel when the client wanted to connect. You could yeet them out of the kernel any time you wanted; the next time the client connected, they‚Äôd just get pulled again, and everything would work fine."
"The problem you quickly run into to build this design is that Linux kernel WireGuard doesn‚Äôt have a feature for installing peers on demand. However:"
""
"The Linux kernel‚Äôs  is  (which is basically a way to create a userland socket to talk to a kernel service). Here‚Äôs a . Note that there‚Äôs no API call to subscribe for ‚Äúincoming connection attempt‚Äù events."
"That‚Äôs OK! We can just make our own events. WireGuard connection requests are packets, and they‚Äôre easily identifiable, so we can efficiently snatch them with a BPF filter and a ."
""
"We own the daemon code for that, and can just hook the packet receive function to snarf WireGuard packets."
"It‚Äôs not obvious, but WireGuard doesn‚Äôt have notions of ‚Äúclient‚Äù or ‚Äúserver‚Äù. It‚Äôs a pure point-to-point protocol; peers connect to each other when they have traffic to send. The first peer to connect is called the , and the peer it connects to is the ."
""
"For Fly.io,  is typically our initiator,  sending a single UDP packet to the gateway, which is the responder. According , this first packet is a .  It gets better: the packet type is recorded in a single plaintext byte. So this simple BPF filter catches all the incoming connections: ."
"In most other protocols, we‚Äôd be done at this point; we‚Äôd just scrape the username or whatnot out of the packet, go fetch the matching configuration, and install it in the kernel. With WireGuard, not so fast. WireGuard is based on Trevor Perrin‚Äôs , and Noise goes way out of its way to  during handshakes. To identify incoming requests, we‚Äôll need to run enough Noise cryptography to decrypt the identity."
"The code to do this is fussy, but it‚Äôs relatively short (about 200 lines). Helpfully, the kernel Netlink interface will give a privileged process the private key for an interface, so the secrets we need to unwrap WireGuard are easy to get. Then it‚Äôs just a matter of running the first bit of the Noise handshake. If you‚Äôre that kind of nerdy,"
"At this point, we have the event feed we wanted: the public keys of every user trying to make a WireGuard connection to our gateways. We keep a rate-limited cache in SQLite, and when we see new peers, we‚Äôll make an internal HTTP API request to fetch the matching peer information and install it. This fits nicely into the little daemon that already runs on our gateways to manage WireGuard, and allows us to ruthlessly and recklessly remove stale peers with a  job."
"But wait! There‚Äôs more! We bounced this plan off Jason Donenfeld, and he tipped us off on a sneaky feature of the Linux WireGuard Netlink interface."
""
"Our API fetch for new peers is generally not going to be fast enough to respond to the first handshake initiation message a new client sends us. That‚Äôs OK; WireGuard is pretty fast about retrying. But we can do better."
"When we get an incoming initiation message, we have the 4-tuple address of the desired connection, including the ephemeral source port  is using. We can install the peer as if we‚Äôre the initiator, and  is the responder. The Linux kernel will initiate a WireGuard connection back to . This works; the protocol doesn‚Äôt care a whole lot who‚Äôs the server and who‚Äôs the client. We get new connections established about as fast as they can possibly be installed."
""
""
"We‚Äôve been running this in production for a few weeks and we‚Äôre feeling pretty happy about it. We went from thousands, or hundreds of thousands, of stale WireGuard peers on a gateway to what rounds to none. Gateways now hold a lot less state, are faster at setting up peers, and can be rebooted without having to wait for many unused peers to be loaded back into the kernel."
"I‚Äôll leave you with this happy Grafana chart from the day of the switchover."
"Despite our tearful protests, Lillian has decided to move on from Fly.io to explore new pursuits. We wish her much success and happiness!¬†‚ú®"
""
""
""
"Fly Kubernetes is the ‚Äúblessed path""‚Ñ¢Ô∏è to using Kubernetes backed by Fly.io infrastructure. Or, in simpler terms, it is our managed Kubernetes service. We take care of the complexity of operating the Kubernetes control plane, leaving you with the unfettered joy of deploying your Kubernetes workloads. If you love Fly.io and K8s, this product is for you."
""
"So how did this all come to be‚Äîand what even is a Kubernete?"
""
"If you wade through all the YAML and , what‚Äôs left is an API for declaring workloads and how it should be accessed."
"But that‚Äôs not what people usually talk / groan about. It‚Äôs everything else that comes along with adopting Kubernetes: a container runtime (CRI), networking between workloads (CNI) which leads to DNS (CoreDNS). Then you layer on Prometheus for metrics and whatever the logging daemon du jour is at the time. Now you get to debate which Ingress‚Äîstrike that‚Äî API to deploy and if the next thing is anything to do with a Service Mess, then as they like to say where I live, ""bless your heart‚Äù."
"Finally, there‚Äôs capacity planning. You‚Äôve got to pick and choose where, how and what the  will look like in order to configure and run the workloads."
"When we began thinking about what a Fly Kubernetes Service could look like, we started from first principles, as we do with most everything here. The best way we can describe it is the . As he‚Äôs looking at the knowledge left behind by those that came before, he starts to imagine something entirely different and more capable than could have been accomplished previously. That‚Äôs what happened to JP, but with K3s and Virtual Kubelet."
""
"We looked at what people need to get started‚Äîthe API‚Äîand then started peeling away all the noise, filling in the gaps to connect things together to provide the power. Here‚Äôs how this looks currently:"
"Containerd/CRI ‚Üí  + Firecracker + : our system transmogrifies Docker containers into Firecracker microVMs"
"Now‚Ä¶not everything is a one-to-one comparison, and we explicitly did not set out to support any and every configuration. We aren‚Äôt dealing with resources like Network Policy and init containers, though we‚Äôre also not completely ignoring them. By mapping many of the core primitives of Kubernetes to a Fly.io resource, we‚Äôre able to focus on continuing to build the primitives that make our cloud better for workloads of all shapes and sizes."
"A key thing to notice above is that there‚Äôs no ‚ÄúNode‚Äù."
"plays a central role in FKS. It‚Äôs magic, really. A Virtual Kubelet acts as if it‚Äôs a standard Kubelet running on a Node, eager to run your workloads. However, there‚Äôs no Node backing it. It instead behaves like an API, receiving requests from Kubernetes and transforming them into requests to deploy on a cloud compute service. In our case, that‚Äôs Fly Machines."
"So what we have is Kubernetes calling out to our , a small Golang program we run alongside K3s, to create and run your pod. It creates , via the , deploying it to any underlying host within that region. This shifts the burden of managing hardware capacity from you to us. We think that‚Äôs a cool trick‚Äîthanks, Virtual Kubelet magic!"
""
"You can deploy your workloads (including GPUs) across any of our available regions using the Kubernetes API."
"You create a cluster with :"
""
"When a cluster is created, it has the standard  namespace. You can inspect it:"
""
""
"The  label shows the name of the Fly App that corresponds to your cluster."
"It would seem appropriate to deploy the  here, but since your pods are connected over an , we‚Äôre going to use a  with support for ."
""
"And you can see its Machine representation via:"
""
""
"This is important! Your pod is a Fly Machine! While we don‚Äôt yet support all kubectl features, Fly.io tooling will ‚Äújust work‚Äù for cases where we don‚Äôt yet support the kubectl way. So, for example, we don‚Äôt have  and , but you can use flyctl to forward ports and get a shell into a pod."
"Expose it to your internal network using the standard ClusterIP Service:"
""
"ClusterIP Services work natively, and Fly.io internal DNS supports them. Within the cluster, CoreDNS works too."
"Access this Service locally via : Get connected to your org‚Äôs . Get kubectl to describe the  Service:"
""
""
"You can pull out the Service‚Äôs IP address from the above output, and get at the KUARD UI using that: in this case, ."
"Using internal DNS: . Or, in our example: ."
"And finally CoreDNS:  resolves to the  IP and is routable within the cluster."
""
""
"The Fly Kubernetes Service is free during the beta. Fly Machines and Fly Volumes you create with it will cost the . It‚Äôll be  after that, plus the cost of the other resources you create."
""
"Today, Fly Kubernetes supports only a portion of the Kubernetes API. You can deploy pods using Deployments/ReplicaSets. Pods are able to communicate via Services using the standard K8s DNS format. Ephemeral and persistent volumes are supported."
"The most notable absences are: multi-container pods, StatefulSets, network policies, horizontal pod autoscaling and emptyDir volumes. We‚Äôre working at supporting autoscaling and emptyDir volumes in the coming weeks and multi-container pods in the coming months."
"If you‚Äôve made it this far and are eagerly awaiting your chance to tell us and the rest of the internet ‚Äúthis isn‚Äôt Kubernetes!‚Äù, well, we agree! It‚Äôs not something we take lightly. We‚Äôre still building, and conformance tests may be in the future for FKS. We‚Äôve made a deliberate decision to only care about fast launching VMs as the one and only way to run workloads on our cloud. And we also know enough of our customers would like to use the Kubernetes API to create a fast launching VM in the form of a Pod, and that‚Äôs where this story begins."
""
""
""
"There are three hard things in computer science:"
"Cache invalidation"
"Of all the annoying software problems that have no business being annoying, handling a file upload in a full-stack application stands apart, a universal if tractable malady, the plantar fasciitis of programming."
"Now, the actual act of clients placing files on servers is straightforward. Your framework      . What‚Äôs hard is making sure that uploads stick around to be downloaded later."
""
"Enter object storage, a pattern you may know by its colloquial name ‚ÄúS3‚Äù. Object storage occupies a funny place in software architecture, somewhere between a database and a filesystem. It‚Äôs like , but for cloud storage instead of program memory."
"‚Äîerr, object storage ‚Äî is so important that it was the second AWS service ever introduced (EC2 was not the first!). Everybody wants it. We know, because they keep asking us for it."
"So why didn‚Äôt we build it?"
"Because we couldn‚Äôt figure out a way to improve on S3. And we still haven‚Äôt! But someone else did, at least for the kinds of applications we see on Fly.io."
""
"S3 checks all the boxes. It‚Äôs trivial to use. It‚Äôs efficient and cost-effective. It has redundancies that would make a DoD contractor blush. It integrates with archival services like Glacier. And every framework supports it. At some point, the IETF should just take a deep sigh and write an S3 API RFC, XML signatures and all."
"There‚Äôs at least one catch, though."
"Back in, like, ‚Äò07 people ran all their apps from a single city. S3 was designed to work for those kinds of apps. The data, the bytes on the disks (or whatever weird hyperputer AWS stores S3 bytes on), live in one place. A specific place. In a specific data center. As powerful and inspiring as The Architects are, they are mortals, and must obey the laws of physics."
"This observation feels banal, until you realize how apps have changed in the last decade. Apps and their users don‚Äôt live in one specific place. They live all over the world. When users are close to the S3 data center, things are amazing! But things get less amazing the further away you get from the data center, and even less amazing the smaller and more frequent your reads and writes are."
"(Thought experiment: you have to pick one place in the world to route all your file storage. Where is it? Is it ?)"
"So, for many modern apps, you end up having to , so that people close to the data get it from a region-specific bucket. Doing that pulls in CDN-caching things that complicated your application and put barriers between you and your data. Before you know it, you‚Äôre wearing custom orthotics on your, uh, developer feet. ()"
""
"Personally, I know this happens. Because I had to build one! I run a  that‚Äôs a caching proxy for S3 in six continents across the world. All so that I can deliver images and video efficiently for the readers of my blog."
""
"What if data was really global? For some applications, it might not matter much. But for others, it matters a lot. When a sandwich lover in Australia snaps a picture of a , the people most likely to want to see that photo are also in Australia. Routing those uploads and downloads through one building in Ashburn is no way to build a sandwich reviewing empire."
"Localizing all the data sounds like a hard problem. What if you didn‚Äôt need to change anything on your end to accomplish it?"
""
"Building a miniature CDN infrastructure just to handle file uploads seems like the kind of thing that could take a week or so of tinkering. The Fly.io unified theory of cloud development is that solutions are completely viable for full-stack developers only when they take less than 2 hours to get working."
"AWS agrees, which is why they have a SKU for it, , which will, at some variably metered expense, optimize the read side of a single-write-region bucket: they‚Äôll set up  for you. You can probably get S3 and Cloudfront working within 2 hours, especially if you‚Äôve set it up before."
"Our friends at Tigris have this problem down to single-digit minutes, and what they came up with is a lot cooler than a cache CDN."
"Here‚Äôs how it works. Tigris runs redundant FoundationDB clusters in our regions to track objects. They use Fly.io‚Äôs NVMe volumes as a first level of cached raw byte store, and a queuing system modelled on  to distribute object data to multiple replicas, to regions where the data is in demand, and to 3rd party object stores‚Ä¶ like S3."
"If your objects are less than about 128 kilobytes, Tigris makes them instantly global. By default! Things are just snappy, all over the world, automatically, because they‚Äôve done all the work."
"But it gets better, because Tigris is also much more flexible than a cache simple CDN. It‚Äôs globally distributed from the jump, with inter-region routing baked into its distribution layer. Tigris isn‚Äôt a CDN, but rather a toolset that you can use to build arbitrary CDNs, with consistency guarantees, instant purge and relay regions."
"There‚Äôs a lot going on in this architecture, and it‚Äôd be fun to dig into it more. But for now, you don‚Äôt have to understand any of it. Because Tigris ties all this stuff together with an S3-compatible object storage API. If your framework can talk to S3, it can use Tigris."
""
"To get started with this, run the  command:"
""
"All you have to do is fill in a bucket name. Hit enter. All of the configuration for the AWS S3 library will be injected into your application for you. And you don‚Äôt even need to change the libraries that you‚Äôre using.  all use the AWS libraries to put and delete objects into Tigris using the same calls that you use for S3."
"I know how this looks for a lot of you. It looks like we‚Äôre partnering with Tigris because we‚Äôre chicken, and we didn‚Äôt want to build something like this. Well, guess what: you‚Äôre right!"
"Compute and networking: those are things we love and understand. Object storage? , and it wasn‚Äôt nearly as slick as Tigris."
"Object storage is important. It needs to be good. We did not want to half-ass it. So we partnered with Tigris, so that they can put their full resources into making object storage as ‚ú®magical‚ú® as Fly.io is."
"This also mirrors a lot of the Unix philosophy of Days Gone Past, you have individual parts that do one thing very well that are then chained together to create a composite result. I mean, come on, would you seriously want to buy your servers the same place you buy your shoes?"
""
"Well, okay, the main reason why you would want to do that is because having everything under one bill makes it really easy for your accounting people. So, to make one bill for your computer, your block storage, your databases, your networking, and your object storage, we‚Äôve wrapped everything under one bill. You don‚Äôt have to create separate accounts with Supabase or Upstash or PlanetScale or Tigris. Everything gets charged to your Fly.io bill and you pay one bill per month."
""
"This is our Valentine‚Äôs Day gift to you all. Object storage that just works. Stay tuned because we have a couple exciting features that build on top of the integration of Fly.io and Tigris that allow really unique things, such as truly global static website hosting and turning your bucket into a CDN in 5 minutes at most."
"Here‚Äôs to many more happy developer days to come."
""
""
""
"GPUs are now available to everyone!"
"We know you‚Äôve been excited about wanting to use GPUs on Fly.io and we‚Äôre happy to announce that they‚Äôre available for everyone. If you want, you can spin up GPU instances with any of the following cards:"
"Ampere A100 (40GB)"
"To use a GPU instance today, change the  for one of your apps or processes to any of the above GPU kinds. Here‚Äôs how you can spin up an  server in seconds:"
""
"Deploy this and bam, large language model inferencing from anywhere. If you want a private setup, see the article  for more information. You never know when you have a sandwich emergency and don‚Äôt know what you can make with what you have on hand."
"We are working on getting some lower-cost A10 GPUs in the next few weeks. We‚Äôll update you when they‚Äôre ready."
"If you want to explore the possibilities of GPUs on Fly.io, here‚Äôs a few articles that may give you ideas:"
""
"Depending on factors such as your organization‚Äôs age and payment history, you may need to go through additional verification steps."
"If you‚Äôve been experimenting with Fly.io GPUs and have made something cool, let us know on the  or by mentioning us ! We‚Äôll boost the cool ones."
""
""
""
"Serverless is great because is has good ergonomics - when an event is received, a ‚Äúnot-server‚Äù boots quickly, code is run, and then everything is torn down. We‚Äôre billed only on usage."
"It turns out that Fly.io shares many of  as serverless. Can we do a serverless on Fly.io? ü¶Ü Well, if it‚Äôs quacking like a duck, let‚Äôs call it a mallard."
"Here‚Äôs a useful pattern for triggering our own not-servers with Fly Machines."
""
"I want to make Machines do some work based on my own events. Fly.io can already  based on HTTP, so let‚Äôs concentrate on non-HTTP events."
"The process of running evented Machines involves:"
"Listening for events"
"To do this, I made a project and named it  because reasons.
You can consider this project ‚Äúreference architecture‚Äù in the same way you call a toddler‚Äôs scribbling ‚Äúart‚Äù."
"The goal is to run some of our code on a fresh not-server when an event is received. We want this done efficiently - a Machine should only exist long enough to process an event or 3."
"Lambdo does just that - it receives some events, and spins up Fly Machines with those events placed  the VMs. Once the code finishes, the Machine is destroyed."
""
""
"For our purposes, an event is just a JSON object. ."
"We want to turn events into compute, so we need some sort of event system. I decided to use a queue."
""
"The first thing I needed was a place to send events! I chose to use SQS, which let me continue to pretend servers don‚Äôt exist."
"It‚Äôs no surprise then that the first part of this project is ."
"When the polling returns some non-zero number of events, it collects the SQS messages‚Äô JSON strings (and some meta data), resulting in an array of objects (a list of events)."
"Then we send these events to some Machines."
""
"Fly Machines are fast-booting Micro-VM‚Äôs, controlled by an ."
"A feature of that API is the ability to  on a new Machine. This is how we‚Äôll get our events into the Machine."
"When Lambdo creates a Machine, it places a file at . Our code just needs to read that file and parse the JSON."
""
"Part of the ergonomics of Serverless is (usually) being limited to running just a function. Fly.io doesn‚Äôt really care what you run, which is to our advantage. We can choose to write discreet functions per event, or we can bring our whole  to bear."
"How do we package up our code? The real answer is ‚Äúhowever you want!‚Äù, but here‚Äôs 2 ideas."
""
"You can just use your existing code base. This is especially easy if you‚Äôre already deploying apps to Fly.io."
"All we‚Äôd need to do is add some additional code - a command perhaps (, , whatever) - that sucks in that JSON, iterates over the events, and does some stuff."
""
"When we create an event, we‚Äôll tell Lambdo how to run your code - more on that later."
""
"This project also provides some ‚Äúruntimes‚Äù (base images). This is a bit more ‚Äútraditional serverless‚Äù, were you provide a function to run."
"Lambdo contains  right now - Node and PHP. There could be more, of course, but you know‚Ä¶lazy."
"The Node runtime ¬†that will read the JSON payload file   (again, just an array of JSON events), and call a user-supplied JS function once per event."
"An¬†¬†- our code just needs to export a function that does stuff to the given event:"
""
"The¬†¬†is the same idea, a user-supplied handler looks like this:"
""
"Explore the  directory of the project to see how that‚Äôs put together."
""
"Since our events are sent via SQS queue, it would be helpful to see an example SQS message. Remember how I mentioned the SQS message has some meta data?"
"Here‚Äôs an example, with said meta data:"
""
"The Body field of the SQS message is assumed to be a JSON string (it‚Äôs the event itself, and its contents are arbitrary - whatever makes sense for you)."
"The message Attributes contains the meta data - up to 3 important details:"
": The image to run (it might be a Docker Hub image, or something you pushed to registry.fly.io). This is ."
"‚Ä†You can get valid values for the¬†¬†option by running¬†."
"‚Ä†‚Ä†It‚Äôs an array form, e.g. , you may need to do some escaping of double quotes if you‚Äôre sending messages to SQS via terminal."
""
"Fly.io isn‚Äôt serverless, but it has all these primitives that add up to serverless. You have events, Fly.io has fast-booting VM‚Äôs. They just make sense together!"
"What we did here is use . Our code can process those events any way we want."
"What I like about this approach is how flexible it can be. We can choose the base image to use and the server type (even using GPU-enabled Machines) .
Since we have full control over the Machine VM‚Äôs responding to the events, we can do whatever we want inside of them. Pretty neat!"
""
""
""
"There are many ways to delegate work in web applications, from using background workers to serverless architecture. In this article, we explore a new machine pattern that takes advantage of Fly Machines and distinct process groups to make quick work of resource-intensive tasks."
""
"Let‚Äôs say you‚Äôre building a web application that has a few tasks that demand a hefty amount of memory or CPU juice. Resizing images, for example, can require a shocking amount of memory, but you might not need that much memory  of the time, for handling most of your web requests. Why pay for all that horsepower when you don‚Äôt need it most of the time?"
"What if there‚Äôs a different way to delegate these resource-intensive tasks?"
""
"What if you could simply delegate these types of tasks to a more powerful machine  when necessary? Let‚Äôs build an example of this method in a sample app. We‚Äôll be using Next.js today, but this pattern is framework (and language) agnostic."
"Here‚Äôs how it will work:"
"A request hits an endpoint that does some resource-intensive tasks"
"To demonstrate this task-delegation pattern, we‚Äôre going to start with a single-page application that looks like this:"
"Our ‚ÄúOpen Pickle Jar‚Äù app is quite simple: you provide the width and height and it goes off and resizes some high-resolution photos to those dimensions (exciting!)."
"If you‚Äôd like to follow along, you can clone the  branch of this repository:  . The final changes are visible on the  branch. This app uses S3 for image storage, so you‚Äôll need to create a bucket called  and provide ,  , and   as environment variables."
"This task is really just a stand-in for any HTTP request that kicks off a resource-intensive task. Get the request from the user, delegate it to a more powerful machine, and then return the result to the user. It‚Äôs what happens when you can‚Äôt open a pickle jar, and you ask for someone to help."
"Before we start, let‚Äôs define some terms and what they mean on Fly.io:"
"Extremely fast-booting VMs. They can exist in different regions and even run different processes."
""
"Here‚Äôs what we‚Äôll need for our application:"
"A  that performs our resource-intensive task"
"In short, this is what our architecture will look like, a standard web and worker duo."
""
"Next.js has two distinct routing patterns: Pages and App router. We‚Äôll use the App router in our example since it‚Äôs the preferred method moving forward."
"Under your  directory, create a new folder called  containing a  ."
"(We‚Äôre using TypeScript here, but feel free to use normal JavaScript if you prefer!)"
""
"Inside  we‚Äôll flesh out our endpoint:"
""
"The function  that we‚Äôre importing contains our resource-intensive task, which in this case is extracting images from a  file, resizing them all to the new dimensions, and returning the new image URLs."
"The  function is how one define routes for specific HTTP methods in Next.js, and ours implements a function   that accepts the path of the current endpoint () our resource-intensive function, and the same request parameters. This function doesn‚Äôt yet exist, so let‚Äôs build that next!"
""
"Now that we‚Äôve set up our endpoint, let‚Äôs flesh out the wrapper function that delegates our request to a more powerful machine."
"We haven‚Äôt defined our process groups just yet, but if you recall, the plan is to have two:"
"- Our standard web server"
"Here‚Äôs what we want this wrapper function to do:"
"If the current machine is a  , proceed to execute the resource-intensive task"
"Inside your  directory, create a file called  with the following content:"
""
"In our  section, you‚Äôll notice that while developing locally (aka, when  is ) we define the hostname of our  process to be . Typically Next.js apps run on port , so while testing our app locally, we can have two instances of our process running in different terminal shells:"
"- This will run on  and will act as our local  process"
"Also, if you‚Äôre wondering about the  and  constants, these are  available on all apps."
""
"Now, when this code is running in production (aka  is NOT ) you‚Äôll see that we‚Äôre using a unique hostname to access our  Machine."
"Apps belonging to the same organization on Fly.io are provided a number of . These  addresses let you point to different Apps and Machines in your private network. For example:"
"‚Äì To reach app instances in a particular region, like"
"Since our  process group is running the same process as our  process (in our case, ), we‚Äôll also need to make sure we use the same internal port ()."
""
"The last thing to do will be to define our two process groups and their respective Machine specs. We‚Äôll do this by editing our  configuration."
"If you don‚Äôt have this file, go ahead and create a blank one and use the content below, but replace  with your app‚Äôs name, as well as your preferred .  If you don‚Äôt know what region you‚Äôd like to deploy to, ."
"Note that deploying this example app will spin up  machines. Please feel free to alter the Machine () specs listed here to ones that suit your budget or app‚Äôs needs."
""
"And that‚Äôs it! With our  finished, we‚Äôre ready to deploy our app!"
""
"Today we built a machine pattern on top of Fly.io. This pattern allows us to have a lighter request server that can delegate certain tasks to a stronger server, meaning that we can have one Machine do all the heavy lifting that could block everything else while the other handles all the simple tasks for users. With this in mind, this is a fairly na√Øve implementation, and we can make this much better:"
""
"In its current state, our code isn‚Äôt very resilient to failed requests. For this reason, you may want to consider keeping track of jobs in a queue with Redis (similar to Sidekiq in Ruby-land). When you have work you want to do, put it in the queue. Your queue worker would have to write the result somewhere (e.g., in Redis) that the application could fetch when it‚Äôs ready."
""
"The benefit of this pattern is that you can limit how many ‚Äúbeefy‚Äù Machines you need to have available at any given time. Our demo app doesn‚Äôt dictate how many  Machines to have at any given time, but by adding timeouts you could elect to start and stop them as needed."
"Now, you may think that constantly starting and stopping Machines might incur higher response times, but note that we are NOT talking about creating/destroying Machines. Starting and stopping Machines only takes as long as it takes to start your web server (i.e. ). The best part is that  . Stopped Machines will still be much cheaper than running ones."
""
"This ‚Äúdelegate to a beefy machine‚Äù pattern is similar to serverless functions with platforms like AWS Lambda. The main difference is that serverless functions usually require you to segment your application into a bunch of small pieces, whereas the method discussed today just uses the app framework that you deploy to production. Each pattern has its own benefits and downsides."
""
"The pattern outlined here is one more tool in your arsenal for scaling applications. By utilizing Fly.io‚Äôs private network and  domains, it‚Äôs quick and easy to pass work between different processes that run our app. If you‚Äôd like to learn about more methods for scaling tasks in your applications, check out  by Chris McCord and  by Sam Ruby."
""
""
""
""
""
"Let‚Äôs implement an API token together. It‚Äôs a design called ‚ÄúMacaroons‚Äù, but don‚Äôt get hung up on that yet."
"First some . Then:"
""
""
"We‚Äôre going to build a minimally-stateful bearer token, a blob signed with HMAC. Nothing fancy so far.  for a decade and a half."
"There‚Äôs a , which encode all the data you‚Äôd need to check any request accompanied by that token ‚Äì without a database lookup. Stateless tokens have some nice properties, and some less-nice. Our tokens won‚Äôt be stateless: they carry a user ID, with which we‚Äôll look up the HMAC key to verify it. But they‚Äôll stake out a sort of middle ground."
""
"Let‚Äôs add some stuff."
"The meat of our tokens will be a series of claims we call ‚Äúcaveats‚Äù. We call them that because each claim restricts further what the token authorizes. After , this token only allows operations that happen underneath the  directory. Then, after , it allows only reads, not writes."
"(I guess we‚Äôre building a file sharing system. Whatever.)"
"Some important things about things about this design. First: by implication from the fact that caveats further restrict tokens, a token with no caveats restricts nothing. It‚Äôs a god-mode token. Don‚Äôt honor it."
""
"Second: the rule of checking caveats is very simple: every single caveat must pass, evaluating  against the request that carries it, in isolation and without reference to any other caveat. If any caveat evaluates , the request fails. In that way, we ensure that adding caveats to a token can only ever weaken it."
"With that in mind, take a closer look at this code:"
""
"Every caveat is HMAC-signed independently, which is weird. Weirder still, the key for that HMAC is the output of the last HMAC. The caveats chain together, and the HMAC of the last caveat becomes the ‚Äútail‚Äù of the token."
"Creating a new blank token for a particular user requires a key that the server (and probably only the server) knows. But adding a caveat doesn‚Äôt! Anybody can add a caveat. In our design, you, the user, can edit your own API token."
""
"For completeness, and to make a point, there‚Äôs the verification code. Look up the original secret key from the user ID,  and then it‚Äôs chained HMAC all the way down. The point I‚Äôm making is that Macaroons are very simple."
""
"Back in 2014, Google published  introducing ‚ÄúMacaroons‚Äù, a new kind of cookie. Since then, they‚Äôve become a sort of hipster shibboleth. But they‚Äôre more talked about than implemented, which is a nice way to say that practically nobody uses them."
"Until now! I dragged Fly.io into implementing them. Suckers!"
"We had a problem: our API tokens were much too powerful. We needed to scope them down and let them express roles, and I scoped up that project to replace OAuth2 tokens altogether. We now have what I think is one of the more expansive Macaroon implementations on the Internet."
"I dragged us into using Macaroons because I wanted us to use a hipster token format. Google designed Macaroons for a bigger reason: they hoped to replace browser cookies with something much more powerful."
"The problem with simple bearer tokens, like browser cookies or JWTs, is that they‚Äôre prone to being stolen and replayed by attackers."
""
"Worse, a stolen token is usually a game-over condition. In most schemes, a bearer token is an all-access pass for the associated user. For some applications this isn‚Äôt that big a deal, but then, . A banking app token that authorizes arbitrary transactions is a recipe for having a small heart attack on every HTTP request."
""
"Macaroons are user-editable tokens that enable JIT-generated least-privilege tokens. With minimal ceremony and no additional API requests, a banking app Macaroon lets you authorize a request with a caveat like, I don‚Äôt know, . I mean, something way better than that, probably lots of caveats, not just one, but you get the idea: a token so minimized you feel safe sending it with your request. Ideally, a token that only authorizes that single, intended request."
""
"That‚Äôs not why we like Macaroons. We already assume our tokens aren‚Äôt being stolen."
"In most systems, the developers come up with a permissions system, and you‚Äôre stuck with it. We run a public cloud platform, and people want a lot of different things from our permissions. The dream is, we (the low-level platform developers on the team) design a single permission system, one time, and go about our jobs never thinking about this problem again."
"Instead of thinking of all of our ‚Äúroles‚Äù in advance, we just model our platform with caveats:"
"Users belong to ."
""
"Simplistic. But it expresses admin tokens:"
""
"And it expresses normal user tokens:"
""
"And also an auditor-only token for that user:"
""
""
"Or a deployment-only token, for a CI/CD system:"
""
"Those are just the roles we came up with. Users can invent others. The important thing is that they don‚Äôt have to bother me about them."
""
"Astute readers will have noticed by now that we haven‚Äôt shown any code that actually evaluates a caveat. That‚Äôs because it‚Äôs boring, and I‚Äôm too lazy to write it out. Got an  token for  that allows ? Ok; check and make sure the incoming request is for an asset of , and that it‚Äôs a . Whatever code you came up with, it‚Äôd be fine."
"These straightforward restrictions are called ‚Äúfirst party caveats‚Äù. The first party is us, the platform. We‚Äôve got all the information we need to check them."
"Let‚Äôs kit out our token format some more."
""
"Up till now, we‚Äôve gotten by with nothing but HMAC, which is one of the great charms of the design. Now we need to encrypt. There‚Äôs no authenticated encryption in the Python standard library, but that won‚Äôt stop us."
"With ‚Äúthird-party‚Äù caveats comes a cast of characters. We‚Äôre still the first party. You‚Äôll play the second party. The third party is any other system in the world that you trust: an SSO system, an audit log, a revocation checker, whatever."
"Here‚Äôs the trick of the third-party caveat: our platform doesn‚Äôt know what your caveat means, and it doesn‚Äôt have to. Instead, when you see a third-party caveat in your token, you tear a ticket off it and exchange it for a ‚Äúdischarge Macaroon‚Äù with that third party. You submit both Macaroons together to us."
"Let‚Äôs attenuate our token with a third-party caveat hooking it up to a ‚Äúcanary‚Äù service that generates a notice approximately any time the token is used."
"To build that canary caveat, you first make a  that users of the token will hand to your canary, and then a  that Fly.io will use to verify discharges your checker spits out. The ticket and the challenge are both encrypted. The ticket is encrypted under , so your service can read it. The challenge is encrypted under the previous Macaroon tail, so only Fly.io can read it. Both hide yet another key, the random HMAC key  (‚Äúcaveat root key‚Äù)."
"In addition to , the ticket contains a message, which says whatever you want it to; Fly.io doesn‚Äôt care. Typically, the message describes some kind of additional checking you want your service to perform before spitting out a discharge token."
""
"To authorize a request with a token that includes a third-party caveat for the canary service, you need to get your hands on a corresponding discharge Macaroon. Normally, you do that by ing the ticket from the caveat to the service."
"Discharging is simple. The service, which holds , uses it to decrypt the ticket. It checks the message and makes some decisions. Finally, it mints a new macaroon, using , recovered from the ticket, as the root key. The ticket itself is the nonce."
"If it wants, the third-party service can slap on a bunch of first-party caveats of its own. When we verify the Macaroon, we‚Äôll copy those caveats out and enforce them. Attenuation of a third-party discharge macaroon works like a normal macaroon."
""
"To verify tokens that have third-party caveats, start with the root Macaroon, walking the caveats like usual. At each third-party caveat, match the  from the caveat with the  on the discharge Macaroon. The key for root Macaroon decrypts the  in the caveat, recovering , which cryptographically verifies the discharge."
"(The Macaroons paper uses different terms: ‚Äúcaveat identifier‚Äù or  for ‚Äúticket‚Äù, and ‚Äúverification-key identifier‚Äù or  for ‚Äúchallenge‚Äù. These names are self-evidently bad and our contribution to the state of the art is to replace them.)"
"There‚Äôs two big applications for third-party caveats in Popular Macaroon Thought. First, they facilitate microservice-izing your auth logic, because you can stitch arbitrary policies together out of third-party caveats. And, they seem like : Okta and Google could stand up SSO dischargers, for instance, or someone can do a really good revocation service."
"Neither of these light us up. We‚Äôre allergic to microservices. As for public protocols, well, it‚Äôs good to want things. So we almost didn‚Äôt even implement third-party caveats."
""
"I‚Äôm glad we did though, because they‚Äôve been pretty great."
"The first problem third-party caveats solved for us was hazmat tokens. To the extent possible, we want Macaroon tokens to be safe to transmit between users. Our Macaroons express permissions, but not authentication, so it‚Äôs almost safe to email them."
"The way it works is, our Macaroons all have a third-party caveat pointing to a ‚Äúlogin service‚Äù, either identifying the proper bearer as a particular Fly.io user or as a member of some . To allow a request with your token, you first need to collect the discharge from the login service, which requires authentication."
"The login discharge is very sensitive, but there isn‚Äôt much reason to pass it around. The original permissions token is where all the interesting stuff is, and it‚Äôs not scary. So that‚Äôs nice."
"Ben then came up with  If your token has one of those caveats, when you run , a browser will pop up to log you into your SSO IdP (if you haven‚Äôt done so recently already)."
"We‚Äôve put a , but that work has mostly been invisible to customers. But Macaroon-ized SSO has a subtle benefit: you can configure  to automatically add SSO requirements to specific  (so, for instance, a dev environment might not need SSO at all, and prod might need two)."
"SSO requirements in most applications are a brittle pain in the ass. Ours are flexible and straightforward, and that happened almost by accident. Macaroons, baby!"
"Here‚Äôs a fun thing you can do with a Macaroon system: stand up a Slack bot, and give it an HTTP  handler that accepts third-party tickets. Then:"
"So, the bot is cute, but any platform could do that. What‚Äôs cool is the way our platform  work with Slack; in fact, nothing on our platform knows anything about Slack, and Slack doesn‚Äôt know anything about us. We didn‚Äôt reach out to a Slack endpoint. Everything was purely cryptographic."
"That bot could, if I sunk some time into it, enforce arbitrary rules: it could selectively add caveats for the requests it authorizes, based on lookups of the users requesting them, at specific times of day, with specific logging. Theoretically, it could add third-party caveats of its own."
"The win for us for third-party caveats is that they create a plugin system for our security tokens. That‚Äôs an unusual place to see a plugin interface! But Macaroons are easy to understand and keep in your head, so we‚Äôre pretty confident about the security issues."
""
"Obviously, we didn‚Äôt write our Macaroon code in Python, or with HMAC-SHA256-CTR."
"We landed on a primary implementation Golang (Ben subsequently wrote an Elixir implementation). Our hash is SHA256, our cipher is Chapoly. We encode in MsgPack."
""
"The big strength of Macaroons as a cryptographic design ‚Äî that it‚Äôs based almost entirely on HMAC ‚Äî makes it a challenge to deploy. If you can verify a Macaroon, you can generate one.  We have thousands of servers. They can‚Äôt all be allowed to generate tokens."
"What we did instead:"
"We split token checking into ‚Äúverification‚Äù of token HMAC tags and ‚Äúclearing‚Äù of token caveats."
"Now buckle up, because I‚Äôm about to try to get you to care about service tokens."
"We operate ‚Äúworker servers‚Äù all over the world to host apps for our customers. To do that, those workers need access to customer secrets, like the key to decrypt a customer volume. To retrieve those secrets, the workers have to talk to secrets management servers."
"We manage a lot of workers. We trust them. But we don‚Äôt trust them that much, if you get my drift. You don‚Äôt want to just leave it up to the servers to decide which secrets they can access. The blast radius of a problem with a single worker should be no greater than the apps that are supposed to run there."
"The gold standard for approving access to customer information is, naturally, explicit customer authorization. We almost have that with Macaroons! The first time an app runs on a worker,  has a token, and it can pass that along to the secret stores."
"The problem is, you need that token more than once; not just when the user does a deploy, but potentially any time you restart the app or migrate it to a new worker. And you can‚Äôt just store and replay user Macaroons. They have expirations."
""
"So our token verification service exposes an API that transforms a user token into a ‚Äúservice token‚Äù, which is just the token with the authentication caveat and expiration ‚Äústripped off‚Äù."
"What‚Äôs cool is: components that receive service tokens can attenuate them. For instance, we could lock a token to a particular worker, or even a particular Fly Machine. Then we can expose the whole  to customer VMs while keeping access traceable to specific customer tokens. Stealing the token from a Fly Machine doesn‚Äôt help you since it‚Äôs locked to that Fly Machine by a caveat attackers can‚Äôt strip."
""
"If a customer loses their tokens to an attacker, we can‚Äôt just blow that off and let the attacker keep compromising the account!"
""
"Every Macaroon we issue is identified by a unique nonce, and we can revoke tokens by that nonce. This is just a basic function of the token verification service we just described."
"We host token caches all over our fleet. Token revocation invalidates the caches. Anything with a cache checks frequently whether to invalidate. Revocation is rare, so just keeping a revocation list and invalidating caches wholesale seems fine."
""
"I get it, it‚Äôs tough to get me to shut up about Macaroons."
"A couple years ago, I , from JWTs (never!) to Biscuits. I had a , not all of it positive, and said we‚Äôd be plowing forward with them at Fly.io."
"My plan had been to follow up soon after with a deep dive on Macaroons as we planned them for Fly.io. I‚Äôm glad I didn‚Äôt do that, not just because it would‚Äôve been embarrassing to announce a feature that took us over 2 years to launch, but also because the process of working on this with Ben Toews changed a lot of my thinking about them."
"I think if you asked Ben, he‚Äôd say he had mixed feelings about how much complexity we wrangled to get this launched. On the other hand: we got a lot of things out of them without trying very hard:"
"Security tokens you can (almost) email to your users and partners without putting your account at risk."
"There are downsides and warts! I‚Äôm mostly not telling you about them! Pure restrictive caveats are an awkward way to express some roles. And, blinded by my hunger to get Macaroons deployed, I spat in the face of science and used internal database IDs as our public caveat format, an act for which JP will never forgive me."
"If i‚Äôve piqued your interest, , along with some more ."
""
""
"Hello all, and welcome to another episode of How I Fly, a series where I interview developers about what they do with technology, what they find exciting, and the unexpected things they‚Äôve learned along the way. This time I‚Äôm talking with , an investment partner at A16Z who‚Äôs also an open-source AI developer. She works on some of the most exciting AI projects in the world. I‚Äôm excited to share them with you today, with fun stories about the lessons she‚Äôs learned along the way."
""
"One of Yoko‚Äôs most thought-provoking experiments is , a virtual town populated by AI agents that talk with each other. It takes advantage of the randomness of AI responses to create emergent behavior. When you open it, it looks like this:"
"You can see the AI agents talking with each other and watch how the relationships between them form and change over time. It‚Äôs also a lot of fun to watch."
"One of Yoko‚Äôs other experiments is , a  virtual pet implemented with a large language model instead of the state machine that we‚Äôre all used to. AI Tamago uses an unmodified version of LLaMA 2 7B to take in game state and user inputs, then it generates what happens next. Every time you interact with your pet, it feeds data to LLaMA 2 and then uses Ollama‚Äôs JSON mode to generate unexpected output."
"It‚Äôs all the fun of the classic Tamagochi toys from the 90‚Äôs (including the ability to randomly discipline your virtual pet) without any of the coin cell batteries or having to carry around the little egg-shaped puck."
"But that‚Äôs just something you can watch, not something that‚Äôs as easy to play with on your own machine. Yoko has also worked on the  that lets you go from zero to AI in minutes. It‚Äôs a collection of chains of models that let you ingest a bunch of documents, store them in a database, and then use those documents as context for a language model to generate responses. It‚Äôs everything you need to implement a ‚Äúchat with a knowledge base‚Äù feature."
""
"The Local AI Starter Kit is significant because normally to do this, you need to set up billing and API keys for at least four different API providers, and then you need to write a bunch of (hopefully robust) code to tie it all together. With the Local AI Starter Kit, you can do this on your own hardware, with your own data, and your own models privately. It‚Äôs a huge step forward for democratizing access to this technology."
"Document search is one of my favorite usecases for AI, and it‚Äôs one of the most immediately useful ones. It‚Äôs also one of the most fiddly and annoying to get right. To help illustrate this, I‚Äôve made a diagram of the steps involved with setting up document search by hand:"
"You start with your Markdown documents. Most Markdown documents are easily broken up into sections where each section will focus on a single aspect of the larger topic of the document. You can take advantage of this best practice by letting people search for each section individually, which is typically a lot more useful than just searching the entire document."
""
"Essentially, the vector embeddings that you generate from an embedding model are a mathematical representation of the ‚Äúconcepts‚Äù that the embedding model uses that are adjacent to the text of your documents. When you use the same model to generate embeddings for your documents and user queries, this lets you find documents that are similar to the query, but not precisely the same exact words. This is called ‚Äúfuzzy searching‚Äù and it is one of the most difficult problems in computer science (right next to naming things)."
"When a user comes to search the database, you do the same thing as ingestion:"
"The user query comes into your API endpoint. You use the same embedding model from earlier (omitted from the diagram for brevity) to turn that query into a vector. Then you query the same vector database to find documents that are similar to the query. Then you have a list of documents with metadata like the URL to the documentation page or section fragment in that page. From here you have two options. You can either use the documents to return a list of results to the user, or you can do the more fun thing: using those documents as context for a large language model to generate a response grounded in the relevant facts in those documents."
""
"This basic pattern is called Retrieval-augmented Generation (RAG), and it‚Äôs how Bing‚Äôs copilot chatbot works. The Local AI Starter Kit makes setting this pipeline up  and . It‚Äôs a huge step forward for making this groundbreaking technology accessible to everyone."
""
"When I was trying to get the AI models in AI Town to output JSON, I tried a bunch of different things. I got some good results by telling the model to ‚Äúonly reply in JSON, no prose‚Äù, but we ended up using a model tuned for outputting code. I think I inspired  to add their JSON output feature."
"One of the main benefits of large language models is that they are essentially stochastic models of the entire Internet. They have a bunch of patterns formed that can let you create surprisingly different outputs from similar inputs. This is also one of the main drawbacks of large language models: they are essentially stochastic models of the entire Internet. They have a bunch of patterns formed that can let you create surprisingly different outputs from similar inputs. The outputs of these models are usually correct-ish enough (more correct if you ground the responses in document fact like you do with a Retrieval-augmented Generation system), but they are not always aligned with our observable reality."
"A lot of the time you will get outputs that don‚Äôt make any logical or factual sense. These are called ‚Äúhallucinations‚Äù and they are one of the main drawbacks of large language models. If a hallucination pops in at the worst times, you‚Äôve accidentally told someone how to poison themselves with chocolate chip cookies. This is, as the kids say, ‚Äúbad‚Äù."
"The inherent randomness of the output of a large language model means that it can be difficult to get an exactly parsable format. Most of the time, you‚Äôd be able to coax the model to get usable JSON output, but without schema it can sometimes generate wildly different JSON responses. Only sometimes. This isn‚Äôt deterministic and Yoko has found that this is one of the most frustrating parts of working with large language models."
""
"However, there are workarounds.  offers a way to use a grammar file to strictly guide the output of a large language model by using context-free grammar. This lets you get something more deterministic, but it‚Äôs still not perfect. It‚Äôs a lot better than nothing, though."
"One of the fun things that can happen with this is that you can have the model fail to generate anything but an endless stream of newlines in JSON mode. This is hilarious and usually requires some special detection logic to handle and restart the query. There‚Äôs work being done to let you use JSON schema to guide the generation of large language model outputs, but it‚Äôs not currently ready for the masses."
""
"However, one of the easiest ways to hack around this is by using a model that generates code instead of text. This is how Yoko got the AI Town and AI Tamago models to output JSON that was mostly valid. It‚Äôs a hack, but it works. This was made a lot easier for AI town when one of the tools they use () added support for JSON output from the model. This is a lot better than the code generation model hack, but research continues."
""
"When I was making AI Town, I was inspired by  by Ted Chiang. It‚Äôs about a former zookeeper that trained AI agents to be pets, kinda like how we use Reinforcement Learning from Human Feedback to train AI models like ChatGPT."
"However, at the same time, there are cases where hallucinations are not only useful, but they are what make the implementation of a system possible. If large language models are essentially massive banks of the word frequencies of a huge part of culture, then the emergent output can create unexpected things that happen frequently. This lets you have emergent behavior form, this can be the backbone of games and is the key thing that makes AI Town work as well as it does."
"AI Tamago is also completely driven off of the results of large language model hallucinations. They are the core of what drives user inputs, the game loop, and the surprising reactions you get when disciplining your pet. The status screen takes in the game state and lets you know what your pet is feeling in a way that the segment displays of the Tamagochi toys could never do."
"These enable you to build workflows that are  by the inherent randomness of the hallucinations instead of seeing them as drawbacks. This means you need to choose outputs that can have the hallucinations shine instead of being ugly warts you need to continuously shave away. Instead of using them for doing pathfinding, have them drive the AI of your characters or writing the A* pathfinding algorithm so you don‚Äôt have to write it again for the billionth time."
"I‚Äôm not saying that large language models can replace the output of a human, but they are more like a language server for human languages as well as programming languages. They are best used when you are generating the boilerplate you don‚Äôt want to do yourself, or when you are throwing science at the wall to see what sticks."
""
"Yoko is showing people how to use AI today, on local machines, with models of your choice, that allow you to experiment, hack and learn."
"I can‚Äôt wait to see what‚Äôs next!"
"If you want to follow what Yoko does, here‚Äôs a few links to add to your feeds:"
"Yoko‚Äôs  (or X, or whatever we‚Äôre supposed to call it now)"
"(insert standard conclusion diatribe here)"
""
""
""
"Some people daydream about normal things, like coffee machines or raising that Series A round (those are normal things to dream about, right?). I daydream about commanding a fleet of chonky . Also, totally normal. Well, fortunately for me and anyone else wanting to explore the world of generative AI ‚Äî Fly.io has GPUs now!"
"Sure, this technology will probably end up with the AI  while we go about our lives ‚Äî but it seems like it‚Äôs here to stay, so we should at least have some fun with it. In this post we‚Äôll put these GPUs to task and you‚Äôll learn how to build your very own AI image-generating Discord bot, kinda like Midjourney. Available 24/7 and ready to serve up all the pictures of cats eating burritos your heart desires. And because I‚Äôd never tell you to draw the rest of the owl, I‚Äôll link to working code that you can deploy today."
""
"In the realm of AI image generation, two names have become prominent: Midjourney and Stable Diffusion. Both are image generating software that allow you to synthesize an image from a textual prompt. One is a closed source paid service, while the other is open source and can run locally. Midjourney gained popularity because it allowed the less technically-inclined among us to explore this technology through its ease of use. Stable Diffusion democratized access to the technology, but it can be quite tricky to get good results out of it."
"Enter  (pronounced ), an open source project that combines the best of both worlds and offers a user-friendly interface to Stable Diffusion. It‚Äôs hands down the easiest way to get started with Stable Diffusion. Sure there are more popular tools like Stable Diffusion web UI and ComfyUI, but Fooocus adds some magic to reduce the need to manually tweak a bunch of settings.  The most significant feature is probably GPT-2-based ‚Äú‚Äù to dynamically enhance prompts."
"The point of Fooocus is to  on your prompt. The more you put into it, the more you get out. That said, a very simple prompt like ‚Äúforest elf‚Äù can return high-quality images without the need to trawl the web for prompt ideas or fiddle with knobs and levers (although they‚Äôre there if you want them)."
"So, what can this thing ? Well, this‚Ä¶"
"Here‚Äôs the full command I‚Äôve used to generate this image:"
""
"We‚Äôll deploy two applications. The code to run the bot itself will run on normal VM hardware, and the API server doing all the hard work synthesizing alpacas out of thin air will run on GPU hardware."
"Fooocus is served up as a web UI by default, but with a little elbow grease we can interact with it as a REST API. Fortunately, with more than 25k stars on GitHub at the time of writing, the project has a lively open-source community, so we don‚Äôt need to do much work here ‚Äî it‚Äôs already been done for us.  is a project that shoves FastAPI in front of a Fooocus runtime. We‚Äôll use this for the API server app."
"The Python-based bot connects to the  using the  library. When it starts up, it maintains an open pipe for data to flow back and forth via WebSockets. The bot app also includes a client that knows how to talk to the API server using Flycast and request the image it needs via HTTP."
"When we request an image from Discord using the  slash command, we immediately respond using Pycord‚Äôs  function to let Discord know that the request has been received and the bot is working on it ‚Äî it‚Äôll take a few seconds to process your prompt, fabricate an image, upload it to Discord and let you share it with your friends. This is a blocking operation, so it won‚Äôt perform well if you have hundreds of people on your Discord Server using the command. For that, you‚Äôll want to jiggle some wires to make the code non-blocking. But for for now, this gives us a nice UX for the bot."
"When the API server returns the image, it gets saved to disk. We‚Äôll use the fantastic  library to generate collision-free file names:"
""
"We‚Äôll also use  to check if the image is ready every second, and when it is, we send it off to Discord to complete the request:"
""
"Neither of these two apps will be exposed to the Internet, yet they‚Äôll still be able to communicate with each other. One of the undersold stories about Fly.io is the ease with which two applications can communicate over the private network. We assign special IPv6 private network (6pn) addresses within the same organizational space and applications can effortlessly discover and connect to one another without any additional configuration."
"But what about load balancing and this ‚Äúscale-to-zero‚Äù thing? We don‚Äôt  want our two apps to talk to each other, we want the Fly Proxy to start our Machine when a request comes in, and stop it when idle. For that, we‚Äôll need , our private load balancing feature."
"When you assign a Flycast IP to your app, you can route requests using a special  domain. Those requests are routed through the Fly Proxy instead of directly to instances in your app. Meaning you get all the load balancing, rate limiting and other proxy goodness that you‚Äôre accustomed to. The Proxy runs a process which can automatically downscale Machines every few minutes. It‚Äôll also start them right back up when a request comes in ‚Äî this means we can take advantage of scale-to-zero, saving us a bunch of money!"
""
"The slash command is the heart of your bot, enabling you to generate images based on your prompt, right from within Discord. When you type  into the Discord chat, you‚Äôll see some command options pop up."
"You‚Äôll need to input your base prompt (e.g. ‚Äúan alpaca sleeping in a grassy field‚Äù) and  optionally pick some styles (‚ÄúPencil Sketch Drawing‚Äù, ‚ÄúFuturistic Retro Cyberpunk‚Äù, ‚ÄúMRE Dark Cyberpunk‚Äù etc). With Fooocus, combining multiple styles ‚Äî ‚Äústyle-chaining‚Äù ‚Äî can help you achieve amazing results. Set the aspect ratio or provide negative prompts if needed, too."
"After you execute the command, the bot will request the image from the API, then send it as a response in the chat. Let‚Äôs see it in action!"
""
"For convenience (and to speed things up), we‚Äôll use a pre-built image when we deploy. With dependencies like  and  bundled in, it‚Äôs a hefty image weighing in just shy of 12GB. With a normal Fly Machine  this would not only be a bad idea, but not even possible due to an 8GB limit for the VMs rootfs. Fortunately the wizards behind Fly GPUs have accounted for our need to run huge models and their dependencies, and awarded us 50GB of rootfs."
""
"To start, clone the template . You‚Äôll need this for both the bot and server apps. Then deploy the server with the Fly CLI:"
""
"This command tells Fly.io to deploy your application based on the configuration specified in the , while the  flag secures your app by not exposing it to the public Internet."
"Remember Flycast? To use it, we‚Äôll allocate a private IPv6:"
""
"Now, let‚Äôs take a look at our  config:"
""
"There are a few key things to note here:"
"Currently, the NVIDIA L40Ss we‚Äôre using when we specify  are only available in , so that‚Äôs what we‚Äôve set the  to. We‚Äôre rolling out more GPUs to more regions in a hurry ‚Äî but for now we‚Äôll host the bot in Chicago."
""
"This app will run on a normal Fly Machine, no GPU required. First, set the  and  (the Flycast endpoint for the API server) secrets, using the Fly CLI. Then deploy:"
""
"Notice that the bot app doesn‚Äôt need to be publicly visible on the Internet either. Under the hood, the WebSocket connection to Discord‚Äôs Gateway API allows the bot to communicate freely without the need to define any services in our . This also means that the Fly Proxy will not downscale the app like it does the GPU Machine ‚Äî the bot will always appear ‚Äúonline‚Äù."
""
""
"That‚Äôs easy! NVIDIA provides us with a neat little command-line utility called  which we can use to monitor and get information about NVIDIA GPU devices."
"Let‚Äôs SSH to the running Machine for the API server app and run an  query in one go. It‚Äôs a little clunky, but you‚Äôll get the point:"
""
""
"What we‚Äôve done is run the command on a loop while the bot is actually doing work synthesizing an image and we get to see it ramp up and consume more wattage and VRAM. The card is barely breaking a sweat!"
""
"Let‚Äôs talk about the cost-effectiveness of this setup. On Fly.io, an L40S GPU  $2.50/hr. Tag on a few cents per hour for the VM resources and storage for our models and you‚Äôre looking at about $3.20/hr to run the GPU Machine. It‚Äôs , too ‚Äî if you‚Äôre not using the compute, you‚Äôre not paying for it! Keep in mind that some of these checkpoint models can be several gigabytes and if you create a volume, you will be charged for it even when you have no Machines running. It‚Äôs worth noting too, that the non-GPU bot app falls into our ."
""
"In comparison, Midjourney offers several subscription tiers with the cheapest plan costing $10/mo and providing 3.3 hours of ‚Äúfast‚Äù GPU time (roughly equivalent to an enterprise-grade Fly GPU). This works out to about $3/hr give or take a few cents."
""
"There is a lot you can do to build out the bot‚Äôs functionality. You control the source code for the bot, meaning that you can make it do . You might decide to mimic Midjourney‚Äôs  command to splice your own images into prompts (AKA img2img diffusion). You can do this by adding more commands to your , Pycord‚Äôs way of grouping similar commands. You might decide to add a button to roll the image if you don‚Äôt like it, or even specify the number of images to return. The possibilities are endless and your cloud bill‚Äôs the limit!"
"The full code for the bot and server (with detailed instructions on how to deploy it on Fly.io) can be found ."
""
""
""
"Before proceeding, a caution.  This is an engineering trade-off.  Test carefully before deploying to production."
"By the end of this blog post you should have the information you need to make an informed decision."
""
"is a Linux distribution that advertises itself as Small.  Simple.  Secure."
"It is indisputably smaller than the alternatives ‚Äì when measured by image size.  More on that in a bit.  Some claim that this results in less memory usage and better performance.  Others dispute these claims.  For these, it is best that you test the results for yourself with your application."
"Simple is harder to measure.  Some of the larger differences, like  vs , are less relevant in container environments.  Others, like  are implementation details.  Essentially what you get is a Linux distribution with perhaps a number of standard packages (e.g., bash) not installed by default, but these can be easily added if needed."
"Secure is definitely an important attribute.  The alternatives make comparable claims in this area.  Do your own research in this area and come to your own conclusions."
"Not mentioned is the downside: Alpine Linux has a smaller ecosystem that the alternatives, particularly when compared to Debian."
""
"Let‚Äôs start with a baseline consisting of the Dockerfiles produced by  for some of the most popular
frameworks:"
""
"What may not be obvious to the naked eye from these results is that the base image for these is one of the following:"
"Debian Bookworm (the current ‚Äústable‚Äù distribution)"
"Once you factor in that Ubuntu is based on Debian, the conclusion is that Debian is effectively the default distribution for fly IO.  Rest assured that this isn‚Äôt the result of a devious conspiracy by Fly.io, but rather a reflection of the default choices made independently by the developers of a number of frameworks and runtimes.  Beyond this, all Fly.io is doing is choosing the ‚Äúslim‚Äù version of the default distribution for each framework as the base."
"What‚Äôs likely going on here is a virtuos circle: people choose Debian because of the ecosystem, and ecosystem grows because people chose Debian."
"Now lets compare base image sizes:"
""
"And these numbers are just the for the base images.  I‚Äôve measured a minimal Rails/Postgresql/esbuild application at 304MB on Alpine and 428MB on Debian Slim.  A minimal Bun application at 110MB on Alpine and 173MB on Debian Slim.  And a minimal Node application at 142MB on Alpine and 207MB on Debian Slim."
"In each case, corresponding Alpine images are consistently smaller than their Debian slim equivalent."
""
"Switch distributions (and switching back!) is easy."
"The first change is to replace  with  in  statements in your ."
"Next is to replace  with  and  with .  Delete any options you may have like  and  - they aren‚Äôt needed."
"Now review the names of the packages you are installing.  Many are named the same.  A few are different.
You can use  to look for ones to use.  Some examples of
differences:"
""
"Note: the above is just an approximation.  For example, while  and  include everything
you need to build an application that uses sqlite3, all that is needed at runtime is .  This relentless attention to detail contributes to smaller final image sizes."
"Note: For Bun, Node, and Rails users, knowledge of how to apply the above changes are included in recent versions of the dockerfile generators that we provide.  After all, computers are good at  statements:"
""
""
""
"Over time, we‚Äôve noted a number of issues."
"Alpine uses  for a runtime library.  Debian uses .  Software tested on glibc may not work as expected on musl. And there are other potential compatibility issues like ."
""
"While not as large a community as Debian, there is a substantial number of happy Alpine users."
"For the forseeable future, the default for both frameworks and there fly.io will remain Debian, but we make it easy to switch."
"Try it out!  Hopefully this blog has provided insight into what you should evaluate for before you switch."
""
""
""
""
"We‚Äôll own it: we‚Äôve been snarky about Kubernetes. We are, at heart, old-school Unix nerds. We‚Äôre still scandalized by ."
"To make matters more complicated, the problems we‚Äôre working on , but  that it () is a bad fit for our own platform."
"But, come on: you never took us too seriously about K8s, right? K8s is hard for us to use, but that doesn‚Äôt mean it‚Äôs not a great fit for what you‚Äôre building. We‚Äôve been clear about that all along, right? Sure we have!"
"Well, good news, everybody! If K8s is important for your project, and that‚Äôs all that‚Äôs been holding you back from , we‚Äôve spent the past several months building something for you."
""
"Fly.io works by transmogrifying Docker containers into filesystems for , and running them on servers we rack in dozens of regions around the world."
"You can build something like Fly.io with ‚Äústandard‚Äù orchestration tools like K8s. In fact, that‚Äôs what we did to start, too. To keep things simple, we used Nomad, and instead of K8s CNIs, we built our own Rust-based TLS-terminating Anycast proxy (and designed a WireGuard/IPv6-based private network system ). But the ideas are the same."
"The way we look at it, the signature feature of a ‚Äústandard‚Äù orchestrator is the global scheduler: the global eye in the sky that keeps track of vacancies on servers and optimized placement of new workloads. That‚Äôs the problem we ran into. We‚Äôre running over 200,000 applications, and we‚Äôre doing so on every continent except Antarctica. The speed of light (and a globally distributed network of backhoes) has something to say about keeping a perfectly consistent global picture of hundreds of thousands of applications, and it‚Äôs not pleasant."
"The other problem we ran into is that our Nomad scheduler kept trying to outsmart us, and, worse, our customers. It turns out that our users have pretty firm ideas of where they‚Äôd like their apps to run. If they ask for S√£o Paulo, they want S√£o Paulo, not Rio. But global schedulers have other priorities, like optimally bin-packing resources, and sometimes  looks just as good as  to them."
"To escape the scaling and DX problems we were hitting, we rethought orchestration. Where orchestrators like K8s tend to work through distributed consensus, we keep state local to workers. Each racked server in our fleet is a source of truth about the apps running on it, and provide an API to a market-style ‚Äúscheduler‚Äù that bids on resources in regions.  We call this system the"
"An important detail to grok about how this all works ‚Äì¬†a reason we haven‚Äôt, like, beaten the CAP theorem by doing this ‚Äì is that Fly Machines API calls can fail. If Nomad or K8s tries to place a workload on some server, only to find out that it‚Äôs filled up or thrown a rod, it will go hunt around for some other place to put it, like a good little robot. The Machines API won‚Äôt do this. It‚Äôll just fail the request. In fact, it goes out of its way to fail the request quickly, to deliver feedback; if we can‚Äôt schedule work in  right now, you might want instead to quickly deploy to ."
""
"In a real sense what we‚Äôve done here is extract a chunk of the scheduling problem out of our orchestrator, and handed it off to other components. For most of our users, that component is ."
"But , and anything can drive it. A lot of our users want quick answers to requests to schedule apps in specific regions, and  does a fine job of that. But it‚Äôs totally reasonable to want something that works more like the good little robots inside of K8s."
"You can build your own orchestrator with our API, but if what you‚Äôre looking for is literally Kubernetes, we‚Äôve saved you the trouble. It‚Äôs called Fly Kubernetes, or FKS for short."
"FKS is an implementation of Kubernetes that runs on top of Fly.io. You start it up using , by running ."
"Under the hood, FKS is a straightforward combination of two well-known Kubernetes projects: , and ."
"Virtual Kubelet is interesting. In K8s-land, a  is a host agent; it‚Äôs the thing that runs on every server in your fleet that knows how to run a K8s Pod. Virtual Kubelet isn‚Äôt a host agent; it‚Äôs a software component that pretends to be a host, registering itself with K8s as if it was one, but then sneakily proxying the Kubelet API elsewhere."
"In FKS, ‚Äúelsewhere‚Äù is . All we have to do is satisfy various APIs that virtual kubelet exposes. For example, the API for the lifecycle of a pod:"
""
"This interface is easy to map to the Fly Machines API. For example:"
""
"K3s, meanwhile, is a stripped-down implementation of all of K8s that fits into a single binary. K3s does a bunch of clever things to be as streamlined as it is, but the most notable of them is . Because of , K3s can manage multiple servers, but also gracefully runs on a single server, without distributed state."
"So that‚Äôs what we do. When you create a cluster, we run K3s and the Virtual Kubelet on a single Fly Machine. We compile a , with which you can talk to your K3s via . We set the whole thing up to run Pods on individual Fly Machines, so your cluster scales out directly using our platform, but with K8s tooling."
"One thing we like about this design is how much of the lifting is already done for us by the underlying platform. If you‚Äôre a K8s person, take a second to think of all the different components you‚Äôre dealing with: , specifically provisioned nodes, the , binary and configuration and its integration with the host network, containerd, registries. But Fly.io already does most of those things. So this project was mostly chipping away components until we found the bare minimum: CoreDNS, SQLite persistence, and Virtual Kubelet."
"We ended up with something significantly simpler than K3s, which is saying something."
"Fly Kubernetes has some advantages over plain  and :"
"Your deployment is more declarative than it is with the  file. You declare the exact state of everything down to replica counts, autoscaling rules, volume definitions, and more."
"This is a different way to do orchestration and scheduling on Fly.io. It‚Äôs not what everyone is going to want. But if you want it, you really want it, and we‚Äôre psyched to give it to you: Fly.io‚Äôs platform features, with Kubernetes handling configuration and driving your system to its desired state."
"We‚Äôve kept things simple to start with. There are K8s use cases we‚Äôre a strong fit for today, and others we‚Äôll get better at in the near future, as K8s users drive the underlying platform (and particularly our proxy) forward."
""
""
""
"One obvious thing it means is that you‚Äôve got an investment in Kubernetes tooling, you can keep it while running things on top of Fly.io. So that‚Äôs pretty neat. Buy our cereal!"
"But the computer science story is interesting, too. We placed a bet on an idiosyncratic strategy for doing global orchestration. We replaced global consensus, which is how Borg, Kubernetes, and Nomad all work, with a market-based system. That system was faster and, importantly, dumber than the consensus system it replaced."
"This had costs! Nomad‚Äôs global consensus would do truly heroic amounts of work to make sure Fly Apps got scheduled somewhere, anywhere. Like a good capitalist, Fly Machines will tell you in no uncertain terms how much work it‚Äôs willing to do for you (‚Äúless than a Nomad‚Äù)."
"But that doesn‚Äôt mean you‚Äôre stuck with the answers Fly Machines gives by itself. Because Fly Machines is so simple, and tries so hard to be predictable, we hoped you‚Äôd be able to build more sophisticated scheduling and orchestration schemes on top of it. And here you go: Kubernetes scheduling, as a plugin to the platform."
"More to come! We‚Äôre itching to see just how many different ways this bet might pay off. Or: we‚Äôll perish in flames! Either way, it‚Äôll be fun to watch."
""
""
""
""
"AI is apparently a bit of a  (maybe even  come to think about it). We‚Äôve seen entire industries get transformed in the wake of ChatGPT existing (somehow it‚Äôs only been around for a year, I can‚Äôt believe it either). It‚Äôs likely to leave a huge impact on society as a whole in the same way that the Internet did once we got search engines. Like any good venture-capital funded infrastructure provider, we want to enable you to do hilarious things with AI using industrial-grade muscle."
"Fly.io lets you run a full-stack app‚Äîor an entire dev platform based on the ‚Äîclose to your users. Fly.io GPUs let you attach an  to whatever you‚Äôre building, harnessing the full power of CUDA with more VRAM than your local 4090 can shake a ray-traced stick at. With these cards (or whatever you call a GPU attached to SXM fabric), AI/ML workloads are at your fingertips. You can , segment text, summarize articles, synthesize images, and more at speeds that would make your homelab blush. You can even set one up as your programming companion with  in case you‚Äôve just not been feeling it with the output of  models changing over time."
"If you want to find out more about what these cards are and what using them is like, check out  It covers the history of GPUs and why it‚Äôs ironic that the cards we offer are called ‚ÄúGraphics Processing Units‚Äù in the first place."
""
"We want you to deploy your own code with your favorite models on top of Fly.io‚Äôs cloud backbone. Fly.io GPUs make this really easy."
"You can get a GPU app running  (our friends in text generation) in two steps:"
"Put this in your :"
"If you want to read more about how to start your new sandwich empire, check out , it explains how to set up Ollama so that it  when it‚Äôs not in use."
""
"Being able to spin up GPUs is great, but where Fly.io really shines is inference at the edge."
"Let‚Äôs say you have an app that lets users enter ingredients they have in their kitchen and receive a sandwich recipe. Your users expect their recipes  (or at least as fast as the other leading apps). Seconds count when you need an emergency sandwich."
""
"In the previous snippet, we deployed our app to ord (). The good news is that our model returns a result really quickly and users in Chicago get instant sandwich recipes. It‚Äôs a good experience for users near your datacentre, and you can do this on any half decent cloud provider."
"But surely people outside of Chicago need sandwiches too. Amsterdam has sandwich fiends as well. And sometimes it takes too long to have their requests leap across the pond. The speed of light is only so fast after all. Don‚Äôt worry, we‚Äôve got your back. Fly.io has GPUs in datacentres all over the world. Even more, we‚Äôll let you run  with the same public IP address and the same TLS certificates in any regions with GPU support."
"Don‚Äôt believe us? See how you can scale your app up in Amsterdam with one command:"
""
"It‚Äôs that easy."
""
"GPUs are powerful parallel processing packages, but they‚Äôre not cheap! Once we have enough people wanting to turn their fridge contents into tasty sandwiches, keeping a GPU or two running makes sense. But we‚Äôre just a small app still growing our user base while also funding the latest large sandwich model research. We want to only pay for GPUs when a user makes a request."
"Let‚Äôs open up that  again, and add a section called , and we‚Äôll include instructions on how we want our app to scale up and down:"
""
"Now when no one needs sandwich recipes, you don‚Äôt pay for GPU time."
""
"We have GPUs ready to use in several US and EU regions and Sydney. You can deploy your sandwich, music generation, or AI illustration apps to:"
"with 40gb of RAM for $2.50/hr"
"By default, anything you deploy to GPUs will use eight heckin‚Äô  CPU cores, and you can attach volumes up to 500 gigabytes. We‚Äôll even give you discounts for reserved instances and dedicated hosts if you ask nicely."
"We hope you have fun with these new cards and we‚Äôd love to see what you can do with them! Reach out to us on X (formerly Twitter) or  and share what you‚Äôve been up to. We‚Äôd love to see what we can make easier!"
""
""
""
"GPU hardware will let our users run all sorts of fun Artificial Intelligence and Machine Learning (AI/ML) workloads near their users. But, what are these ‚ÄúGPUs‚Äù really? What can they do? What  they do?"
"Listen here for my tale of woe as I spell out exactly what these cards are, are not, and what you can do with them. By the end of this magical journey, you should understand the true irony of them being called ‚ÄúGraphics Processing Units‚Äù and why every marketing term is always bad forever."
""
"In the early days of computing, your computer generally had a few basic components:"
"The CPU"
"Taking the Commodore 64 as an example, it had a CPU, a chip to handle video output, a chip to handle audio output, and a chip to glue everything together. The CPU would read instructions from the RAM and then execute them to do things like draw to the screen, solve sudoku puzzles, play sounds, and so on."
"However, even though the CPU by itself was fast by the standards of the time, it could only do a million clock cycles per second or so. Imagine a very small shouting crystal vibrating millions of times per second triggering the CPU to do one part of a task and you‚Äôll get the idea. This is fast, but not fast enough when executing instructions can take longer than a single clock cycle and when your video output device needs to be updated 60 times per second."
"The main way they optimized this was by shunting a lot of the video output tasks to a bespoke device called the VIC-II (Video Interface Chip, version 2). This allowed the Commodore 64 to send a bunch of instructions to the VIC-II and then let it do its thing while the CPU was off doing other things. This is called ‚Äúoffloading‚Äù."
"As technology advanced, the desire to do bigger and better things with both contemporary and future hardware increased. This came to a head when this little studio nobody had ever heard of called id Software released one of the most popular games of all time: DOOM."
"Now, even though DOOM was a huge advancement in gaming technology, it was still incredibly limited by the hardware of the time. It was actually a 2D game that used a lot of tricks to make it look (and feel) like it was 3D. It was also limited to a resolution of 320x200 and a hard cap of 35 frames per second. This was fine for the time (most movies were only at 24 frames per second), but it was clear that there was a lot of room for improvement."
"One of the main things that DOOM did was to use a pair of techniques to draw the world at near real-time. It used a combination of ‚Äúraycasting‚Äù and binary-space partitioning to draw the world. This basically means that they drew a bunch of imaginary lines to where points in the map would be to figure out what color everything would be and then eliminated the parts of the map that were behind walls and other objects. This is a very simplified explanation, and if you want to know more,  of DOOM in more detail."
""
"However, a lot of this was logic that ran very slowly on the CPU, and while the CPU was doing the display logic, it couldn‚Äôt do anything else, such as enemy AI or playing sounds. Hence the idea of a ‚Äú3D accelerator card‚Äù. The idea: offload the 3D rendering logic to a separate device that could do it much faster than the CPU could, and free the CPU to do other things like AI, sound, and so on."
"This was the dream, but it was a long way off. Then Quake happened."
""
"Unlike Doom, Quake was fully 3D on unmodified consumer hardware. Players could look up and down (something previously thought impossible without accelerator hardware!) and designers could make levels with that in mind. Quake also allowed much more complex geometry and textures. It was a huge leap forward in 3D gaming and it was only possible because of the massive leap in CPU power at the time. The Pentium family of processors was such a huge leap that it allowed them to bust through and do it in ‚Äúreal time‚Äù. Quake has since set the standard for multiplayer deathmatch games, and its source code has lineage to Call of Duty, Half-Life, Half-Life 2, DotA 2, Titanfall, and Apex Legends."
"However, the thing that really made 3D accelerator cards leap into the public spotlight was another little-known studio called Crystal Dynamics and their 1996 release of Tomb Raider. It was built from the ground up to require the use of 3D accelerator cards. The cards flew off the shelves."
"‚Äú3D accelerator cards‚Äù would later become known as ‚ÄúGraphics Processing Units‚Äù or GPUs because of how synonymous they became with 3D gaming, engineering tasks such as Computer-Aided Drafting (CAD), and even the entire OS environment with compositors like  on Windows Vista,  on GNU+Linux, and  on macOS. Things became so much easier for everyone when 2D and 3D graphics were integrated into the same device so you didn‚Äôt need to chain your output through your 3D accelerator card!"
""
"When GPUs first came out, they were very simple devices. They had a few basic components:"
"A framebuffer to store the current state of the screen"
"This basic architecture has remained the same for the past 20 years or so. The main differences are that as technology advanced, the capabilities of those cards increased. They got faster, more parallel, more capable, had more memory, were made cheaper, and so on. This gradually allowed for more and more complex games like Half-Life 2, Crysis, The Legend of Zelda: Breath of the Wild, Baudur‚Äôs Gate 3, and so on."
"Over time, as more and more hardware was added, GPUs became computers in their own rights (sometimes even bigger than the rest of the computer thanks for the need to cool things more aggressively). This new hardware includes:"
"Video encoding hardware via NVENC and AMD VCE so that content creators can stream and record their gameplay in higher quality without having to impact the performance of the game"
"But, at the same time, that AI/ML hardware started to get noticed by more and more people. It was discovered that the shader cores and then the CUDA cores could be used to do AI/ML workloads at ludicrous speeds. This enabled research and development of models like GPT-2, Stable Diffusion, DLSS, and so on. This has led to a Cambrian Explosion of AI/ML research and development that is continuing to this day."
""
"I‚Äôve mostly been describing consumer GPUs and their capabilities up to this point because that‚Äôs what we all have the biggest understanding of. There is a huge difference between the ‚ÄúGPUs‚Äù that you can get for server tasks and normal consumer tasks from a place like Newegg or Best Buy. The main difference is that enterprise-grade Graphics Processing Units do not have any of the hardware needed to process graphics."
""
"Yes. Really. They don‚Äôt have rasterization hardware, shader cores, display outputs, or anything useful for trying to run games on them. They are AI/ML accelerator cards more than anything. It‚Äôs kinda beautifully ironic that they‚Äôre called Graphics Processing Units when they have no ability to process graphics."
""
"These GPUs are really good at massively parallel tasks. This naturally translates to being very good at AI/ML tasks such as:"
"Summarization (what is this article about in a few sentences?)"
"Or any combination/chain of these tasks. A lot of this is pretty abstract building blocks that can be combined in a lot of different ways. This is why AI/ML stuff is so exciting right now. We‚Äôre in the early days of understanding what these things are, what they can do, and how to use them properly."
"Imagine being able to load articles about the topic you are researching into your queries to find where someone said something roughly similar to what you‚Äôre looking for. Queries like ‚Äúthat one recipe with eggs that you fold over with ham in it‚Äù. That‚Äôs the kind of thing that‚Äôs possible with AI/ML (and tools like vector databases) but difficult to impossible with traditional search engines."
""
"Fortunately and unfortunately, we‚Äôre in the Cambrian Explosion days of this industry. Key advances happen constantly. Exact models and tooling changes almost as often. This is both a very good thing and a very bad thing."
"If you want to get started today, here‚Äôs a few models that you can play with right now:"
"- A generic foundation model with instruction and chat tuned variants. It‚Äôs a good starting point for a lot of research and nearly everything else uses the same formats that Llama 2 does."
"For a practical example, imagine that you have a set of . You want to take those talk videos, extract the audio, and transform them into written text because some people learn better from text than video. The overall workflow would look something like this:"
"Use ffmpeg to extract the audio track from the video files"
"Then bam, you don‚Äôt just have a portfolio piece, you have the recipe for winning downtime from visitors of orange websites clicking on your link so much. You can also use this to create transcripts for your videos so that people who can‚Äôt hear can still enjoy your content."
"The true advantage of these is not using them as individual parts on themselves, but as a cohesive whole in a chain. This is where the real power of AI/ML comes from. It‚Äôs not the individual models, but the ability to chain them together to do something useful. This is where the true opportunities for innovation lie."
""
"So that‚Äôs what these ‚ÄúGPUs‚Äù are really: they‚Äôre AI/ML accelerator cards. The A100 cards incapable of processing graphics or encoding video, but they‚Äôre really, really good at AI/ML workloads. They allow you to do way more tasks per watt than any CPU ever could."
"I hope you enjoyed this tale of woe as I spilled out the horrible truths about marketing being awful forever and gave you ideas for how to  these graphics-free Graphics Processing Units to do useful things. But sadly, not for processing graphics unless you wait for the  cards early in 2024."
"Sign up for Fly.io today and try our GPUs! I can‚Äôt wait to see what you build with them."
""
""
""
"Open-source self-hosted AI tools have advanced a lot in the past 6 months. They allow you to create new methods of expression (with QR code generation and Stable Diffusion), easy access to summarization powers that would have made Google blush a decade ago (even with untuned foundation models such as LLaMa 2 and Yi), to conversational assistants that enable people to do more with their time, and to perform speech recognition in  on moderate hardware (with Whisper et al). With all these capabilities comes the need for more and more raw computational muscle to be able to do inference on bigger and bigger models, and eventually do things that we can‚Äôt even imagine right now. Fly.io lets you put your compute where your users are so that you can do machine learning inference tasks on the edge with the power of enterprise-grade GPUs such as the Nvidia A100. You can also scale your GPU nodes to zero running Machines, so you only pay for what you actually need, when you need it."
""
""
""
"Running GPU nodes on top of Fly is expensive. Sure, GPUs enable you to do things a lot faster than CPUs ever could on their own, but you mostly will have things run idle between uses. This is where scaling to zero comes in. With scaling to zero, you can have your GPU nodes shut down when you‚Äôre not using them. When your Machine stops, you aren‚Äôt paying for the GPU any more. This is good for the environment and your wallet."
"In this post, we‚Äôre going to be using  to generate text. Ollama is a fancy wrapper around  that allows you to run large language models on your own hardware with your choice of model. It also supports GPU acceleration, meaning that you can use Fly.io‚Äôs huge GPUs to run your models faster than your RTX 3060 at home ever would on its own."
"One of the main downsides of using Ollama in a cloud environment is that it doesn‚Äôt have authentication by default. Thanks to the power of about 70 lines of Go, we are able to shim that in after the fact. This will protect your server from random people on the internet using your GPU time (and spending your money) to generate text and integrate it into your own applications."
"Create a new folder called :"
""
""
"First, we need to create a new Fly app:"
""
"After selecting a name and an organization to run it in, this command will create the app and write out a  file for you:"
""
"This is the configuration file that Fly.io uses to know how to run your application. We‚Äôre going to be modifying the  file to add some additional configuration to it, such as enabling GPU support:"
""
"We don‚Äôt want to expose the GPU to the internet, so we‚Äôre going to create a  address to expose it to other services on your private network. To create a flycast address, run this command:"
"The  command makes a unique address in your private network that you can use to access Ollama from your other services. Make sure to add the  flag, otherwise you‚Äôll get a globally unique IP address instead of a private one."
"Next, you may need to remove all of the other public IP addresses for the app to lock it away from the public. Get a list of them with  and then remove them with . Delete everything but your flycast IP."
"Next, we need to declare the volume for Ollama to store models in. If you don‚Äôt do this, then when you scale to zero, your existing models will be destroyed and you will have to re-download them every time the server starts. This is not ideal, so we‚Äôre going to create a persistent volume to store the models in. Add the following to your :"
""
"This will create a 100GB volume in the  region when the app is deployed. This will be used to store the models that you download from the . You can make this smaller if you want, but 100GB is a good place to start from."
"Now that everything is set up, we can deploy this to Fly.io:"
""
"This will take a minute to pull the Ollama image, push it to a Machine, provision your volume, and kick everything else off with hypervisors, GPUs and whatnot. Once it‚Äôs done, you should see something like this:"
""
"This is a lie because we just deleted the public IP addresses for this app. You can‚Äôt access it from the internet, and by extension, random people can‚Äôt access it either. For now, you can run an interactive session with Ollama using an ephemeral Fly Machine:"
""
"And then you can pull an image from the  and generate some text:"
""
"If you want a persistent wake-on-use connection to your Ollama instance, you can set up a . This will let you use Ollama from your local applications without having to run them on Fly. For example, if you want to figure out the safe cooking temperature for ground beef in Celsius, you can query that in JavaScript with this snippet of code:"
""
""
"The best part about all of this is that when you want to scale down to zero running Machines: do nothing, it will automatically shut down when it‚Äôs idle. Wait a few minutes and then verify it with :"
""
"The app has been stopped. This means that it‚Äôs not running and you‚Äôre not paying for it. When you want it to start up again, just make a request. It will automatically start up and you can use it as normal with the CLI or even just arbitrary calls to ."
"You can also upload your own models to the Ollama registry by  and pushing it (though you will need to install Ollama locally to publish your own models). At this time, the only way to set a custom system prompt is to use a Modelfile and upload your model to the registry."
""
"Ollama is a fantastic way to run large language models of your choice and the ability to use Fly.io‚Äôs powerful GPUs means you can use bigger models with more parameters and a larger context window. This lets you make your assistants more lifelike, your conversations have more context, and your text generation more realistic."
"Oh, by the way, this also lets you use the new  mode to have your models call functions, similar to how ChatGPT would. To do this, have a system prompt that looks like this:"
""
"Then you can use the  to receive a JSON response from Ollama (hint:  in the CLI or  in the API). This is a great way to make your assistants more lifelike and more useful. You will need to use something like  or manual iterations to properly handle the cases where the user doesn‚Äôt want to call a function, but that‚Äôs a topic for another blog post."
"For the best results you may want to use a model with a larger context window such as  (16k == 16,384 token window) as JSON is very token-expensive. Future advances in the next few weeks (such as the Yi models gaining ludicrous token windows on the line of 200,000 tokens at the cost of ludicrous amounts of VRAM usage) will make this less of an issue. You can also get away with minifying the JSON in the functions and examples a lot, but you may need to experiment to get the best results."
"Happy hacking, y'all."
""
"Imagine if you could auto scale simply by wrapping any existing app code in a function and have that block of code run in a temporary copy of your app."
"The pursuit of elastic, auto-scaling applications has taken us to silly places."
"Serverless/FaaS had a couple things going for it. Elastic Scale‚Ñ¢ is hard. It‚Äôs even harder when you need to manage those pesky servers. It also promised pay-what-you-use costs to avoid idle usage. Good stuff, right?"
"Well the charade is over. You offload scaling concerns and the complexities of scaling, just to end up needing . Additional queues, storage, and glue code to communicate back to our app is just the starting point. Dev, test, and CI complexity balloons as fast as your costs. Oh, and you often have to rewrite your app in proprietary JavaScript ‚Äì even if it‚Äôs already written in JavaScript!"
"At the same time, the rest of us have elastically scaled by starting more webservers. Or we‚Äôve dumped on complexity with microservices. This doesn‚Äôt make sense. Piling on more webservers to transcode more videos or serve up more ML tasks isn‚Äôt what we want. And granular scale shouldn‚Äôt require slicing our apps into bespoke operational units with their own APIs and deployments to manage."
"Enough is enough. There‚Äôs a better way to elastically scale applications."
""
"Here‚Äôs what we really want:"
"We don‚Äôt want to manage those pesky servers. We already have this for our app deployments via , , , etc"
"Imagine if we could auto scale simply by wrapping any existing app code in a function and have that block of code run in a temporary copy of the app."
"Enter the FLAME pattern."
"FLAME - Fleeting Lambda Application for Modular Execution"
"With FLAME, you treat your  as a lambda, where modular parts can be executed on short-lived infrastructure."
"No rewrites. No bespoke runtimes. No outrageous layers of complexity. Need to insert the results of an expensive operation to the database? PubSub broadcast the result of some expensive work? No problem! It‚Äôs your whole app so of course you can do it."
"The Elixir  implements the FLAME pattern. It has a backend adapter for Fly.io, but you can use it on any cloud that gives you an API to spin up an instance with your app code running on it. We‚Äôll talk more about backends in a bit, as well as implementing FLAME in other languages."
"First, lets watch a realtime thumbnail generation example to see FLAME + Elixir in action:"
"Now let‚Äôs walk through something a little more basic. Imagine we have a function to transcode video to thumbnails in our Elixir application after they are uploaded:"
""
"Our  function accepts a video struct. We shell out to  to take the video URL and generate thumbnails at a given interval. We then write the temporary thumbnail paths to durable storage. Finally, we insert the generated thumbnail URLs into the database."
"This works great locally, but CPU bound work like video transcoding can quickly bring our entire service to a halt in production. Instead of rewriting large swaths of our app to move this into microservices or some FaaS, we can simply wrap it in a FLAME call:"
""
"That‚Äôs it!  accepts the name of a runner pool, and a function. It then finds or boots a new copy of our entire application and runs the function there. Any variables the function closes over (like our  struct and ) are passed along automatically."
"When the FLAME runner boots up, it connects back to the parent node, receives the function to run, executes it, and returns the result to the caller. Based on configuration, the booted runner either waits happily for more work before idling down, or extinguishes itself immediately."
"Let‚Äôs visualize the flow:"
"We changed no other code and issued our DB write with  just like before, because we are running our  . Database connection(s) and all. Except this fleeting application only runs that little function after startup and nothing else."
"In practice, a FLAME implementation will support a pool of runners for hot startup, scale-to-zero, and elastic growth. More on that later."
""
"FaaS solutions help you solve a problem. FLAME removes the problem."
"The FaaS labyrinth of complexity defies reason. And it‚Äôs unavoidable. Let‚Äôs walkthrough the thumbnail use-case to see how."
"We try to start with the simplest building block like request/response AWS Lambda Function URL‚Äôs."
"The complexity hits immediately."
"We start writing custom encoders/decoders on both sides to handle streaming the thumbnails back to the app over HTTP. Phew that‚Äôs done. Wait, is our video transcoding or user uploads going to take longer than 15 minutes? Sorry, hard timeout limit¬†‚Äì¬†time to split our videos into chunks to stay within the timeout, which means more lambdas to do that. Now we‚Äôre orchestrating lambda workflows and relying on additional services, such as SQS and S3, to enable this."
"All the FaaS is doing is adding layers of communication between your code and the parts you want to run elastically. Each layer has its own glue integration price to pay."
"Ultimately handling this kind of use-case looks something like this:"
"Trigger the lambda via HTTP endpoint, S3, or API gateway ($)"
"This is nuts. We pay the FaaS toll at every step. We shouldn‚Äôt have to do any of this!"
"FaaS provides a bunch of offerings to build a solution on top of. FLAME removes the problem entirely."
""
"On Fly.io infrastructure the  can boot a copy of your application on a new  and have it connect back to the parent for work within ~3s."
"By default, FLAME ships with a  and , but any host that provides an API to provision a server and run your app code can work as a FLAME backend. Erlang and Elixir primitives are doing all the heavy lifting here. The entire  is . The library has a single dependency, , which is an HTTP client."
"Because Fly.io runs our applications as a packaged up docker image, we simply ask the Fly API to boot a new Machine for us with the same image that our app is currently running. Also thanks to Fly infrastructure, we can guarantee the FLAME runners are started in the same region as the parent. This optimizes latency and lets you ship whatever data back and forth between parent and runner without having to think about it."
""
"With FaaS, just imagine how quickly the dev and testing story becomes a fate worse than death."
"To run the app locally, we either need to add some huge dev dependencies to simulate the entire FaaS pipeline, or worse, connect up our dev and test environments directly to the FaaS provider."
"With FLAME, your dev and test runners simply run on the local backend."
"Remember, this is your app. FLAME just controls where modular parts of it run. In dev or test, those parts simply run on the existing runtime on¬†your laptop or CI server."
"Using Elixir, we can even send a file across to the remote FLAME application thanks to the distributed features of the Erlang VM:"
""
"On line 2 we open a file on the parent node to the video path. Then in the FLAME child, we stream the file from the parent node to the FLAME server in only a couple lines of code. That‚Äôs it! No setup of S3 or HTTP interfaces required."
"With FLAME it‚Äôs easy to miss everything we‚Äôre not doing:"
"We don‚Äôt need to write code outside of our application. We can reuse business logic, database setup, PubSub, and all the features of our respective platforms"
""
"Elixir is fantastically well suited for the FLAME model because we get so much  like process supervision and distributed messaging. That said, any language with reasonable concurrency primitives can take advantage of this pattern. For example, my teammate, Lubien, created a proof of concept example for breaking out functions in your JavaScript application and running them inside a new Fly Machine:"
"So the general flow for a JavaScript-based FLAME call would be to move the modular executions to a new file, which is executed on a runner pool. Provided the arguments are JSON serializable, the general FLAME flow is similar to what we‚Äôve outlined here. Your application, your code, running on fleeting instances."
"A complete FLAME library will need to handle the following concerns:"
"Elastic pool scale-up and scale-down logic"
"For the rest of this post we‚Äôll see how the Elixir FLAME library handles these concerns as well as features uniquely suited to Elixir applications. But first, you might be wondering about your background job queues."
""
"FLAME works great inside your background job processor, but you may have noticed some overlap. If your job library handles scaling the worker pool, what is FLAME doing for you? There‚Äôs a couple important distinctions here."
"First, we reach for these queues when we need . We often can turn knobs to have the queues scale to handle more jobs as load changes. But durable operations are separate from elastic execution. Conflating these concerns can send you down a similar path to lambda complexity. Leaning on your worker queue purely for offloaded execution means writing all the glue code to get the data into and out of the job, and back to the caller or end-user‚Äôs device somehow."
"For example, if we want to guarantee we successfully generated thumbnails for a video after the user upload, then a job queue makes sense as the   for this operation. The actual transcoding could be a FLAME call inside the job itself, so we decouple the ideas of durability and scaled execution."
"On the other side, we have operations we don‚Äôt need durability for. Take the screencast above where the user hasn‚Äôt yet saved their video. Or an ML model execution where there‚Äôs no need to waste resources churning a prompt if the user has already left the app. In those cases, it doesn‚Äôt make sense to write to a durable store to pick up a job for work that will go right into the ether."
""
"With the Elixir implementation of FLAME, you define elastic pools of runners. This allows scale-to-zero behavior while also elastically scaling up FLAME servers with max concurrency limits."
"For example, lets take a look at the  callback, which is the entry point of all Elixir applications. We can drop in a  for video transcriptions and say we want it to scale to zero, boot a max of 10, and support 5 concurrent  operations per runner:"
""
"We use the presence of a FLAME parent to conditionally start our Phoenix webserver when booting the app. There‚Äôs no reason to start a webserver if we aren‚Äôt serving web traffic. Note we leave other services like the database  alone because we want to make use of those services inside FLAME runners."
"Elixir‚Äôs supervised process approach to applications is uniquely great for turning these kinds of knobs."
"We also set our pool to idle down after 30 seconds of no caller operations. This keeps our runners hot for a short while before discarding them. We could also pass a  to always ensure at least one  runner is hot and ready for work by the time our application is started."
""
"In Elixir, stateful bits of our applications are built around the  primitive ‚Äì¬†lightweight greenthreads with message mailboxes. Wrapping our otherwise stateless app code in a synchronous ‚Äòs or async ‚Äôs works great, but what about the stateful parts of our app?"
"exists to take an existing process specification in your Elixir app and start it on a FLAME runner instead of locally. You can use it anywhere you‚Äôd use  , , or similar interfaces. Just like , the process is run on an elastic pool and runners handle idle down when the process completes its work."
"And like , it lets us take existing app code, change a single LOC, and continue shipping features."
"Let‚Äôs walk through the example from the screencast above. Imagine we want to generate video thumbnails for a video . Elixir and LiveView make this easy. We won‚Äôt cover all the code here, but you can view the ."
"Our first pass would be to write a LiveView upload writer that calls into a :"
""
"An upload writer is a behavior that simply ferries the uploaded chunks from the client into whatever we‚Äôd like to do with them. Here we have a  which starts a process that communicates with an  shell. Inside , we use regular elixir process primitives:"
""
"The details aren‚Äôt super important here, except line 10 where we call , which starts a supervised process. The rest of the implementation simply ferries chunks as stdin into  and parses png‚Äôs from stdout. Once a PNG delimiter is found in stdout, we send the  process (our LiveView process) a message saying ‚Äúhey, here‚Äôs an image‚Äù:"
""
"The  LiveView process then picks up the message in a  callback and updates the UI:"
""
"The  is one magic part about Elixir. Everything is a process, and we can message those processes, regardless of their location in the cluster."
"It‚Äôs like if every instantiation of an object in your favorite OO lang included a cluster-global unique identifier to work with methods on that object. The LiveView (a process) simply receives the image message and updates the UI with new images."
"Now let‚Äôs head back over to our  function and make this elastically scalable."
""
"That‚Äôs it! Because everything is a process and processes can live anywhere, it doesn‚Äôt matter what server our  process lives on. It simply messages the caller with  and the messages are sent across the cluster if needed."
"Once the process exits, either from an explicit close, after the upload is done, or from the end-user closing their browser tab, the FLAME server will note the exit and idle down if no other work is being done."
"Check out the  if you‚Äôre interested."
""
"All this transient infrastructure needs failsafe mechanisms to avoid orphaning resources. If a parent spins up a runner, that runner must take care of idling itself down when no work is present and handle failsafe shutdowns if it can no longer contact the parent node."
"Likewise, we need to shutdown runners when parents are rolled for new deploys as we must guarantee we‚Äôre running the same code across the cluster."
"We also have active callers in many cases that are awaiting the result of work on runners that could go down for any reason."
"There‚Äôs a lot to monitor here."
"There‚Äôs also a number of failure modes that make this sound like a harrowing experience to implement. Fortunately Elixir has all the primitives to make this an easy task thanks to the Erlang VM. Namely, we get the following for free:"
"Process monitoring and supervision ‚Äì¬†we know when things go bad. Whether on a node-local process, or one across the cluster"
"We‚Äôll cover the internal implementation details in a future deep-dive post. For now, feel free to poke around ."
""
"We‚Äôre just getting started with the Elixir FLAME library, but it‚Äôs ready to try out now. In the future  look for more advance pool growth techniques, and deep dives into how the Elixir implementation works. You can also find me  to chat about implementing the FLAME pattern in your language of choice."
"Happy coding!"
"‚ÄìChris"
""
""
""
"The topic of ‚ÄúAI‚Äù gets a lot of attention and press. Coverage ranges from apocalyptic warnings to Utopian predictions. The truth, as always, is likely somewhere in the middle. As developers, we are the ones that either imagine ways that AI can be used to enhance our products or the ones doing the herculean tasks of implementing it inside our companies."
"I believe the following statement to be true:"
"AI won‚Äôt replace humans ‚Äî but humans with AI will replace humans without AI."
"I believe this can be extended to many products and services and the companies that create them. Let‚Äôs express it this way:"
"AI won‚Äôt replace businesses ‚Äî but businesses with AI will replace businesses without AI."
"Today I‚Äôm assuming your business would benefit from using AI. Or, at the very least, your C-levels have decreed from on high that thou must integrateth with AI. With that out of the way, the next question is how you‚Äôre meant to do it. This post is an argument to build on top of open source language models instead of closed models that you rent access to. We‚Äôll take a look at what convinced me."
""
"OpenAI, the creators of the famous ChatGPT, are the strong market leaders in this category. Why wouldn‚Äôt you want to use the best in the business?"
"Early on, stories of private corporate documents being uploaded by employees and then finding that private information leaking out to general ChatGPT users was a real black eye. . It exposed that people‚Äôs interactions with ChatGPT were being used as training data for future versions of the model."
"In response, OpenAI recently announced an  offering promising that no Enterprise customer data is used for training."
"With the top objection addressed, it should be smooth sailing for wide adoption, right?"
"Not so fast."
"While an Enterprise offering may address that concern, there are other subtle reasons to not use OpenAI, or other closed models, that can‚Äôt be resolved by vague statements of enterprise privacy."
""
"Let‚Äôs briefly outline the risks we take on when relying on a company like OpenAI for critical AI features in our applications."
": Relying deeply on an external service that plays a critical role in our business is risky. The integration is not easily swapped out for another service if needed. Additionally, we don‚Äôt want part of our ‚Äúsecret sauce‚Äù to actually be another company‚Äôs product. That‚Äôs some seriously shaky ground! They  to sell the same thing to our competitors too."
"Let‚Äôs look a bit closer at the ‚ÄúSingle provider risk‚Äù."
""
"For hobby usage, proof of concept work, and personal experiments, by all means, use ChatGPT! I do and I expect to continue to as well. It‚Äôs fantastic for prototyping, it‚Äôs trivial to set up, and it allows you to throw ink on canvas so much more quickly than any other option out there."
"Up until recently, I was all gung-ho for ChatGPT being integrated into my apps. What happened? November 2023 happened. It was a very bad month for OpenAI."
"I created a  powered by ChatGPT and on the morning of November 8th, I asked my personal trainer about the workout for the day and it failed. OpenAI was having a bad day with an outage."
"I don‚Äôt fault someone for having a bad day. At some point, downtime happens to the best of us. And given enough time, it happens to  of us. But when possible, I want to prevent someone  bad day from becoming  bad day too."
""
"In my case, my personal fitness trainer being unavailable was a minor inconvenience, but I managed. However, it gave me pause. If I had built an AI fitness trainer as a service, that outage would be a much bigger deal and there would be nothing I could have done to fix it until the ChatGPT API came back up."
"With services like a Personal AI Fitness Trainer, the AI component is the primary focus and main value proposition of the app. That‚Äôs pretty darn critical! If that AI service is interrupted, significantly altered (say, by the model suddenly refusing my requests for fitness information in ways that worked before) or my desired usage is denied (without warning or reason), the application is useless. That‚Äôs an existential threat that could make my app evaporate overnight without warning."
"This highlights the risk of having a critical dependency on an external service."
"Modern applications depend on many services, both internal and external. But how  that dependency is matters."
"Let‚Äôs take a  simple application as an example. The application has a critical dependency on the database and both the app and database have a critical dependency on the underlying VMs/machines/provider. These critical dependencies are so common that we seldom think about them because we deal with them every day we come to work. It‚Äôs just how things are."
"The danger comes when we draw a critical dependency line to an  . If the service has a hiccup or the network between my app and their service starts dropping all my packets, the entire application goes down. Someone else‚Äôs bad day gets spread around when that happens. üòû"
"In order to protect ourselves from a risk like that, we should diversify our reliance away from a single external provider. How do we do that? We‚Äôll come back to this later."
""
"It‚Äôs really common for apps to have external dependencies. The question is how critical to our service are those dependencies?"
"What happens to the application when the external log aggregation service, email service, and error reporting services are all unreachable? If the app is designed well, then users may have a slightly degraded experience or, best case, the users won‚Äôt even notice the issues at all!"
"The key factor is these external services are not essential to our application functioning."
""
"Our industry has a lot of misconceptions, fear, uncertainty, and doubt around the idea of regulation, but sometimes it‚Äôs justified. I don‚Äôt want you to think about regulation as a scary thing that yanks away control. Instead, let‚Äôs think about regulation as when a government body gets involved to disallow businesses from doing or engaging in specific activities. Given that our industry has been so self-defined for so long, this feels like an existential threat. However, this is a good thing when we think about vehicle safety standards (you don‚Äôt want your 4-ton mass of metal exploding while traveling at 70 mph), pollution, health risks, and more. It‚Äôs a careful balance."
"Ironically, Sam Altman has been a major proponent  of the AI industry. Why would he want that?"
"It turns out that . Or, put another way, when the people with an early lead see that , they want to pull up the ladders behind them and have the government make it legally harder, or impossible, for competitors to catch up to them."
"If Altman‚Äôs efforts are successful, then companies who create AI can expect government involvement and oversight. Added licensing requirements and certifications would raise the cost of starting a competing business."
"At this point you may be thinking something like ‚Äúbut all of that is theoretical Mark, how would this affect my business‚Äô use of AI today?‚Äù"
"Introducing an external organization that can dictate changes to an AI product risks breaking an existing company‚Äôs applications or significantly reducing the effectiveness of the application. And those changes may come without notice or warning."
"Additionally, if my business is built on an external AI system protected from competition by regulators, that adds a significant risk. If they are now the only game in town, they can set whatever price they want."
""
"In the week following the OpenAI outage (November 17th to be precise), the entire tech industry was upended for most of a week following a blog post on the OpenAI blog . Then ."
"OpenAI is partnered with Microsoft and on Nov 20, 2023,  (formerly Twitter):"
"We remain committed to our partnership with OpenAI (OAI) and have confidence in our product roadmap, our ability to continue to innovate with everything we announced at Microsoft Ignite, and in continuing to support our customers and partners. We look forward to getting to know Emmett Shear and OAI‚Äôs new leadership team and working with them. And  We look forward to moving quickly to provide them with the resources needed for their success."
"Microsoft nearly  OpenAI for $0! That‚Äôs some serious business Jujutsu."
"In the end, after 12 days of very public corporate chaos,  as if nothing happened (save the firing of the rest of the board)."
"With all the drama and uncertainty resolved, you may say, ‚Äúit all worked out in the end, right? So what‚Äôs the problem?‚Äù"
"This highlights the risk of building  critical business system on a product offered and hosted by an external company. When we do that, we implicitly take on all of that company‚Äôs risks in addition to the risks our business already has! In this case, it‚Äôs taking on all the risks of OpenAI while getting none of their financial benefits!"
""
"The thing big AI providers like OpenAI and Google seem to fear most is competition from open source AI models. And they should be afraid. Open source AI models continue to develop at a rapid pace (there‚Äôs huge incremental improvements on a weekly basis) and, most importantly, they can be self-hosted."
"Additionally, it‚Äôs not out of reach for us to  a general model to better fit our  needs by adding and removing capabilities rather than hope that the capabilities we need suddenly manifest for us."
"Doesn‚Äôt this all sound like the classic argument in favor of open source?"
"If we have the model and can host it ourselves, no one can take it away. When we self-host it, we are protected from:"
"service interruptions from an external provider for a critical system"
"Using an open source and self-hosted model insulates us from these external risks."
""
"Getting dedicated access to a GPU is more expensive than renting limited time on OpenAI‚Äôs servers. That‚Äôs why a hobby or personal project is better off paying for the brief bits of time when needed."
"But let‚Äôs face it."
"If you really want to integrate AI into your business, you need to host your own models. You can‚Äôt control third party privacy policies, but you can control your own policies when you are the one doing your own inference with your own models. Ideally this means getting your own GPUs and incurring the capital expenditure and operations expenditures, but thankfully we‚Äôre in the future. We have the cloud now. There‚Äôs many options you can use for renting GPU access from other companies. This is supported in the big clouds as well as Fly.io. You can check out our ."
""
""
"It‚Äôs important to take advantage of AI in our applications so we can reap the benefits. It can give us an important edge in the market! However, we should be extra cautious of building any critical features on a product offered by a proprietary external business. ."
"Your specific level of risk depends on how central the AI aspect is to your business. If it‚Äôs a central component like in my Personal AI Fitness Trainer, then I risk losing all my customers and even the company if any of the above mentioned risk factors happen to  my AI provider. That‚Äôs an existential risk that I can‚Äôt do anything about without taking emergency heroic efforts."
"If the AI is sprinkled around the edges of the business, then suddenly losing it won‚Äôt kill the company. However, if the AI isn‚Äôt being well utilized, then the business may be at risk to competitors who place a bigger bet and take a bigger swing with AI."
"Oh, what interesting times we live in! üôÉ"
""
""
""
"Scaling discussions often lead to recommendations to add more memory, more CPU, more machines, more regions, more, more, more."
"This post is different.  It focuses instead on the idea of decomposing parts of your applications into event handlers, starting up Machines to handle the events when needed, and stopping them when the event is done.  Along the way we will see how a few built in Fly.io primitives make this easy."
"To make the discussion concrete, we are going to focus on a common requirement: generation of PDFs from web pages.  The code that we will introduce isn‚Äôt merely an example produced in support of a blog post - rather it is code that was extracted from a production application, and packaged up into an appliance that you can deploy in minutes to add PDF generation to your existing application."
"But before we dive in, let‚Äôs back up a bit."
""
"Normally the way this is approached is to start with a tool like , , , , or .  These and other tools ultimately launch a browser like ."
"Now a few things about Chrome itself:"
"It likely is bigger than your entire web server."
"Taken together, this makes splitting PDF generation into a completely separate application an easy win.  With a smaller image, your application will start faster.  Memory usage will be more predictable, and the memory needed to generate PDFs will only be allocated when needed and can be scaled separately."
""
"Without further ado, the entire application is available on GitHub as .  Installation is a simple matter of: clone repository, create app, adjust config, deploy, and scale."
"Next, you will need to integrate this into your application.  All that is needed is to reply to requests that are intended to produce a PDF with a  response header.  This can either be done on individual application routes / controller actions, or it can be done globally via either middleware or a front end like .  You can find a few examples in the ."
"And, that‚Äôs it.  The most you might consider doing is issuing an additional HTTP request in anticipation of the user selecting what they want to print as this will ."
""
"If you don‚Äôt have an application handy, you can try a demo.  Go to .  Click on Demo, then on Publish, and finally on Invoices to see a PDF.  The PDF you see will likely be underwhelming as you would need to enter students, entries, packages and options to fill out the page.  But click refresh anyway and see how fast it responds.  If you want to explore further, links to the  and  can be found on the front page."
""
"The basic flow starts with a request comes into your app for a PDF.  That request is replayed to the PDF appliance.  A Chrome instance in that app then issues a second request to your app for the same URL minus the  extension and then converts the HTML which it receives in response to a PDF.  That PDF is then returned as the response to the original request."
"A single Google Chrome instance per machine will be reused across all requests, which itself is faster than starting a new instance per request.  As all HTTP headers will be passed back to your application, this will seamlessly work with your existing session, cookies, and basic authentication."
"Starting up a machine on demand is handled by the  setting in your .  With this in place, machines can confidently exit when idle, secure in the knowledge that they will be restarted when needed.  See the  for more information on scaling."
"Note that different machines can use different languages and frameworks.  This code is written in JavaScript and runs on Bun.  It was designed to support a Ruby on Rails app, but can be used with any app."
""
"If your app is small and your usage is low, scaling may not be much of a
concern, but as your need grow your first instinct shouldn‚Äôt merely be to throw
more hardware at the problem, but rather to partition the problem so that each
machine has a somewhat predictable capacity."
"Do this by taking a look at your application, and look for requests that are
somehow different than the rest.  Streaming audio and video files, handling websockets,
converting text to speech or performing other AI processing, long running
‚Äúbackground‚Äù computation, fetching static pages, producing PDFs, and updating
databases all have different profiles in terms of server load."
"It might even be helpful ‚Äì purely as a thought experiment ‚Äì to think of
replacing your main server with a proxy that does nothing more than route
requests to separate machines based on the type of workload performed."
"Once you have come up with an allocation of functions performed to pools of
machines, Fly-Replay is but one tool available to you.  There is also a
 that will
enable you to orchestrate whatever topology you can come up with.

gives a preview of what that would look like with Laravel."
""
""
""
"Previously when you ran , you got asked a bunch of hopefully relevant questions to help you get your app up and running. We‚Äôve taken a lot of the guesswork out of the process and made it a lot more streamlined. It turns out that even though Fly.io developers use a variety of frameworks, languages, and toolchains you can fold most of them into a few basic infrastructure shapes."
""
"Now when you run , the CLI will infer what you want based on the source code of your application. For example, if you have a Rails app with SQLite, it‚Äôll give you an opinionated set of defaults that you can build from. If you don‚Äôt, it‚Äôll give you other options so you can craft the infrastructure you need. I took one of my older applications named  and launched it with the new flow. Here‚Äôs what it looks like:"
"If the settings it guessed are good enough, you can launch it into the cloud. If not, then you‚Äôll be taken to a webpage where you can confirm or change the settings it guessed."
"Once you say yes or confirm on the web, your app will get built and deployed (unless you asked it not to with ). You‚Äôll get a link to your app so you can go check it out. It‚Äôs that easy."
""
"We hope that this can help you look before you  into the wild unknowns of the cloud."
"Got any ideas or comments on how we can make this even smoother? Get in touch on our . We‚Äôd love to hear from you."
""
""
""
"I‚Äôm Xe Iaso. I‚Äôm a writer, technical educator, and philosopher who focuses on making technology easy to understand and scale to your needs. I use Fly.io to host my website and in nearly all of my personal projects now. Fly.io allows me to experiment with new ideas quickly and then deploy them to the world with ease."
""
"Fly.io lets you host your applications in data centers close to your users. Fly.io also lets you have rolling updates of your programs and facilitates easy communication between your services inside and outside of your organization‚Äôs private network."
"I use Fly.io to host my blog, its CDN (named XeDN for reasons which are an exercise for the reader), and a bunch of other supporting services that help make it run. It is easily the most fun I‚Äôve had deploying things since I worked at Heroku."
""
"My blog is made up of several parts: the backend blog server and the CDN. Both are written in Go, my favorite programming language. The back-end blog server runs in Toronto, but XeDN runs in 35 datacenters worldwide. I plan to eventually move my blog to be served from XeDN, but for right now it‚Äôs still comfortably running off of a single server in Toronto."
"Overall, my website‚Äôs architecture looks like this. My website listens for updates from Patreon and GitHub to trigger rebuilds because of its . When I am working on new posts or building new assets, I upload them to Backblaze B2. Anytime someone tries to access one of the files on a XeDN node, it will download it from Backblaze B2 if it doesn‚Äôt have it locally already."
"With Fly.io, I don‚Äôt have to worry about the user experience being degraded when servers go down. If any individual XeDN server goes down, I can rely on the other XeDN servers worldwide to pick up the slack thanks to the fact that Fly.io will shunt the traffic to the servers that aren‚Äôt down. Combine this with some very aggressive caching logic for things like video assets, I can make sure that my blog is fast for everyone, no matter where they are in the world."
"Of course, it doesn‚Äôt end here. My CDN server is the back end that helps make my other projects work too. I spent some time working on a  for all of my web properties, and I  so that I can use it in every project of mine. This allows me to integrate it into other projects like  without having to do anything special."
""
"I like making projects that aren‚Äôt entirely serious. I love using these projects to explore aspects and bits of technology that I would have never gotten to play with before. One of these is , a project I used to explore what a ‚Äúdead internet‚Äù powered by AI could look like."
"Every 12 hours, Ars√®ne will have the ChatGPT API generate new posts and then use Stable Diffusion to create a (hopefully relevant) illustration for that post. I run a copy of the  Stable Diffusion API in my private network. When Ars√®ne generates an image, it reaches out to that Stable Diffusion API directly over that private network to make the calls it needs. Since XeDN is in the same private network, I can also have Ars√®ne send the images there to be cached and served all over the world."
"Here‚Äôs what the total flow looks like:"
"This means that when I am creating things, I am not just making one-off things that don‚Äôt work with each other. I am creating individual building blocks that interoperate with each other. I am creating opportunities for me to reuse my infrastructure to create brand new things that are robust and scalable with minimal effort on my end."
""
"I have some other projects that I‚Äôm working on that I don‚Äôt want to get into too much detail about yet, but it‚Äôs going to mostly involve transforming the basic ideas of using my CDN for distributing things and a webserver for sending HTML to users in new and interesting ways. I love using Fly.io for this because I am just allowed to create things instead of having to worry about how to implement it, where state is going to be stored, or how I‚Äôm going to scale it."
""
""
"If you haven‚Äôt given Fly.io a try yet, you‚Äôre really missing out. It is utterly trivial to deploy your application across the globe. Not to mention, when your applications are idle, you can have them scale down to zero copies. This means that you only pay for what you actually use. I don‚Äôt have to worry about overpaying for my blog by having a giant server in Helsinki running 24/7, even though I‚Äôm only using a small sliver of it."
"If you want to learn more about Fly.io, you can check out . My CDN cost me nothing until I started adding cover art per post and the  with furry stickers. It definitely went over the bar when I started uploading video. I can see it scaling in the future as my demands scale too."
"Of course, this is barely even scratching the surface. Stay tuned for secret tricks you can use to dynamically spin up and spin down machines as you need. Imagine uploading an image, automatically creating a machine to handle compressing it, and uploading it to your storage back end. Imagine what you could do if compute was a faucet that you could turn on and off as you needed it."
"You can do it on Fly.io. Try it today, you can run an app on a 256 MB Machine for free. XeDN ran on three 256 MB Machines for a year. Ars√®ne still runs on a 256 MB Machine to this day. It‚Äôs more than enough for what you‚Äôre going to do. And when it isn‚Äôt, scaling up is ."
""
""
""
"Fly.io has GPU Machines, which means we can finally    run AI workloads with just a few API calls."
"This is exciting! Running GPU workloads yourself is useful when the community‚Ñ¢ builds upon available models to make them faster, more useful, or less restrictive than first-party APIs."
"One such tool is the , which is conveniently packaged in a way that makes it a good candidate to use on Fly GPU Machines."
"Let‚Äôs see how to use Fly.io GPU by spinning up Whisper Webservice."
""
"Whisper is OpenAI‚Äôs voice recognition service - it‚Äôs used for audio transcription. To use it anywhere that‚Äôs not OpenAI‚Äôs platform, you need , a few GB of storage, and (preferably) a GPU."
"The aforementioned  packages this up for us, while making Whisper faster, more useful, and less restricted than OpenAI‚Äôs API:"
"It provides a web API on top of Whisper‚Äôs Python library"
"Luckily for us, and totally  why I chose this as an example - the project provides GPU-friendly Docker images. We‚Äôll use those to spin up Fly GPU Machines and process some audio files."
"(I‚Äôll also show examples of making your own Docker image!)"
""
"Spinning up a GPU Machine is very similar to any other Machine. The main difference is the new ‚ÄúGPU kind‚Äù option (), which takes 2 possible values:"
""
"These are 2 flavors of Nvidia A100 GPUs, the difference worth caring about is  vs  GB of  memory (here‚Äôs )."
"We‚Äôll create machines using  because we don‚Äôt need 80 freakin‚Äô GB for what we‚Äôre doing."
"Using  is a great way to run a GPU Machine. We‚Äôll make an app and run the conveniently created  that supports Nvidia GPUs. The  commands will default us into a  server size (8 CPUs, 16G ram) unless we specify something different."
"AI model files are big. Docker images ideally aren‚Äôt big - sending huge layers across the network angers the spiteful networking gods. If you shove models into your Docker images, you  have a bad time."
"We suggest creating a Fly Volume and making your Docker image download needed models when it first spins up. The Whisper service (and in my experience, OpenAI‚Äôs Python library) does that for us."
"So, we‚Äôll create a volume to house (and cache) the models. In the case of the Whisper project, the models get placed in  on its first boot, and so we‚Äôll mount our disk there."
"Alright, let‚Äôs create a GPU Machine. Here‚Äôs what the process looks like:"
""
"That‚Äôs all pretty standard for Fly Machines,  for the  flags used both for volume  Machine creation. Volumes are pinned to specific hosts - using this flag tells Fly.io to create the volume on a GPU host. Assuming we set the same region (), creating a GPU Machine with the just-created volume will tell Fly.io to place the Machine on the same host as the volume."
"As my machine started up, I saw a log line , which ended up being an issue of timing. Once everything is running, I was able to see things were working by using  and running command  to confirm that the VM had a GPU. It also listed the running web service (Python in this case) was running as a GPU process."
"Once everything is running, you should be able to head to  and view it in the browser."
"The Whisper Webservice UI will let you try out individual calls in its API. This will also give you the information you need to make those calls from your code. There‚Äôs a link to the API specification (e.g. ) you can use to, say, have  in your language of choice."
""
"If you want to automate this, you can use the  (spec )."
"An easy way to get started is to spy on the API requests  is making:"
""
"This helped me figure out why my own initial API attempts failed - it turns out we need some extra parameters in the  portion of the request JSON for creating a volume, and the  section for creating a Machine."
"For both volumes and Machines, we set the  the same way we did in our  command. However we  need the  to be set. Additionally, when creating a Machine, we need to set  and  to  for  Machines."
""
"After that we can assign the app some IPs. You can use  for this, or the  You can once again use debug mode with  to see what API calls it makes. Side note: Eventually the Machines REST API will include the ability to allocate IP addresses."
""
"If you‚Äôre doing this type of work for your business, you may want to keep these Machines inside a private network anyway, in which case you won‚Äôt be assigning it IP addresses."
""
"There is, luckily (for me, a hardware ignoramus) less dark magic to making GPU-friendly Docker images than you might think. Basically you need to just install the correct Nvidia drivers."
"A way to cheat at this is to run , but you‚Äôre made of sterner stuff, you can also start with a base Ubuntu image and install your own."
"While the Whisper webservice image is based on , I got Whisper (plain, not the webservice) working with :"
""
"You can find a full, ."
""
"AI feels a bit different than previous trends in that it has immediately-obvious benefits. No one needs to throw around catchy phrases with a wink-wink nudge-nudge  (‚Äúwe like the art‚Äù) for us to find value."
"Since AI workloads work most efficiently in GPUs, they remain a hot commodity. For those of us who didn‚Äôt purchase enough $NVDA to retire, we can bring more value to our businesses by adding in AI."
"Fly Machines have always been a great little piece of tech to run ‚Äúephemeral compute workloads‚Äù (wait, do I work at AWS!?) - and this is what I like about GPU Machines. You can mix and match all sorts of AI stuff together to make a chain of useful tools!"
""
""
""
"My favorite part about building tools is discovering their unintended uses. It‚Äôs like starting to write a murder mystery book but you have no idea who the killer is!"
"History is filled with examples of these accidental discoveries: WD-40 was originally  and now it fixes your squeaky doorknob. Bubble wrap was  and now it protects your Amazon packages."
"When we started writing , a distributed SQLite database, we thought it would be used to distribute data geographically so users in, say, Bucharest see response times as fast as users in San Jose. And for the most part, that‚Äôs what LiteFS users are doing."
"But we discovered another unexpected use: replacing the API layer between services with SQLite databases."
""
"In the early days of LiteFS development, we wanted to find a real-world test bed for our tool so we could smoke out any bugs that we didn‚Äôt find during automated tests. Part of  our existing infrastructure is a program called  that gossips state between all our servers. Corrosion tracks VM statuses, health checks, and a plethora of other information for each server and communicates this info with other servers so they can make intelligent decisions about request routing and VM placement. Corrosion keeps a fast, local copy of all this data in a SQLite database."
"So we set up a Corrosion instance that also ran on top of LiteFS. This helped root out some bugs but we also found another use for it: making Corrosion accessible to our internal services."
""
"The typical approach to making data available between services is to spend weeks designing an API and then building a service around it. Your API design needs to take into account the different use cases of each consuming service so that it can deliver the data it needs efficiently. You don‚Äôt want your clients making a dozen API calls for every request!"
"A different approach is to skip the API design entirely and just ship the entire database to your client. You don‚Äôt need to consider the consuming service‚Äôs access patterns as they can use vanilla SQL to query and join whatever data their heart desires. That‚Äôs what we did using LiteFS."
"While we could have set up each downstream service as a Corrosion node, gossip protocols can be chatty and we really just needed a one-way stream of updates. Setting up a read-only LiteFS instance for a new service is simple‚Äîit just needs the hostname of the upstream primary node to connect to:"
""
"And voila! You have a full, read-only copy of the database on your app."
""
"API design is notoriously difficult as it‚Äôs hard to know what your consuming services will need. Query languages such as  have even been invented for this specific problem!"
"However, GraphQL has its own limitations. It‚Äôs good for fetching raw data but it lacks built-in  & advanced querying capabilities like . GraphQL is typically layered on top of an existing relational database that uses SQL. So why not just use SQL?"
"Additionally, performing queries on your service means that you need to handle multiple tenants competing for compute resources. Managing these tenants involves rate limiting and query timeouts so that no one client consumes all the resources."
"By pushing a read-only copy of the database to clients,  these restrictions aren‚Äôt a concern anymore. A tenant can use 100% of its CPU for hours if it wants to. It won‚Äôt adversely affect any other tenant because the query is running on its own hardware."
""
"There‚Äôs always trade-offs with any technology and shipping read-only replicas is no different. One obvious limitation of read-only replicas is that they‚Äôre read-only. If your clients need to update data, they‚Äôll still need an API for those mutations."
"A less obvious downside is that the contract for a database can be less strict than an API. One benefit to an API layer is that you can change the underlying database structure but still massage data to look the same to clients. When you‚Äôre shipping the raw database, that becomes more difficult. Fortunately, many database changes, such as adding columns to a table, are backwards compatible so clients don‚Äôt need to change their code. Database views are also a great way to reshape data so it stays consistent‚Äîeven when the underlying tables change."
"Finally, shipping a database limits your ability to restrict access to data. If you have a multi-tenant database, you can‚Äôt ship that database without the client seeing all the data. One workaround for this is to use a database per tenant. SQLite databases are lightweight since they are just files on disk. This also has the added benefit of preventing queries in your application from accidentally fetching data across tenants."
""
"While this approach has worked well for some internal tooling, how does this look in the broader world of software? APIs are likely stick around for the foreseeable future so providing read-only database replicas make sense for specific use cases where those APIs aren‚Äôt a great fit."
"Imagine being able to query all your Stripe data or your GitHub data from a local database. You could join that data on to your own dataset and perform fast queries on your own hardware."
"While companies such as Stripe or GitHub likely colocate their tenant data into one database, many companies run an event bus using tools like Kafka which could allow them to generate per-tenant SQLite databases to then stream to customers."
"Pushing queries out to the end user has huge benefits for both the data provider & the data consumer in terms of flexibility and power."
""
""
""
"We‚Äôve been using Sentry since the dawn of the internet. Or at least as far back as the  of the Higgs boson. Project to project, the familiar Sentry issue detail screen has been our faithful debugging companion."
"Today it‚Äôs no exception: All of our Golang, Elixir, Ruby and Rust services report dutifully to Sentry."
"So, it felt natural to integrate Sentry as the default error monitoring tool. All new deployments on Fly.io get a Sentry project provisioned automatically. Existing apps can grab theirs with ."
"Each Fly.io organization receives, for one year, a generous monthly quota:"
"50,000 Error events"
"Once your app is instrumented, you‚Äôll automatically get notified of production errors, latency issues, and crashes as soon as they occur in production. Sentry‚Äôs Team plan also gives you access to over 40 integrations, unlimited seats, and custom alerting."
""
"To see Sentry in action, let‚Äôs launch our . Yes kids, Rails is old school, and it‚Äôs the easiest framework to auto-instrument."
"When  detects a Rails app, it‚Äôs automatically setup to use a freshly minted Sentry project. Gems are installed, initializers planted, and finally, the  secret is set for deployment. We redacted some output for brevity."
""
""
"Now, having Sentry configured at launch time means that deployment errors are captured early. This is useful for situations where apps fail to boot, run out of memory, and so on."
"Now let‚Äôs force an application exception. We visit the app root, which goes Boom, thanks to some hastily written Ruby code."
""
"Oh shucks. Something went wrong. But, I got an email about this error."
"We could click ‚ÄúView on Sentry‚Äù. Instead, let‚Äôs use  to send us to the Sentry issues dashboard."
""
"We click through to this specific issue."
"We successfully debugged our issue. The takeaway: don‚Äôt raise when you can call."
"Error tracking on Sentry is just scratching the surface. Check out their , ,  and ."
""
"For our next trick, we‚Äôll be tracking Fly.io releases in Sentry, so Sentry can link issues to their  feature.
We‚Äôll also send events like  to Sentry. The possibilities are endless."
"Got ideas or comments? Get in touch on our ."
""
""
"When we started the  project a year ago, we started more with an ideal in mind rather than a specific implementation. We wanted to make it possible to not only run distributed SQLite but we also wanted to make it‚Ä¶ ‚Ä¶ easy!"
"There were hurdles that we expected to be hard, such as intercepting SQLite transaction boundaries via syscalls or shipping logs around the world while ensuring data integrity. But there was one hurdle that was unexpectedly hard: maintaining a consistent view from the application‚Äôs perspective."
"LiteFS requires write transactions to only be performed at the primary node and then those transactions are shipped back to replicas instantaneously. Well, almost instantaneously. And therein lies the crux of our problem."
"Let‚Äôs say your user sends a write request to write to the primary node in Madrid and the user‚Äôs next read request goes to a local read-only replica in Rio de Janeiro. Most of the time LiteFS completes replication quickly and everything is fine. But if your request arrives a few milliseconds before data is replicated, then your user sees the database state from before the write occurred. That‚Äôs no good."
"How exactly do we handle that when our database lives outside the user‚Äôs application?"
""
"Our first plan was to let LiteFS users manage consistency themselves. Every application may have different needs and, honestly, we didn‚Äôt have a better plan at the time. However, once we started explaining how to track replication state, it became obvious that it was going to be an untenable approach. Let‚Äôs start with a primer and you‚Äôll understand why."
"Every node in LiteFS maintains a  for each database which consists of two values:"
"Transaction ID (TXID): An identifier that monotonically increases with every successful write transaction."
"You can read the current position from your LiteFS mount from the  file:"
""
"This example shows that we are at TXID  (or 4,343,691 in decimal) and the checksum of our whole database after the transaction is . A replica can detect how far it‚Äôs lagging behind by comparing its position to the primary‚Äôs position. Typically, a monotonic transaction ID doesn‚Äôt work in asynchronous replication systems like LiteFS but when we couple it with a checksum it allows us to check for divergence so the pair works surprisingly well."
"LiteFS handles the replication position internally, however, it would be up to the application to check it to ensure that its clients saw a consistent view. This meant that the application would have needed to have its clients track the TXID from their last write to the primary and then the application would have to wait until its local replication caught up to that position before it could serve the request."
"That would have been a lot to manage. While you may find the nuts and bolts of replication interesting, sometimes you just want to get your app up and running!"
""
"Teaching distributed systems to each and every LiteFS user was not going to work. So instead, we thought we could tuck that complexity away by providing a LiteFS client library. Just import a package and you‚Äôre done!"
"Libraries are a great way to abstract away the tough parts of a system. For example, nobody wants to roll their own cryptography implementation so they use a library. But LiteFS is a database so it needs to work across all languages which means we needed to implement a library for each language."
"Actually, it‚Äôs worse than that. We need to act as a traffic cop to redirect incoming client requests to make sure they arrive at the primary node for writes or that they see a consistent view on a replica for reads. We aren‚Äôt able to redirect writes at the data layer so it‚Äôs typically handled at the HTTP layer. Within each language ecosystem there can be a variety of web server implementations: Ruby has Rails & Sinatra, Go has net/http, gin, fasthttp, and whatever 12 new routers came out this week."
""
"Abstraction often feels like a footgun. Generalizing functionality across multiple situations means that you lose flexibility in specific situations. Sometimes that means you shouldn‚Äôt abstract but sometimes you just haven‚Äôt found the right abstraction layer yet."
"For better or for worse, HTTP & REST-like applications have become the norm in our industry and some of the conventions provide a great layer for LiteFS to build upon. Specifically, the convention of using  requests for reading data and the other methods (, , , etc) for writing data."
"Instead of developers injecting a LiteFS library into their application, we built a thin HTTP proxy that lives in front of the application."
"This approach has let us manage both the incoming client side via HTTP as well as the backend data plane via our FUSE mount. It lets us isolate the application developer from the low-level details of LiteFS replication while making it feel like they‚Äôre developing against vanilla SQLite."
""
"The LiteFS proxy design is simple but effective. As an example, let‚Äôs start with a write request. A user creates a new order so they send a  request to your web app. The LiteFS proxy intercepts the request & parses the HTTP headers to see that it‚Äôs a  write request. If the local node is a replica, the proxy forwards the request to the primary node."
"If the local node is the primary, it‚Äôll pass the request through to the application‚Äôs web server and the request will be processed normally. When the response begins streaming out to the client, the proxy will attach a cookie with the TXID of the newly-written commit."
"When the client then sends a  read request, the LiteFS proxy again intercepts it and parses the headers. It can see the TXID that was set in the cookie on the previous write and the proxy will check it against the replication position of the local replica. If replication has caught up to the client‚Äôs last write transaction, it‚Äôll pass through the request to the application. Otherwise, it‚Äôll wait for the local node to catch up or it will eventually time out. The proxy is built into the  binary so communication with the internal replication state is wicked fast."
""
"The proxy provides another benefit: health checks. Networks and servers don‚Äôt always play nice when they‚Äôre communicating across the world and sometimes they get disconnected. The proxy hooks into the LiteFS built-in heartbeat system to detect lag and it can report the node as unhealthy via a health check URL when this lag exceeds a threshold."
"If you‚Äôre running on Fly.io, we‚Äôll take that node out of rotation when health checks begin reporting issues so users will automatically get routed to a different, healthy replica. When the replica reconnects to the primary, the health check will report as healthy and the node will rejoin."
""
"Despite how well the LiteFS proxy works in most situations, there‚Äôs gonna be times when it doesn‚Äôt quite fit. For example, if your application cannot rely on cookies to track application state then the proxy won‚Äôt work for you."
"There are also frameworks, like , which can rely heavily on websockets for live updates so this circumvents your traditional HTTP request/response approach that LiteFS proxy depends on. Finally, the proxy provides  guarantees which may not work for every application out there."
"In these cases,  to make it work for more use cases! We‚Äôd love to hear your thoughts."
""
"The LiteFS proxy makes it easy to run SQLite applications in multiple regions around the world. You can even run many legacy applications with little to no change in the code."
"If you‚Äôre interested in setting up LiteFS, check out our  guide. You can find additional details about configuring the proxy on our  docs page."
""
""
"You‚Äôve done everything right.  You are well aware of
.
You have multiple redundant machines.  You‚Äôve set up
a regular back up schedule for your database, perhaps even are using
.  You
 to
 or perhaps some other

so you can do forensic analysis should anything go wrong‚Ä¶"
"Then the unexpected happens.  A major network outage causes your application to
misbehave.  What‚Äôs worse is that your logs are missing crucial data from this
point, perhaps because of the same network outage.  Maybe this time you are
lucky and you can find the data you need by using copies of your logs via
 or the monitoring tab on the
 before they
disappear forever."
"So, what is going on here?  Let‚Äôs look at the steps.  Your application writes
logs to STDOUT.  Fly.io will take that output and send it to
.  The  will take that data and
hand it to .  From
there it is shipped to your third party logging provider.  That‚Äôs a lot of
moving parts."
"All that is great, but just like how you have redundant machines in case of
failures, you may want to have redundant logs in addition to the ones fly.io
and the log shipper provide.  Below are two strategies for doing just that.
You can use either or both, and best of all the logs you create will be in
addition to your existing logs."
""
"The following approach is likely the most failsafe, but often the least
convenient: having your primary application on each machine write to a
separate log file in addition to standard out.  This does mean that when
you need this data you will have to fetch it from each machine and it
likely with be rather raw.  But at least it will be there even in the face
of network failures."
"For best results put these logs on a
 so that it survives
a restart, and be prepared to rotate logs as they grow in size so
that they don‚Äôt eventually fill up that volume."
"This approach is necessarily framework specific, but most
frameworks provides some ability to do this.  A Rails example:"
""
"You probably already have the first two lines already in your
 file.  Adjust and add the last
two lines.  That‚Äôs it!  You now have redundant logs."
"See the 
documentation on how to handle log rotation."
"Some pointers for other frameworks:"
""
""
"This approach is less bullet proof but may result in more immediately usable
results.  Instead of using Log Shipper, Vector, and a third party, it is easy
to subscribe directly to NATS and process log entries yourself."
"What you are going to want is a separate app running on a separate machine so
that it doesn‚Äôt go down there are problems with the machine you are monitoring,
or even during the times when you are deploying a new version.  If the
code you write will be writing to disk, you will want a volume."
"Also like with log shipper, you will want to set the following secret:"
""
"Here‚Äôs a minimal JavaScript example that can be run using Node or Bun:"
""
"The above is pretty straightforward.  It connects to NAT, opens a file,
subscribes to logs, parses each message, and writes out selected data
to disk.  This example is in JavaScript, but feel free to reimplement
this basic approach using your favorite language, as NATS supports
."
"Things to watch out for: you don‚Äôt want recursive errors when exceptions
occur during write.  You want to capture errors and reconnect to NATS
when the connection goes down.  You may even want to filter messages.
A more complete example implementing a number of these features can be found
."
""
"Log failures are not common, and perhaps the redundant logs that fly.io already
keeps will be sufficient for your needs.  But it may be worth reviewing what
your exposure is and how to mitigate that exposure should your logs fail at the
worst possible time."
"Hopefully the approaches listed above give you ideas on how to ensure that
you will always have the log data you need even in the most hostile
environment conditions."
""
""
""
"We built some little security thingies. We‚Äôre open sourcing them, and hoping you like them as much as we do. In a nutshell: it‚Äôs a proxy that injects secrets into arbitrary 3rd-party API calls. We could describe it more completely here, but that wouldn‚Äôt be as fun as writing a big long essay about how the thingies came to be, so: buckle up."
"The problem we confront is as old as Rails itself. Our application started simple: some controllers, some models. The only secrets it stored were bcrypt password hashes. But not unlike a pet baby alligator, it grew up. Now it‚Äôs become more unruly than we‚Äôd planned."
"That‚Äôs because frameworks like Rails make it easy to collect secrets: you just create another model for them, , jam that secret into the deployment environment, and call it a day."
"And, at least in less sensitive applications, or even the early days of an app like ours, that can work!"
""
"But for us, not anymore. At the stage we‚Äôre at, all secrets are hazmat. And Rails itself is the portion of our attack surface we‚Äôre least confident about ‚Äì¬†the rest of it is either outside of our trust boundaries, or written in Rust and Go, strongly-typed memory-safe languages that are easy to reason about, and which have never accidentally treated YAML as an executable file format."
"So, a few months back, during an integration with a 3rd party API that relied on OAuth2 tokens, we drew a line: ‚ö°  ‚ö°. This is easier said than done, though: despite prominent ‚Äúthis is not a place of honor‚Äù signs all over the codebase, our Rails API is still where much of the action in our system takes place."
""
"We just gave you one way, probably the most common. Stick ‚Äòem in a model, encrypt them with an environment secret, and watch Dependabot religiously for vulnerabilities in transitively-added libraries you‚Äôve never heard of before."
"Here‚Äôs a second way, probably the second-most popular: use a secrets management system, like  or . These systems, which are great, keep secrets encrypted and allow access based on an intricate access control language, which is great."
"That‚Äôs what we do for customer app secrets, like  and . We use  (for the time being). Our Rails API has an access token for Vault that allows it to set secrets, but not read any of them back, like a kind of diode. A game-over Rails vulnerability might allow an attacker to scramble secrets, but not to easily dump them."
"In the happiest cases with secrets, systems like Vault can keep secret bits from ever touching the application. Customer app secrets are a happy case: Rails never needs to read them, , to inject them into VM environments. In other happy cases, Vault operates on the app‚Äôs behalf: signing a time-limited request URL for AWS, or making a direct request to a known 3rd-party service. Vault calls these features ‚Äú‚Äù, and when you can get away with using them, it‚Äôs hard to do better."
"The catch is, sometimes you can‚Äôt get away with them. For most 3rd parties, Vault has no idea how to interact with them. And most secrets are bearer tokens, not request signatures. The only way to use those kinds of secrets is to read them into app memory. If good code can read a secret from Vault, so can a YAML vulnerability."
""
"So that‚Äôs why there‚Äôs a third way to handle this problem, which is: decompose your application into services so that the parts that have to handle secrets are tiny and well-contained. The bulk of our domain-specific business code can chug along in Rails, and the parts that trade bearer tokens with 3rd parties can be built in a couple hundred lines of Go."
"This is a good approach, too. It‚Äôs just cumbersome, because a big application ends up dealing with lots of different kinds of secrets, making a trusted microservice for each of them is a drag. What you want is to notice some commonality in how 3rd party API secrets are used, and to come up with some possible way of exploiting that."
"We thought long and hard on this and came up with:"
""
"We developed a multipurpose secret-using service called the ."
"is a stateless HTTP proxy that holds the private key of a"
"When we get a new 3rd party API secret, we encrypt it to  public key; we ‚Äútokenize‚Äù it. Our API server can handle the (encrypted) tokenized secret, but it can‚Äôt read or use it directly. Only  can."
"When it comes time to talk to the 3rd party API, Rails does so via . Here‚Äôs how that works:"
"The API request is proxied, as an ordinary HTTP 1.1 request, through ."
"You can think of  as a sort of Vault-style ‚Äúsecret engine‚Äù that happens to capture virtually everything an app needs secrets for. It can even use decrypted secrets to selectively HMAC parts of requests, for APIs that authenticate with signatures instead of bearer tokens."
"Check it out: ."
"Now, our goal is to keep Rails from ever touching secret bits. But, hold on: a game-over Rails vulnerability would give attackers an easy way around : you‚Äôd just proxy requests for a particular secret to a service you ran that collected the plaintext."
"To mitigate that, we built the obvious feature: you can lock requests for specific secrets down to a list of allowed hosts or host regexp patterns."
"We think this approach to handling secrets is pretty similar to how payment processors tokenize payment card information, hence the name. The advantages are straightforward:"
"Secrets are exposed to a much smaller attack surface that doesn‚Äôt include Rails."
""
"When we created , we were motivated by the problem of OAuth2 tokens other services providers gave us, for partnership features we build for mutual customers."
"We‚Äôd also dearly like our customers to use OAuth2/OIDC to log into Fly.io itself; it‚Äôs more secure for them, and gives them the full complement of Google MFA features, meaning we don‚Äôt immediately have to implement the full complement of Google MFA features. Letting people log into Fly.io with a Google OAuth token means we have to keep track of people‚Äôs OAuth tokens. That sounds like a job for the !"
"But there‚Äôs a catch: acquiring those OAuth tokens in the first place means doing the OAuth2 dance, which means that for a brief window of time, Rails is handling hazmat. We‚Äôd like to close that window."
"Enter the ."
"The job of the  is to perform the OAuth2 dance on behalf of Rails, and then use the output of that process (the OAuth2 bearer token yielded from the OAuth2 code flow, which you can ) to drive the ."
"In other words, where we‚Äôd otherwise explicitly encrypt secrets to be tokenized a-priori, the  does that on the fly, passing tokenized OAuth2 credentials back to Rails. Those‚Ä¶ tokenized tokens can only be used through the  proxy, which is the only component in our system with the private key that unseals them."
"We think this is a pretty neat trick. The  itself is tiny, even smaller than the  (), and essentially stateless; in fact, pretty much everything in this system is minimally stateful, except Rails, which is great at being stateful. We even keep almost all of OAuth2 out of Rails and confined to Go code (where it‚Äôs practically the hello-world of Go OAuth2 libraries)."
"A nice side effect-slash-validation of this design: once we got it working for Google, it became a super easy project to get OAuth2 logins working for other providers."
""
"We‚Äôre psyched for a bunch of reasons:"
"We‚Äôve got a clear path to rolling out SSO logins."
"These are standalone tools with no real dependencies on Fly.io, so they‚Äôre easy for us to open source. Which is what we did: if they sound useful to you, check out the¬†¬†and¬†¬†repositories for instructions on deploying and using these services yourself."
""
""
".  Fly.io is making preparations."
"Previously, we stated that , and we understandably started with Node.js.  While that work is ongoing, it makes sense to start expanding to other runtimes."
"Bun is the obvious next choice given it ."
"Starting with  version 0.1.54 and  version 0.3.3, you can launch and deploy bun applications using  and ,
provided:"
"You‚Äôve installed bun version 0.5.3 or later"
"Basically, if you can run  and , you have all you need to deploy your application on fly.io."
"We also have a  that you can deploy."
"Be forewarned that everything is beta at this point.  Some issues we encountered while preparing this support:"
".  Our Dockerfiles use this to remove development dependencies after running .  Of course with bun you are less likely to need a build step as TS and JSX are built in."
"Undoubtedly there will be bugs in fly‚Äôs dockerfile generator too.  But as Node.js and Bun share the same generator, fixes that are made for either framework will generally benefit both."
"If you see a problem, 
,
, or
."
""
""
""
"We love , and we‚Äôre all about running apps close to users. That‚Äôs why we created LiteFS: an open source distributed SQLite database that lives on the same filesystem as your application, and replicates data to all the nodes in your app cluster."
"With LiteFS, you get the simplicity, flexibility, and lightning-fast local reads of working with vanilla SQLite, but distributed (so it‚Äôs close to your users)! It‚Äôs especially great for read-heavy web applications. Learn more about LiteFS in the  and in ."
"At Fly.io we‚Äôve been using LiteFS internally for a while now, and it‚Äôs awesome!"
"However, something is missing: disaster recovery. Because it‚Äôs local to your app, you don‚Äôt need to‚Äîindeed can't‚Äîpay someone to manage your LiteFS cluster, which means no managed backups. Until now, you‚Äôve had to : take regular snapshots, store them somewhere, figure out a retention policy, that sort of thing."
"This also means you can only restore from a point in time when you happen to have taken a snapshot, and you likely need to limit how frequently you snapshot for cost reasons. Wouldn‚Äôt it be cool if you could have super-frequent reliable backups to restore from, without having to implement it yourself?"
"Well, that‚Äôs why we‚Äôre launching, in preview, LiteFS Cloud: backups and restores for LiteFS, managed by Fly.io. It gives you painless and reliable backups, with the equivalent of a snapshot every five minutes (8760 snapshots per month!), whether your database is hosted with us, or anywhere else."
""
"There‚Äôs a few steps to get started:"
"Upgrade LiteFS to version 0.5.1 or greater"
", but that‚Äôs literally it. Then your database will start automagically backing up, we‚Äôll manage the backups for you, and you‚Äôll be able to restore your database near instantaneously to any point in time in the last 30 days (with 5 minute granularity)."
"I want to say that again because I think it‚Äôs just wild ‚Äì you can restore your database to . ."
"Speaking of restores‚Äîyou can do those in the dashboard too. You pick a date and time, and we‚Äôll take the most recent snapshot before that timestamp and restore it. This will take a couple of seconds (or less)."
"We‚Äôll introduce pricing in the coming months, but for now LiteFS Cloud is in preview and is free to use. Please go check it out, and let us know how it goes!"
""
"LiteFS is built on a simple file format called  which is designed for fast, flexible replication and recovery in LiteFS itself and in LiteFS Cloud."
"But first, let‚Äôs start off with what an LTX file represents: ."
"When you commit a write transaction in SQLite, it updates one or more fixed-sized blocks called pages. By default, these are 4KB in size. An LTX file is simply a sorted list of these changed pages. Whenever you perform a transaction in SQLite, LiteFS will build an LTX file for that transaction."
"The interesting part of LTX is that contiguous sets of LTX files can be merged together into one LTX file. This merge process is called ."
"For example, let‚Äôs say you have 3 transactions in a row that update the following set of pages:"
"LTX A: Pages 1, 5, 7"
"With LTX compaction, you avoid the duplicate work that comes from overwriting the same pages one transaction at a time. Instead, one LTX file for transactions A through C contains the last version of each page, so the pages are stored and updated only once:"
"That, in a nutshell, is how a single-level compaction works."
""
"Compactions let us take changes for a bunch of transactions and smoosh them down into a single, small file. That‚Äôs cool and all but how does that give us fast point-in-time restores? By the magic of multi-level compactions!"
"Compaction levels are progressively larger time intervals that we roll up transaction data. In the following illustration, you can see that the highest level (L3) starts with a full snapshot of the database. This occurs daily and it‚Äôs our starting point during a restore."
"Next, we have an hourly compaction level called L2 so there will be an LTX file with page changes between midnight and 1am, and then another file for 1am to 2am, etc. Below that is L1 which holds 5-minute intervals of data."
"When a restore is requested for a specific timestamp, we can determine a minimal set of LTX files to replay. For example, if we restored to January 10th at 8:15am we would grab the following files:"
"Start with the snapshot for January 10th."
"Since LTX files are sorted by page number, we can perform a streaming merge of these  twelve files and end up with the state of the database at the given timestamp."
""
"One of the primary goals of LiteFS is to be simple to use. However, that‚Äôs not an easy goal for a distributed database when our industry is moving more and more towards highly dynamic and ephemeral infrastructure. Traditional consensus algorithms require stable membership and adjusting the member set can be complicated."
"With LiteFS, we chose to use async replication as the primary mode of operation. This has some trade-offs in durability guarantees but it makes the cluster much simpler to operate. LiteFS Cloud alleviates many of these trade-offs of async replication by writing data out to high-durability, high-availability object storage‚Äîfor now, we‚Äôre using S3."
"However, we don‚Äôt write every individual LTX file to object storage immediately. The latency is too high and it‚Äôs not cost effective when you write a lot of transactions. Instead, the LiteFS primary node will batch up its changes every second and send a single, compacted LTX file to LiteFS Cloud. Once there, LiteFS Cloud will batch these 1-second files together and flush them to storage periodically."
"We track the ID of the latest transaction that‚Äôs been flushed, and we call this the ‚Äúhigh water mark‚Äù or HWM. This transaction ID is propagated back down to the nodes of the LiteFS cluster so we can ensure that the transaction file is not removed from any node until it is safely persisted in object storage. With this approach, we have multiple layers of redundancy in case your LiteFS cluster can‚Äôt communicate with LiteFS Cloud or if we can‚Äôt communicate with S3."
""
"We have a small team dedicated to LiteFS Cloud, and we‚Äôre chugging away at new exciting features! Right now, LiteFS Cloud is really just backups and restores, but we are working on a lot of other cool stuff:"
"Upload your database in the Fly.io dashboard. This way you don‚Äôt have to worry about figuring out how to initialize your database when you first deploy it, just upload the database in the dashboard and LiteFS will pull it from LiteFS Cloud."
"We‚Äôre really excited about the future of LiteFS Cloud, so we wanted to share what we‚Äôre thinking. We‚Äôd also love to hear any feedback you have about these ideas that might inform our work."
""
""
""
"Why do startups write announcements like these? We went back and forth on it. There are lots of reasons, most of them dumb."
"Our first reason is obvious, and mercenary. It‚Äôs the same reason we write anything: to woo customers. We‚Äôre all adults here, we can talk about this stuff, right? There are customers who are comfortable engaging with tiny Fly.io, and others who are comfortable engaging with the Fly.io that raised an additional $70MM led by EQT ventures. Alcoa: ring us up!"
"More compellingly, it‚Äôs an opportunity to gaze deeply into our own navels. We‚Äôve been , for years. We evolved, and got religion about a particular vision of what we‚Äôre building. We shared that with investors, and they bought it (suckers). Now we‚Äôll share with you."
""
"Here‚Äôs what we believed in 2020: apps work better when they run closer to their users. Some kinds of apps, like video or real-time presence, can‚Äôt be done without physical locality. So, that‚Äôs what we expected to talk about on our : WebRTC, edge caching, game servers."
"What people actually wanted to talk about, though? Databases."
"Here‚Äôs what we missed: we thought there was a particular kind of ‚Äúedgy‚Äù app that demanded global deployment. But it turns out, most apps want to be edgy‚Ä¶ if it‚Äôs easy."
"What‚Äôs going on here? Why is edge deployment table stakes for a game server and an untenable science project for an online bookstore? We think it‚Äôs because game servers have to be edgy, and online bookstores don‚Äôt. The game server team will bang on  edge deployment until it‚Äôs solved. The bookstore team will try for about two hours, not find a clear path forward, and then give up and move on to other things."
"The result of this is an Internet where all of the world‚Äôs CRUD apps are hosted in Loudoun County, VA (motto: ‚Äúwhere tradition meets innovation‚Äù), at Amazon‚Äôs  in Ashburn, a city with so many Rails apps that one of them was elected to the county Board of Supervisors."
"We think everybody understands that it‚Äôd be better to run close to users rather than in the Internet‚Äôs least worst data center. But with ordinary tooling, getting an app running in more than one city at the same time isn‚Äôt a two-hour problem: in two hours, you‚Äôll learn that it‚Äôs possible to run simultaneously in Sydney, Frankfurt, and Dallas, but not how to do it, or how long it‚Äôll take."
"So our bet is simple: with the right platform and toolchain, people building bookstores, sandwich rating apps, music recommenders, mailing list managers for churches, and every other kind of app will build apps that run fast globally. Not just walking distance from Carolina Brothers BBQ in Ashburn, but in Chicago, or Sydney, or Singapore, or S√£o Paulo. Because being fast in more than one city at the same time is a super valuable feature!"
"We think this pattern holds for a lot of things. We‚Äôre going to track those things down and build them."
"For example: sandboxing, code editors and REPLs, and CI/CD applications all have to figure out how to run untrusted customer code. They all figure out how to spin up locked down containers on demand. But being able to spin up a VM on the fly is a super valuable feature for all kinds of apps (as anyone who‚Äôs ever debugged a stuck job queue can attest). Why doesn‚Äôt everybody do it? Because it isn‚Äôt clear after two hours of investigation how to do it. , which makes spinning up a VM as straightforward as calling a function."
"We‚Äôve got more things like this coming. Real-time features and user presence are two-hour features. So is encryption and secret storage. And clustered databases. And hardware-accelerated inferencing."
"There are other companies looking to solve ‚Äútwo hour window‚Äù problems for developers: distributed databases, data locality, storage, AI, app frameworks. If we get Fly.io right, we‚Äôll give those platforms new primitives to build on top of, get new ideas in front of users faster, and ratchet up the quality of every application anywhere."
"Sounds like an investment pitch? Well, yeah, it was."
""
"Here‚Äôs what we think it takes to build this kind of platform:"
"A hardware fleet. Fly.io has always run on its own hardware. There are fun, technical, ‚Äúcontrol your own destiny‚Äù reasons to rack hardware instead of layering on top of commodity clouds. But it‚Äôs really just economics. If you want to get people to build apps on your platform, you need a shot at being around 10 years from now. Hardware is what makes the margins work."
"Those things are all capital intensive, and alongside them we‚Äôd like to place more bets: on advanced storage, on security capabilities, on new kinds of hardware. So you see where the money goes."
""
"üé∂ There are two kinds of platform companies üé∂ : the kind where you can sign up online and be playing with them in 5 minutes, and the kind where you can sign up online and get a salesperson to call and quote you a price and arrange a demo."
"üé∂  There are two kinds of platform companies üé∂ : the kind you can figure out without reading the manual, and the kind where publishers have competing books on how to use them, the kind where you can get professionally certified in actually being able to boot up an app on them."
"üé∂  There are two kinds of platform companies üé∂ : the kind where you can get your Python or Rust or Julia code running nicely, and the kind where you find a way to recompile it to Javascript."
"The kind of platform company we want to be hasn‚Äôt changed since 2020. Our features are all generally a command or two in , and they work for any app that can be packaged in a container."
"You can take our word for that, but if you‚Äôve already got a working Docker container for your app, you can put us to the test. From a standing start, you should be able to get it running on Fly.io in single digit minutes, and on every continent in just a minute or two more."
""
""
""
"Last year, while working in what was my day job at the time (before I joined Fly.io!), we had just developed a new internal tool to help an adjacent team with their work. This adjacent team wrote technical content, and they had a lot of issues stemming from differences in library and language versions in the team members‚Äô local environments as compared to our production environment."
"There are a lot of possible solutions to this problem, but because of the unique needs and skillset of this team, we decided to build an app for them to work in, and allow them to just get rid of their local environment entirely. This way, we could ensure that all the versions were exactly as expected, and over time we could also add more assistive features."
"At the start, this was a super-hastily-thrown-together, barely an MVP tool that kinda sorta met the internal users‚Äô needs most of the time. The first version was only good enough because their previous workflow was just so awful ‚Äî it was difficult for us to do worse."
"One thing our new app needed to do, was build and install libraries (the same ones our teammates had been installing locally), and we needed to rebuild them regularly (think, when a user clicks a ‚ÄúBuild‚Äù button in the app)."
"Initially, we simply implemented these builds in the backend directly. This worked great for a little while, and it was nice to only have to deploy one thing. But then we discovered that (1) for some edge cases, our builds were very slow (occasionally over 30 minutes ‚Äî far too slow for the HTTP request cycle‚Ä¶), and (2) some builds took a lot of resources, so occasionally, even after over-provisioning, if two builds came in at once, our backend got killed (and the builds never completed)."
"Based on this less-than-awesome experience, it became clear to us that we needed background jobs!"
"We ended up configuring Celery, as one does (when one is a Python developer anyway). However, this wasn‚Äôt as pain-free as it could have been. There‚Äôs some significant configuration required, and Celery was overkill for our very simple use case."
"Plus ‚Äì those expensive builds? We needed to have a worker (or several workers) available to run them any time, even though we only had a handful of team members using the tool, so most of the time the worker was idle. We were paying for resources we weren‚Äôt using most of the time ‚Äî not at all awesome for a bootstrapped startup!"
"So, how could we have implemented super simple background jobs, and avoid paying for resources we didn‚Äôt need?"
"Well, it turns out that it‚Äôs really pretty easy to implement simple background jobs using Fly Machines! I‚Äôll show you how."
""
"First some background. Fly Machines are lightweight VMs based on  that start up super fast (you can read more details about Machines in ). They also have a convenient and simple API, making them easy to start, stop, and interact with from your code."
"For the purposes of this post, we‚Äôll be building a demo app - a super minimal Flask web application which sends email in a background job (). You can also try out the application at . Note: for demonstration purposes, the application I‚Äôve deployed uses the  function, which doesn‚Äôt actually send an email! You can also deploy your own version with real  credentials, though."
"So, here‚Äôs how our implementation works from a high level:"
"The web application (or a library the web app uses) writes some job parameters to Redis"
"One really cool thing about this implementation is that you only pay for worker resources when your workers are actually, you know, doing work. For infrequent, expensive background jobs, this can make a huge difference in costs!"
"Before we get into the code, we‚Äôll need to set up a few bits of infrastructure. Let‚Äôs check how that‚Äôs done."
""
"I‚Äôll assume you‚Äôve already set up your Fly.io account and installed the  commandline tool. If you haven‚Äôt done that yet, follow these instructions to , , , and then come back here!"
"After you have your Fly.io account set up and  installed locally, you‚Äôll need to create two pieces of infrastructure: a Fly.io App, which the Machines that run the background jobs will belong to, and a Redis instance, which we‚Äôll use to communicate between the web application and the background job Machines."
""
"Fly.io Machines need to be created in an app, so we‚Äôll need to create an app."
""
""
""
""
"Take note of the Redis url that‚Äôs printed after creation. If you forget it, you can see it again using ."
""
"First, let‚Äôs take a look at the code that we‚Äôll run on the Machine:"
""
"You might notice something missing here ‚Äî the code that actually sends the email. You‚Äôll also need to implement the functions that do the work of the background jobs, and include them in the worker library. You can take a look at , to see the implementation for sending an email!"
"Here‚Äôs an example of the task info that might be stored in Redis for sending an email from our demo app:"
""
"We‚Äôre sending the module and function name as strings in the task information in Redis. There are more sophisticated options here, but this approach works for our simple use case!"
""
"Then, let‚Äôs take a look at the code that we‚Äôll use to set up the Machine and kick off the background job:"
""
"We‚Äôll call this code from our web application whenever the POST endpoint (to send an email) is called. This will kick off the job running on a Fly Machine, and return the task id, which is used to retrieve the results!"
""
"When we retrieve the results, we need to first check whether the Machine is still running. If it‚Äôs still running, we can just return a  status, and expect the client will try again later."
"Once the Machine is done, we can retrieve the result that the job wrote to Redis, and return it to the caller!"
""
"In our simple demo web application, we have a  endpoint, which calls this function to retrieve the result and then displays it to the user. If the status is , the user can refresh the page to try again."
""
"After results have been retrieved, you‚Äôll want to clean up: remove the Machine, and delete the values stored in Redis."
""
"And that‚Äôs it! Now we have a super-simple implementation of background jobs using Fly Machines. üéâ"
""
"In this post, I‚Äôve presented a very simple proof of concept implementation of background jobs on Fly.io Machines with Python. For some simple apps, you can use this approach as it is, but there‚Äôs a lot more you could do without very much effort! Here‚Äôs some ideas to get you started:"
"Write a generic Python library for this purpose, which could be reused across different apps."
""
""
"Recapping where we are to date:"
"There are , and fly.io loves them all."
"Picking up where we left off, this blog post will describe literally
dozens (and that‚Äôs actually an understatement as you will soon see) of
considerably more, dare I say it,  frameworks that you can assemble on
your own and deploy to fly.io and elsewhere."
"This can be overwhelming, so to make things easier we are going to define a baseline application that will be reimplemented to take advantage of various tools.  The result will be:"
"Educational.  Seeing a bite sized working example is a great way to learn how a tool works."
"Let‚Äôs get started!"
""
"What we are looking for is a cross between  and , but for a full stack application.  For our purposes, the baseline is a stateful web server.  Ideally one that can be deployed around the globe, and can deliver real time updates.  But for now we will start small and before you know it we will have grown into the full application."
"A simple application that meets these requirements is one that shows a visitors counter.  A counter that starts at one, and increments each time you refresh the page, return to the page, or even open the page in another tab, window, browser, or on another machine.  It looks something like this:"
"As , key to deployment is a  file that lists all of your dependencies, optional build instructions, and how to start your application.  We are going to start very simple, with no dependencies and no build process, so the  file will start out looking like the following:"
""
"Now to complete this we are going to need not only a  file, but also HTML, CSS, and image(s).  As with some of the cooking shows you see on the television, we are going to skip ahead and pull a completed meal out of the oven.  Run the following commands on a machine that has node.js >= 16 installed:"
""
"Once this command completes, you can launch the application with .  If you have authenticated and have flyctl version 0.1.6 or later installed, you can launch this application with  followed by .  When you run , consider saying  to deploying a postgres and redis database as we will be using them later."
""
"If you are running it locally, open  in your browser.  If you have deployed it on fly.io, try .  If you are running in a fly.io terminal, there is a handy link you can use on the left hand pane."
"Now take a look at .  It is all of 72 lines, including blank lines and comments.  In subsequent sections we show how to make it smaller using available libraries, and how to add features.  But before we proceed, lets save time and keystrokes by installing the node-demo package, which we will use repeatedly to generate variations on this application:"
""
""
"If you look at the top of the  file you will see a number of calls to .  This is Nodes  modules.  Node also supports  modules, which is what all the cool kids are using these days."
"This requires opting in.  You can let  make the changes for you by running the following command:"
""
"This script will detect what changes need to be made, give you the option to show a diff of the changes, and to accept or reject the changes.  This leads us to the second option:  that will automatically apply the changes without prompting:"
""
"Relaunch your application locally using  or redeploy it remotely using ."
""
"Inside the application you can see that the HTML response is produced by reading a template file and replacing a placeholder string with the current count:"
""
"While this is fine for this example, larger projects would be better served with a real template.   supports two such templating engines at the moment:  and .  Select your favorite, or switch back and forth:"
""
"and"
""
"Be sure to add  if you want to continue to use  statements."
""
"While  provides the means for you to create a capable HTTP server, it requires you to be responsible for status codes, mime types, headers, and other protocol details.   will take care of all of this for you:"
""
"Both ejs and mustache have integrations with express.  Try switching between the two to see how they differ."
""
"Maintaining a counter in a text file is good enough for a demo, but not suitable for production.  Sqlite3 and PostgreSQL are better alternatives:"
""
""
"Sqlite3 is great for development, and when used with  is great for deployment.  PostgreSQL can be used in development, and currently is the best choice for production."
"To run with PostgreSQL locally, you need to install and start the server and create a database.  For MacOS:"
""
""
"The next two options are frankly polarizing.  People either love them or hate them.  We won‚Äôt judge you."
"First  is a CSS builder that works based on parsing your class attributes in your HTML:"
""
"Next is  which adds type annotations:"
""
"TypeScript should work with all of the options on this page, in many cases making use of development only .  All of this should be handled automatically by node-demo."
"Both of these require a build step, which can be run via .  A change to the Dockerfile used to deploy is also required, which can be made using:"
""
"is actually a separate project with its own options for you to explore."
""
"Adding databases was the first change that we‚Äôve seen that actually makes the demo application noticeably larger, particularly with PostgreSQL once the code that handles reconnecting to the database after network failures is included.  This can be handled by including still more libraries, this time Object Relational Managers (ORMs).  Three popular ones:"
""
""
""
"Knex runs just fine with vanilla JavaScript.  Prisma can run with vanilla JavaScript, but works better with TypeScript.  Drizzle requires TypeScript."
"Prisma and Drizzle also require a build step."
"A final note: if you switch back and forth between Sqlite3 and PostgreSQL, you may get into a state where the migrations generated are for the wrong database.  Simply delete the  or  directory and rerun the  command to regenerate the migrations."
""
"If you open more than one browser window or tab, each will show a different number.  This can be addressed by introducing websockets:"
""
"The server side of web sockets will be different based on whether or not you are using express.  For the first time we are providing a client side script which is responsible for establishing (and reestablishing) the connection, and updating the  when messages are received.  This is a chore, and  is one of the many libraries that can be used to handle this chore:"
""
"The next problem is that if you are running multiple servers, each will manage their own pool of WebSockets so that only clients in the same pool will be notified of updates.  This can be addressed by using redis:"
""
"At this point, if you are using fly.io, postgres, and redis, you can go global:"
""
""
"So far, we have been using , but  and  are alternatives that may be better for some use cases:"
""
""
"Each package manager organizes the  directory a bit differently, so for best results when switching, remove the  directory before switching:"
""
"Windows Powershell users will want to use the following command instead:"
""
""
"While we have explored many options, this only scratches the surface. There are many alternatives to the libraries above, and many more things to explore.  Examples:"
"can be run server side in a number of different ways, and can be run client side using a  or self hosted scripts."
"is open source, so , , and  are always welcome!"
"I hope you have found this blog post to be informative, and perhaps some of you will use this information to start your next application ‚Äúvanilla‚Äù with your personal selection of toppings.  Yummy!"
""
""
""
"The  header is deceptively simple. All your app has to do is respond with a header, and the HTTP request gets re-ran somewhere else."
"It‚Äôs behind-the-scenes of some pretty interesting apps on Fly.io (we wrote about using it with )."
"We often bring it up when answering questions by those enamored with the ."
"So, here‚Äôs a use case I think is pretty neat."
""
"All public network traffic headed into Fly.io goes through the Fly Proxy. The proxy has features! 
One of those features involves looking for a  header in responses."
"The  header tells the Fly Proxy to replay an HTTP request somewhere else. This gives your applications some power."
"Depending on the value your app gives the  header, the Fly Proxy can replay the initial HTTP request on another app, in a different region, on a specific VM, or a mix of those things.
This only works for sending apps within the same Fly.io organization."
"Here‚Äôs what that looks like."
""
"I‚Äôm going to steal from the  article (and the corresponding )."
"If you have a ‚Äúleader‚Äù database with a bunch of read-replicas, you typically need write queries to go to the leader."
"If an HTTP request (e.g. ) results in writes to your database, then sending that request 
to a VM near the leader database has benefits - it‚Äôs way faster than opening DB connection across the globe."
"To do this, your application can return a header that looks like this:"
""
""
"You may have a bunch of apps - perhaps because each of your customers gets an app, or your have some micro services, or whatever crazy scheme you trapped yourself into."
"You can route requests to specific apps:"
""
""
"Maybe you want requests to go to specific VM‚Äôs! I‚Äôve used this to make sure requests after a file upload landed on the same server."
"The  was a quick way to accomplish that:"
""
"Since Machines can scale down to zero (stop on exit), you can also use this as a tricky way to wake them up - just ship it an HTTP request!"
""
""
"We‚Äôre going to make a ‚Äúproxy‚Äù - a little app that just responds with a  header. It‚Äôll tell the Fly Proxy to replay the HTTP request on a different app."
"This is useful if you, for example, point  to that router and have a specific app respond to a request - perhaps based on the hostname."
"This particular use case of mine is a bit like a load balancer - a ‚Äúreverse proxy‚Äù, but with some code instead of configuration."
"I like Go for HTTP plumbing, so let‚Äôs do some of that. We‚Äôre going to write the type of ‚Äútoy‚Äù app that accidentally stays in production for 14 years."
"This ‚Äúproxy‚Äù app will check the request hostname against a database of known apps, and route the request as needed."
"The full(ish) ."
""
"The important logic is this bit of standard Go HTTP stuff:"
""
"Go‚Äôs HTTP library does a prefix match on HTTP URI‚Äôs, so  will match anything, which is just what we want."
"All we do is find a customer (based on hostname) and respond with a replay header."
"This is great when paired with a SQLite database, as (trigger warning) reads from the local disk are pretty quick relative to network stuff."
"The  function is just a sql query (but super verbose, because Golang):"
""
"Locally, the whole round trip of the HTTP request + database lookup took ~4ms. In the real world, it added ~100ms to hit this proxy and replay the request against another Fly.io app (my crufty blog)."
"To test this out, I ran a few  requests:"
""
""
"In this scenario, we want the ‚Äúproxy‚Äù app to be available publicly, while keeping customer apps private."
"However, the Fly Proxy needs to know where apps are listening when it directs HTTP requests to them. 
Therefore, we need to define  in the  file."
""
"Luckily, we can keep the apps private while still telling the Fly Proxy how to reach them. 
The easiest way is to create the app without any public IP addresses via the  command:"
""
"The flag  is the key there. However, it requires the newer Machines-based apps platform. Also, if you‚Äôre creating apps via the Machines API, having no public IP‚Äôs is the default."
"Now the customer apps are private,  the Fly Proxy can still replay requests against them."
""
"I used a SQLite database to map domains to apps. If this proxy ran globally, I could have used  for distributed SQLite across multiple regions."
"Another fun possibility is (ab)using Fly‚Äôs  to check for the existence of apps (or application instances) via DNS."
"Perhaps we could have pinged this occasionally and created/updated an in-memory map of apps and hostnames! Here‚Äôs two DNS queries that would have been useful for that:"
""
"So this is pretty neat! The  header is a simple solution that gives you the ability to do some really neat stuff - 
particularly within globally distributed apps."
""
""
"Note, I‚Äôm not saying that JavaScript is weird, though it .  But that‚Äôs not the point of this blog post."
"Bear with me, instead of starting with  JavaScript ecosystem is weird, I‚Äôm going to start with  the JavaScript ecosystem is weird."
""
"Less that 10 years ago, JavaScript sucked bad.  It had no imports, no classes, no async, no arrow functions, no template literals, no destructuring assignment, no default parameters, no rest/spread parameters.  And the environment it predominately ran in, namely the browser‚Äôs DOM, sucked too.   made it suck less.  It still sucked, but was ‚Äî at that point in time ‚Äî relatively sane."
"Bundling JS to run in the browser was the first sign of weirdness.  In that process you would also want to both minimize and tree shake the source, and perhaps even code split.  In general the process involved reading a number of JavaScript sources as input and then producing one or more JavaScript sources as output.  This meant that the code you were executing wasn‚Äôt the code you wrote.   helped."
"Then  came along.  Instead of writing in JavaScript, you would write in a language which was compiled into JavaScript.  This is a bit different than languages like  and  which compile into the same byte codes as another language, CoffeeScript actually compiles into the other language.  C++ started out this way."
"Then came ECMAScript 6 in 2015.  JavaScript improved rapidly in the next few years.  This eventually mostly displaced CoffeeScript, but presented a different problem: for a while the implementations were not keeping up so  like  came along that compiled current and future versions of JavaScript into older versions of JavaScript that ran on supported environments.  Currently  is rapidly rising in popularity as a Javascript bundler/transpiler."
"Along the way,  came along which compiled actual machine code into a subset of JavaScript, though these days the new target for this tool is generally"
"Lately the pace of innovation in JavaScript has slowed, and JavaScript implementations are doing a better job of keeping up, so you would think that the need for transpilers would be waning, particularly on the server side where there is no need for bundlers.  But that‚Äôs not happening.  And the reason why is an interesting story."
""
"OK, the title above is clearly hyperbole, but I‚Äôll describe a number of the many ways that people aren‚Äôt writing JavaScript any more."
"If you write a Rails application, you write it in Ruby.  If you write a Django application, you write it in Python.  Phoenix, Elixir.  Lavavel, PHP.  Rails gets a lot of flack for doing magic using meta-programming, and Elixir has macros, but all of the above stay within the boundaries of what can be done by the language."
"JavaScript, however, is different.  While it nominally is standardized by , if you are using a popular framework like , , or  you are  coding in  as standardized by ECMA TC39.  Four examples:"
"Once upon a time, nearly 20 years ago, the ECMA committee standardized  that enabled XML to be treated as a data type.  This lost favor, got deprecated and archived.  Years later what once was Facebook (now Meta) had a similar need and invented .  It differs from E4X in that it compiles into JS."
"I mentioned earlier that Rails gets a lot of flack for its use of meta programming.  Nobody bats an eye at any of the ‚Äúabuses‚Äù of the JavaScript language mentioned above.  The JavaScript ecosystem is a Big Tent party."
""
"The latest  is by .  First , it is now adopted by ."
"What ‚Äú and  do, other than being a valid JavaScript statements that do absolutely nothing, is change the meaning of the code that follows them.  This has gotten mixed reviews, but in my mind is very much in the spirit of which also changes the meaning of the code that follows."
"While JSX often compiles to JS, the  enable compilation to HTML.  RSC goes a different way, and compiles into a .  This is all very transparent to you, but what it does enable is a  and even Rails:"
"It is not clear to me whether these comparisons are meant in a positive way, but I will say that from my perspective it is a very good thing."
"From a fly.io perspective, RSC enabling an  is very much of interest.  We‚Äôve always been especially shiny for frameworks that benefit from geographic distribution, like Elixir‚Äôs , Laravel‚Äôs  and Ruby on Rail‚Äôs . We want those kinds of frameworks to succeed, because the better they do, the more valuable we are.  Now we can add React‚Äôs RSC to that list."
"Returning to the topic at hand, the fact that such a feature is only made possible through cooperation with bundlers ‚Äî a statement tantamount to saying a change to the JavaScript language itself ‚Äî is profound and, dare I say it, delightful."
""
"Dan Abramov gave a talk at RemixConf entitled :"
""
""
""
"I hear about Large Language Models (LLM) everywhere these days! Do you? ü§î"
"LLMs are a type of natural language processing (NLP) technology that uses advanced deep learning techniques to generate human-like language. If you haven‚Äôt heard about LLMs, you probably heard about one of the most notable examples of it today: . ChatGPT is a language model developed by OpenAI and it was trained on a large amount of text data which allows it to understand the patterns and generate responses to inputs."
"is a Python framework that rapidly gained notoriety. It was launched as an open source project in October 2022  - yes, a few months ago. This framework was designed to simplify the creation of powerful applications providing ways to interact with LLMs."
"I recently created a  using LangChain and deployed it to Fly.io. This article aims to share the process of how to ."
"is a Python  framework for building web applications. That‚Äôs perfect for our example since it‚Äôs designed to make getting started quick and easy. That‚Äôs all we need for now."
"Let‚Äôs get to it! üòé"
""
"LangChain provides an interface to interact with several LLMs."
"The  is using the  LLM wrapper, which uses, at the time I‚Äôm writing this article,   - this model belongs to the  family. Keep in mind that there are other alternatives to use more capable and less expensive models like , which is the one recommended by OpenAI because of its lower cost. However, we won‚Äôt get into that in this article."
"Language models take text as input. This text is what we usually referred as a . LangChain facilitates the use of those prompts. To make things a bit more interesting, the template makes use of the : ask a question and also receive an input from the user."
""
"Our minimal application receives a  (city, country, etc.) as an input and give us 3 options where to eat in that . The default value for  is ."
"Out prompt:"
""
""
"You can define your own input variable by calling the url:"
""
"For example:"
"Country:"
"To illustrate, we are using the  to display the results on the browser."
"So, let‚Äôs start at the beginning‚Ä¶"
""
"We assume the initial setup is already done and you have  installed.It‚Äôs recommended to use the latest version of Python. We are using  and it supports Python 3.8 and newer."
"Create and enter your project‚Äôs folder:"
""
""
"We can go ahead and clone the repository inside your project‚Äôs folder using either"
"HTTPS:"
""
"or SSH:"
""
""
"Choose a virtual environment to manage our dependencies. For simplicity, we‚Äôre using  for this project. Inside your project, create and activate it:"
""
"From this point on, the commands won‚Äôt be displayed with  but we assume you have your Python virtual environment ."
""
"For this minimal example, we have a few dependencies to be installed:"
""
"Go ahead and install them by running:"
""
"We are using ,  and  packages as minimal requirements for this example.  (Green Unicorn) is the pure Python WSGI server we will use in production instead of the built-in development server - other options can be found . Finally, we use  to use the environment variables set on  file - more about in the next section."
""
"The template contains a  file. Go ahead and rename it to . Our local environment variables will be stored in this  file:"
""
"The OpenAI API uses API keys for authentication. We will need an API Key to be able to use the API in your requests. Log in to your account and check  page to create or retrieve your API key to be set as  ."
"Note that  is required because we are using  LLM wrapper - other providers will have different requirements. ."
""
"file is only used for your local development."
""
"Now that everything is set up we can run the project:"
""
""
"Now, we can head over to  üéâ"
""
"With our LangChain app prepped and running on our local machine, let‚Äôs move to the next section and deploy our app to Fly.io!"
""
"is the command-line utility provided by Fly.io."
"If not installed yet, follow these ,  and  to Fly.io."
""
""
"Before deploying our app, first we need to configure and launch our app to Fly.io by using the  command . During the process, we will:"
": this will be your dedicated fly.dev subdomain."
"This is what it looks like when we run :"
""
""
"If you cloned the template mentioned in this article, you will see a similar message described above."
"The template provides you with an existing  file, you can copy its configuration to your app."
""
"Go ahead and define your app name and select the organization to deploy our app."
""
"The template also provides you with existing  and  files. Those files are generated for you if they don‚Äôt exist in your project. If so, make sure you update them to fit your needs."
""
"Note that the built-in Python builder used () will automatically copy over the contents of the directory to the deployable image."
""
"To keep it simple, a  is used to deploy and run Python applications - the minimal generated  starts the Gunicorn server with our WSGI application."
""
"By now, we are almost ready to deploy our app. Before we do that, we need to set the environment variables to be used in production. Let‚Äôs see how that‚Äôs done."
""
"As mentioned before, for our local development we are using  file to set our environment variables. In production, we can‚Äôt share such file with sensitive values."
"We can specify secret values for our app using  command by running:"
""
"That‚Äôs it! We are now ready to deploy our app!"
""
"Let‚Äôs simply run:"
""
"Our app should be up and running!"
""
"Let‚Äôs try it:"
"YAY! üéâ We just deployed our LangChain app to production! Cool, right? üòé"
""
""
"Our app does the job of finding new places to eat! Now that we gave it a try, you are probably wondering: what‚Äôs next?"
"We got some options where to eat tonight in Berlin, here where I live! That‚Äôs a great start for what is possible to do with LangChain. But that‚Äôs a LOT more!"
"Let‚Äôs say that I‚Äôm meeting my best friend in Berlin for dinner tomorrow."
"From all the places I could get in , I want to get the name and address, with working hours of the ones that serve  (because we all love Italian food, right?) and are closer to  - my best friend‚Äôs neighbourhood. The places also need to be top-rated, with rating higher than  on Google Maps and be open  at ."
"And we could go on and on here."
"That looks a bit more complex and‚Ä¶"
"It started to look like a  (aha!) of calls that also depend on user‚Äôs input. That‚Äôs when simple applications start to become more powerful."
"Note that our chain depends on . Not only that, but some of the  information like current working hours and rating on Google Maps are not available to us."
"AI language models don‚Äôt have access to real-time data neither the ability to browse the internet."
""
"For these type of chains, we got to interact with the outside world to get some answers!"
"That‚Äôs when agents come into play."
"The ‚Äúagent‚Äù has access to a . Depending on the user‚Äôs input, the agent can decide which, if any, of the available  to call - you can also build your own custom  and ."
"Those tools are the way we interact with the rest of the world - in our case, using  to get real-time information such as working hours and rating."
"That‚Äôs so neat and it doesn‚Äôt even scratch the surface. There are so much more out there - and that‚Äôs something for future articles!  you can find a curated list of tools and projects using LangChain."
"Happy coding! ü§ñ"
""
"For more detailed information on how to deploy a Python App to Fly.io, you can check the ."
"If you have any question or comments, reach out on the . That‚Äôs a great place to share knowledge, help and get help!"
"üì¢ Now, tell me‚Ä¶ What are the cool ideas you have now using LangChain? üë©üèΩ‚Äçüíª"
""
""
"Fly.io is a great place to run fullstack applications.  For most programming languages,
there is a defacto default fullstack framework.  For Ruby, there is Rails.
For Elixir, there is Phoenix.  For PHP there is Laravel.  For Python, there is Django."
"If you don‚Äôt know where to look, Node.js appears to be a mess.  For starters there
are .
Then there are three different package managers.  Not to mention that Typescript as
an alternative to JavaScript.  And if that is not bad enough Bun and Deno are providing
alternatives to Node itself."
"The result is predictable.  Fly.io has a number of community contributed templates for
a small number of Node frameworks.  Some have had more attention than others."
"It is time to clean up the mess."
""
"The key sentence in the preceding section starts with .
The right place to start is .  It tells you what dependencies need to be
installed.  For most frameworks, it tells you how to start the web server.  And if there
is a build step.  And if there are any development dependencies that may be needed to
run the build, and removed prior to deployment."
"Given this knowledge, a baseline Dockerfile can be built for any framework that follows
these conventions.  Handling different package managers can be accomplished by looking
for  and  files.  TypeScript is a devDependency and handled by the
build step.  While Deno projects don‚Äôt typically have  files, some bun
projects do."
"The  project endeavors to do exactly that:"
""
"This will create (or replace!) your existing Dockerfile, as well as ensure that you have a
 file, and optionally may create a  script.  You can run
with this Dockerfile locally, or use it to deploy on your favorite cloud
provider.  For Fly.io, you would get started by running:"
""
"The  parameter is needed to tell  to use your Dockerfile rather
than trying to generate a new one."
"Of course, if you prefer to run your application on Google Cloud Run, Amazon ECS, MRSK, or
even locally, you are welcome to do so."
""
""
"Not all frameworks are alike."
"Some will, by default, start servers that only process requests that come from
the localhost.  That, of course, is entirely unsatisfactory."
"Some require extra steps, for example applications that make use of Prisma."
"One (and I won‚Äôt mention the name) actually lists the package needed to run the
production server as a development only dependency."
"Fortunately,  templates can include  statements and/or make
use of computed variables that customize the Dockerfiles produced."
"As a starter set, I‚Äôve got templates working for the following frameworks:
, , ,
, , , and
.  At the moment, I‚Äôve been focusing
on breadth vs depth, so what I have working may not be able to handle much more than
the splash screen, but my experience is that getting that far is often the hardest part,
after that point you have all the scaffolding in place and can focus on any specific issue that may come up."
"Those are the successes so far.  Here‚Äôs a list of frameworks that are still being worked on,
along with the current blocking issue:"
": Access to the Postgres database is required during the build step.  Worst case,
we do the build step during the deployment of the server, but that is suboptimal for cases
where multiple servers are started."
"In the fullness of time, these will be picked off one by one.  This code is all
open source, so everybody with an interest in a particular framework can
contribute via issues and pull requests.  Interest and participation will
definitely affect prioritization of this work."
""
"Once this script has a little bit of exposure to real world usage, it will replace the existing
flyctl scanners, much in the way that 
is the basis for the Dockerfiles produced for Rails applications with Fly.io.
At which point, usage will be as simple as ."
"Integration with fly launch will also enable thing like setting of secrets,
defining volumes, launching of databases, and defining health checks as part of
the workflow."
"This package will also be designed to be re-run and accept arguments which will customize the Dockerfile
produced.  Peruse the  for dockerfile-rails
to see examples of the types of customizations possible.  Some highlights:"
"- use build caching to speed up builds"
"The scanner will also be able to do things like detect the inclusion of  and automatically
install and configure Chrome/Chromium.  This is already being done for Rails applications today."
"Another thing already being done for Rails applications is to run the web server as a
non-root user for security reasons.  Repeating this for Node.js  will require
knowledge of what files the application is expected to write to and which are
expected to be read-only.  This knowledge is necessarily framework specific,
and may not be possible for minimal and general purpose frameworks like
express."
""
"If you have questions, comments, or concerns, let us know!"
"If they are even vaguely Fly.io related, feel free to use our
.  Otherwise,
start a 
on GitHub."
"And to those that wish to contribute, perhaps to make support for their
favorite framework(s) better‚Ä¶. let‚Äôs do this!"
""
""
""
"In the field of computer science, the industry is represented by two separate yet equally important groups: the software developers who build Rails applications and mobile games, and the academics who write theory papers about why the problems those apps try to solve are NP-hard.  This is a story about both."
"Distributed systems span the practical-academic divide. Reading a stack of MIT PhD dissertations may be a good Friday night, but it won‚Äôt equip you for debugging a multi-service outage at 2am. That requires real-world experience."
"Likewise, building a fleet of microservices won‚Äôt give you the conceptual tools to gracefully & safely handle failure. Many failure scenarios are rare.  They don‚Äôt show up in unit tests. But they‚Äôre devastating when they do show up. Nailing down the theory  gives you a fighting chance at designing a correct system in the first place."
"The practical and academic tracks seldom converge. To fix this, we teamed up with , author of , to develop a series of distributed systems challenges that combine real code with the academic rigor of Jepsen‚Äôs verification system."
"We call these challenges the  ."
""
""
"You know Kyle Kingsbury from his ‚Äú‚Äù blog posts that eviscerate distributed databases. You may also have known about , the Clojure-based open-source tooling Kyle uses to conduct these analyses. Well, Kyle also wrote another tool on top of Jepsen called ."
"Maelstrom runs toy distributed systems on a simulated network.  It easily runs on a laptop. Kyle uses it to teach distributed systems. We all thought it‚Äôd be neat to build a series of challenges that would teach people around the Internet Maelstrom, and, in turn, some distributed systems theory."
"Each challenge is composed of several parts:"
"The  acts as a set of clients to your distributed systems. These clients send different types of messages as defined by the challenge and expect certain constraints to be met. These workloads can vary between a simple distributed counter all the way to multi-operation, transactional database systems."
""
"Our challenges start off easy and get more difficult as you move along. They‚Äôre organized into six high-level challenges with many of those having several smaller challenges within them."
"First, you‚Äôll start with the Echo challenge. This is the ‚Äúhello world‚Äù of distributed systems challenges. It gets you up and running and helps you understand how these challenges work."
"Next, you‚Äôll build a totally-available, distributed unique ID generator. In this challenge, nodes will need to be coordination-free and independently generate a unique identifier for any number of clients."
"After that, the difficulty starts to ramp up with the broadcast challenge. In this challenge, you‚Äôll need to propagate messages out to all the nodes in the cluster. You‚Äôll need to ensure fault tolerance in the face of network partitions and then work to optimize your message delivery to minimize the number of messages sent within your system."
"Once you‚Äôve made it past broadcast, you‚Äôll implement a grow-only counter, or g-counter. The tricky part with this challenge is that you‚Äôll need to build on top of Maelstrom‚Äôs  consistent key/value store."
"Then you‚Äôll dive into the world of replicated logs by building a Kafka-like system. This challenge will build on the  key/value store provided by Maelstrom but you‚Äôll need to figure out how to not only make it correct but also efficient."
"Finally, you‚Äôll wrap up with the totally-available transactions challenge where you‚Äôll build a transactional database on various consistency levels."
""
"Over the past year, we‚Äôve been growing like gangbusters. That‚Äôs great. But it also means we‚Äôve been hiring, and hiring is hard."
"We hire : we have people write code and design systems, and then score those submissions based on a rubric. We‚Äôve got criteria set up for . But we didn‚Äôt have strong criteria for hiring staff engineers."
"So we began tossing around ideas. In a previous life, some of us had success with a series of cryptography challenges called , so we figured we‚Äôd try something similar, but with a distributed systems flavor."
"That sounded great but how do you actually test distributed systems to know if someone passed or failed? For weeks, we wrote up one iteration after another but none of them felt right."
"Finally, we had a brilliant idea. Let‚Äôs find someone who lives and breathes distributed system validation! That someone is Kyle Kingsbury."
"After working on these challenges with Kyle, we realized that they are too much fun to keep to ourselves as an internal evaluation tool. So we‚Äôre releasing them for anyone to play with."
""
"If you scoff in the face of cascading failures, if you bend consistency levels to your will, and if you read  post-mortems as bedtime stories to your kids, you may be interested in trying our hardest challenge."
"We reserved this last challenge for evaluating our staff engineers at Fly.io. So if you think you‚Äôd be up to the challenge, ."
""
""
""
"Nearly all of our apps are puking output. Sometimes, it‚Äôs intentional. Often this output is in the form of structured logs."
"Logs are helpful for a variety of use cases - debugging, tracking, collating, correlating, coalescing, and condensing the happenings of your code into useful bits of human-parsable information."
"There can be a lot of logs, from a lot of apps. Aggregating logs to a central place is useful for many reasons, but here are my top 2 favorite:"
"- Being able to search/query/report on all your logs in one place helps you correlate events (‚ÄúJoe deleted prod again‚Äù) amongst services"
""
"Since we grab stdout from the processes run in your apps, whatever an app outputs becomes a log. Logs are constantly flowing through Fly.io‚Äôs infrastructure."
""
"Here‚Äôs how that works."
"Your apps run in a VM via Firecracker. Inside the VM, we inject an  process (pid 1) that runs and monitors your app. Since we build VM‚Äôs from Docker images,  is taking  +  and running that.
The  program (really just a bit of Rust that we named ) is, among other things, gathering process output from stdout and shooting it into a socket."
"Outside of the VM, on the host, a bit of Golang takes that output and sends it to  via yet-another socket."
"Vector‚Äôs job is to ship logs to other places. In this case, those logs (your app‚Äôs output) are shipped to an internal  cluster. For the sake of simplicity, let‚Äôs call NATS a ‚Äúfancy, clustered pubsub service‚Äù. Clients can subscribe to specific topics, and NATS sends the requested data to those subscribers."
"In true Fly.io fashion, a proxy sits in front of NATS. We call this proxy ‚ÄúFlaps‚Äù (Fly Log Access Pipeline Server‚Ñ¢, as one does). Flaps ensures you only see your own logs."
"You can hook into NATS (via Flaps) to get your logs."
"To get your logs, all you need is an app that acts as a NATS client, reads the logs, and ships them somewhere. Vector can do just that! It‚Äôs fairly simple - in fact, we‚Äôve done the work for you:"
""
"To ship your logs, you can run an instance of the ."
"This app configures a Vector  of your choosing, and runs Vector. A sink is a ‚Äúdriver‚Äù that Vector will ship logs to, for example Loki, Datadog, or (bless your heart) Cloudwatch."
"I liked the look of , so I tried out its free tier."
""
"If you sign up for Logtail, it helpfully gives you instructions on setting that up with Fly.io."
"Let‚Äôs go ahead and follow those instructions (they‚Äôre similar to what you see on the )."
""
"The NATS log stream is scoped to your organization. This means that the Fly Log Shipper collects logs from  your applications."
"Here‚Äôs how to set it up with Logtail:"
""
"You can configure as many providers as you‚Äôd like by adding more secrets. The secrets needed are determined by  you want to use."
"Before launching your application, you should edit the generated  file and delete the entire  section. Replace it with this:"
""
"Then you can deploy it:"
"You‚Äôll soon start to see logs appear from all of your apps."
"That wasn‚Äôt too bad!"
""
""
"So far we‚Äôve seen how to ship logs from every application in your organization."
"You can, however, narrow that down by setting a  environment variable. That can be set in the ‚Äòs  section, or as an application secret."
"I opted to add it to my , which looked like this:"
""
"The subject is in format . An example  to only log an application named  (no matter what region it‚Äôs in) is:"
""
"See that greater-than symbol ? That‚Äôs a . There are also regular wildcards , but the special wildcard  is used at the end of the string to say ‚Äúand anything to the right of this‚Äù."
"So, our use of  says to ship any logs that are from application , no matter what region or instance they come from. You can (ab)use this to get the logs you‚Äôre interested in."
"Go forth and ship logs!"
""
""
""
"So, you want to build an app to rate sandwiches. Well, the world has a lot of different sandwiches.  in Baltimore,  in Shinjuku, and  in Puebla. You want real-time sandwich telemetry, no matter the longitude of the sandwich. So you need to run it all over the world, without a lot of ceremony."
"We built one of those at Fly.io. We‚Äôve written a bunch : how we take Docker images from our users and efficiently run them as virtual machines. You can run a Docker image as VM. You‚Äôre almost done! Time to draw the rest of the owl."
"To turn our Docker transmogrification into a platform, we need to go from running a single job to running hundreds of thousands. That‚Äôs an engineering problem with a name:"
""
"Orchestrators link clusters of worker servers together and offer up an API to run jobs on them.  is an orchestrator; the Kleenex of orchestrators. Then, HashiCorp has , which we use, and about which more in a bit."
"Find a serverside developer complaining about how much harder it is to deliver an app in 2023 than it was in 2005, and odds are,  They‚Äôre not wrong: Kubernetes is fractally complicated. But the idea isn‚Äôt."
"Let‚Äôs write an orchestrator. Start by writing a supervisor."
""
"I believe this design is so powerful it does not need to be discussed."
""
"There are, like,   .  You can write a program to run a shell command, you can write a supervisor. Come on. You‚Äôve already written a supervisor. Let‚Äôs stop kidding each other."
"Let‚Äôs turn ours into an orchestrator."
"For illustrative purposes, our supervisor takes a JSON configuration:"
""
"Instead of reading this configuration from a file, like a dumb old supervisor, read it from an HTTP API, like a majestic orchestrator.  ‚ÄúWorkers‚Äù run our simple supervisor code, and a  doles out tasks. Here‚Äôs an API:"
""
"The server implementing this is an exercise for the reader. Don‚Äôt overthink it ."
"Workers poll . They  them by name. The  decides which claim wins, awarding it a  HTTP response. The worker runs the job, until it stops, and posts ."
"End-users drive the orchestrator with the same API; they post JSON tasks to , check to see where they‚Äôre running, kill them by name with . Workers poll  to see what to stop running."
"There. That‚Äôs an orchestrator. It‚Äôs just a client-server process supervisor."
"I see a lot of hands raised in the audience. I‚Äôll take questions at the end. But let‚Äôs see if I can head some of them off:"
"Sure, it‚Äôs unusual for an orchestrator to run shell commands.  A serious orchestrator would run Docker containers (or some agglomeration of multiple Dockerfiles called a Pod or a Brood or a Murder). But that‚Äôs just a detail; a constant factor of new lines calling the containerd SDK."
"You there in the back hollering‚Ä¶ this isn‚Äôt a real orchestrator, why? Oh, because we‚Äôre not"
""
"Scheduling means deciding which worker to run each task on."
"Scheduling is to an orchestrator what a routing protocol is to a router: the dilithium crystal, the contents of Marcellus Wallace‚Äôs briefcase, the thing that, ostensibly, makes the system Difficult."
"It doesn‚Äôt have to be hard. Assume our cluster is an undifferentiated mass of identical workers on the same network. Decide how many jobs a worker can run. Then: just tell a worker not to bid on jobs when it‚Äôs at its limit."
"But no mainstream orchestrator works this way. All of them share some notion of centralized scheduling: an all-seeing eye that allocates space on workers the way a memory allocator doles out memory."
"Even centralized scheduling doesn‚Äôt complicate our API that much."
""
"Instead of rattling off all the available jobs and having workers stampede to claim them, our new API assigns them directly. Easier for the workers, harder for the server, which is now obligated to make decisions."
"Here‚Äôs the rough outline of a centralized scheduler:"
"Filter out workers that fail to match constraints, like sufficient disk space or CPUs or microlattice shapecasters."
"The textbook way to rank viable workers is ‚Äú‚Äù. Bin packing is a classic computer science problem: given a series of variably-sized objects and fixed-size containers, fit all the objects in the smallest number of containers. The conventional wisdom about allocating jobs in a cluster is indeed that of the clown car: try to make servers as utilized as possible, so you can minimize the number of servers you need to buy."
"So far, the mechanics of what I‚Äôm describing are barely an afternoon coding project. But real clusters tend to run Kubernetes. Even small clusters: people run K8s for apps like  all the time. But K8s was designed to host things like . So K8s has fussy scheduling system."
"To qualify as ‚Äúfussy‚Äù, a scheduler needs at least 2 of the following 3 properties:"
"Place jobs on workers according to some optimum that is theoretically NP-hard to obtain (but is in practice like 2 nested  loops)."
"These tenets of fussiness hold true not just for K8s, but for all mainstream orchestrators, including the one we use."
""
""
"Let‚Äôs start by reckoning with what‚Äôs going on with Kubernetes."
"The legends speak of a mighty orchestrator lurking within the halls of Google called ‚Äú‚Äù. Those of us who‚Äôve never worked at Google have to take the word of those who have that Borg actually exists, and the word of other people that"
"The thing about Borg is that, if it exists, it exists within an ecosystem of other internal Google services. This makes sense for Google the same way having , , , , , , , , , , , , , , , , , , , , , , , , and  does for AWS. Like, somewhere within Google there‚Äôs a team that‚Äôs using each of these kinds of service."
""
"It makes less sense for a single piece of software to try to wrap up all those services. But . Here‚Äôs some perspective: K8s is, some people say, essentially Borg but with Docker Containers instead of . Midas is neat, but it in turn relies on  and , two huge Google services. And that‚Äôs just packages, the lowest level primitive in the system. It‚Äôs an, uh, ambitious starting point for a global open source standard."
"At any rate, our customers want to run Linux apps, not Kubernetes apps. So Kubernetes is out."
"Sometime later, a team inside Google took it upon themselves to redesign Borg. Their system was called . I don‚Äôt know if it was ever widely used, but it‚Äôs influential. Omega has these properties:"
"Distributed scheduling, so that scheduling decisions could be made on servers across the cluster instead of a monolithic single central scheduler."
"Hashicorp , called Nomad."
"Omega‚Äôs architecture is nice. But the real win is that Nomad is lightweight. It‚Äôs conceptually  not all that far from the API we designed earlier, ."
"Nomad can run Unix programs directly, or in Docker containers. We do neither. Not a problem: Nomad will orchestrate jobs for anything that conforms to :"
""
"For the year following , Fly.io‚Äôs platform was a Rust proxy and a Golang Nomad driver. The driver could check out a Docker image, convert it to a block device, and start Firecracker on it. In return for coding to the driver interface, we got:"
"Constraint-based deployments that let us  tell a specific Fly app to run in Singapore (har cheong gai burger), Sydney (hamdog), and Frankfurt (doner kebab), on dedicated CPU instances with 2 cores and at least 4 gigs of memory, say."
"About Nomad itself, we have nothing but nice things to say. Nomad is like Flask to K8s‚Äôs Django, Sinatra to K8s‚Äôs Rails. It‚Äôs unopinionated, easy to set up, and straightforward to extend. Use Nomad."
""
"But we‚Äôve outgrown it, because:"
". Fussy schedulers are premised on minimizing deployed servers by making every server do more. That makes a lot of sense if you‚Äôre Pixar. We rent out server space. So we buy enough of them  to have headroom in every region. As long as they‚Äôre running, we‚Äôd want to use them."
"on the logic behind Nomad‚Äôs first-fit bin packing scheduler. It was designed for a cluster where 0% utilization was better, for power consumption reasons, than < 40% utilization. Makes sense for Google. Not so much for us."
"With strict bin packing, we end up with Katamari Damacy scheduling, where a couple overworked servers in our fleet suck up all the random jobs they come into contact with. Resource tracking is imperfect and neighbors are noisy, so this is a pretty bad customer experience."
"Nomad added a ‚Äú‚Äù option, which just inverts the bin pack scoring they use by default. But that‚Äôs not necessarily what we want. What we want is complicated! We‚Äôre high-maintenance! In a geographically diverse fleet with predictable usage patterns, the best scheduling plans are intricate, and we don‚Äôt want to fight with a scheduler to implement them."
"This isn‚Äôt what Nomad expects. Nomad wants us to run  (one in Dallas, one in Newark, and so on)."
"There are two big reasons we don‚Äôt federate Nomad:"
"It changes the semantics of how apps are orchestrated, which would require fiddly engineering for us to wire back into our UX. For instance: there isn‚Äôt an obvious, clean way to roll back a failing app deploy across a dozen regions all at once. We have lots of regions, but offer one platform to our users, so we run into lots of stuff like this."
"Nomad scheduling is asynchronous. You submit a job to a server. All the servers convene a trustees meeting, solicit public comment, agree on the previous meeting‚Äôs minutes, and reach consensus about the nature of the job requested. A plan is put into motion, and the implicated workers are informed. Probably, everything works fine; if not, the process starts over again, and again, until seconds, minutes, hours, or days later, it does work."
"This is not a bad way to handle a  request. But it‚Äôs no way to handle an HTTP request, and that‚Äôs what we want: for a request to land at our network edge in S√£o Paulo, and then we  to handle it in our  region, starting a Fly Machine on a particular server, synchronously."
""
"At this point, what we‚Äôre asking our scheduler to do is to consider Docker images themselves to be a resource, like disk space and memory. The set of images cached and ready to deploy on any given server is changing every second, and so are the scheduling demands being submitted to the orchestrator. Crazy producers. Crazy consumers. It‚Äôs a lot to ask from a centralized scheduler."
"So we built our own, called"
""
""
"Just kidding, we call it ."
"There is a  of , . We decided not to consult it, and just built something instead."
"has a radically different model from Kubernetes and Nomad. Mainstream orchestrators are like sophisticated memory allocators, operating from a reliable global picture of all capacity everywhere in the cluster. Not ."
"Instead,  operates like a market. Requests to schedule jobs are bids for resources; workers are suppliers. Our orchestrator sits in the middle like an exchange.  asks for a Fly Machine with 4 dedicated CPU cores in Chennai (sandwich: bun kebab?). Some worker in  offers room; a match is made, the order is filled."
"Or, critically: the order is not filled. That‚Äôs fine too! What‚Äôs important is that the decision be made quickly, so that it can be done synchronously. What we don‚Äôt want is a  state waiting for the weather to clear up."
"Our system has a cast of three characters:"
"is the source of truth for all the VMs running on a particular worker."
"The engine of this system is ."
"In Nomad-land, our Firecracker driver doesn‚Äôt keep much state. That‚Äôs the job of huge scheduling servers, operating in unlighted chambers beyond time amidst the maddening beating and monotonous whine of the ."
""
"In -land, state-keeping is very much the worker‚Äôs problem. Every worker is its own source of truth. Every  keeps a  database of its current state, which is an append-only log of all the operations applied to the worker."
"is rigidly structured as a collection of state machines, like ‚Äúcreate a machine‚Äù or ‚Äúdelete a volume‚Äù.  Each has a concrete representation both in the code (using Go generics) and in . Everything happening in  (in logs, traces, metrics or whatever) happens at a particular state for a particular resource ID. Easy to reason about. And, of course, if we bounce , it picks up right where it left off."
""
"All the  instances in (say) Madrid form a  cluster. But it‚Äôs not a cluster in the same sense Nomad or K8s uses: no state is shared between the  instances, and no consensus protocol runs."
"To get jobs running on a  in , you talk to .  is running wherever you are (in my case, )."
"uses Corrosion to find all the workers in a particular region. It has direct connectivity to every , because our network is meshed up with WireGuard.  exposes an internal HTTP API to , and  in turn exposes this API:"
""
"‚ÄúCreating‚Äù a Fly Machine reserves space on a worker in some region."
"To reserve space in Sydney,  collects capacity information from all the  in , and then runs a quick best-fit ranking over the workers with space, which is just a simple linear interpolation rankings workers as more or less desirable at different utilizations of different resources."
""
"Rather than forming distributed consensus clusters, Fly.io regions like  and ‚Ä† are like products listed on an exchange. There are multiple suppliers of  VMs (each of our workers in Madrid) and you don‚Äôt care which one you get.  act like a broker. Orders come in, and we attempt to match them.  does some lookups in the process, but it doesn‚Äôt hold on to any state; the different  instances around the world don‚Äôt agree on a picture of the world. The whole process can fail, the same way an immediate-or-cancel order does with a financial market order. That‚Äôs OK!"
"Here‚Äôs what doesn‚Äôt happen in this design: jobs don‚Äôt arrive and then sit on the book in a ‚Äúpending‚Äù state while the orchestrator does its best to find some place, any place to run it. If you ask for VMs in , you‚Äôre going to get VMs in , or you‚Äôre going to get nothing. You won‚Äôt get VMs in  because the orchestrator has decided ‚Äúthat‚Äôs close enough‚Äù. That kind of thing happened to us all the time with Nomad."
""
"If you‚Äôre a certain kind of reader, you‚Äôve noticed that this design doesn‚Äôt do everything Fly Apps do. What happens when an app crashes? How do we deploy across a bunch of regions? How does a rollback work? These are problems Nomad solved. It doesn‚Äôt look like  and  solve them."
"That‚Äôs because they don‚Äôt! Other parts of the  platform ‚Äî most notably, , our beloved CLI ‚Äî take over those responsibilities."
"For example: how do we handle a crashed worker? Now,  will restart a crashed VM, of course; that‚Äôs an easy decision to make locally. But some problems can‚Äôt be fixed by a single worker. Well, one thing we do is: when you do a deploy,  creates multiple machines for each instance. Only one is started, but others are prepped on different workers. If a worker goes down,  notices, and sends a signal to start a spare."
"What we‚Äôre doing more generally is carving complex, policy-heavy functionality out of our platform, and moving it out to the client.   will recognize this as an old strategy."
""
"What we had with Nomad was a system that would make a lot of sense if we were scheduling a relatively small number of huge apps. But we schedule a huge number of relatively small apps, and the intelligent decisions our platform made in response to stimuli were often a Mad Hatter‚Äôs tea party. For instance: many times when Europe lost connectivity to  S3, apps would flake, and Nomad would in response cry ‚Äúchange places!‚Äù and reschedule them onto different machines."
"What we‚Äôve concluded is that these kinds of scheduling decisions are actually the nuts and bolts of how our platform works. They‚Äôre things we should have very strong opinions about, and we shouldn‚Äôt be debating a bin packer or a constraint system to implement them. In the new design, the basic primitives are directly exposed, and we just write code to configure them the way we want."
"Internally, we call this new system ‚ÄúAppsV2‚Äù, because we‚Äôre good at naming things. If you‚Äôre deploying an app in January of 2023, you‚Äôre still using Nomad; if you‚Äôre deploying one in December of 2023, you‚Äôll probably be interacting with . If we do it right, you mostly won‚Äôt have to care."
""
""
"Over the last couple years, we‚Äôve written about most of the guts of Fly.io:"
"in the first place,"
"It took us awhile, but we‚Äôre glad to have finally written down our thoughts about one of the last remaining big pieces. With an execution engine, a control plane, and an orchestrator, you‚Äôve got most of our platform! The only huge piece left is , which we have not yet done justice."
"We hope this is interesting stuff even if you never plan on running an app here (or building a platform of your own on top of ours). We‚Äôre not the first team to come up with a bidding-style orchestrator ‚Äî they‚Äôre documented ! But given an entire industry of orchestrators that look like Borg, it‚Äôs good to get a reminder of how many degrees of freedom we really have."
""
""
""
"Did you know that we‚Äôre in Johannesburg? There‚Äôs rugby and cricket. Hearty kota and Gatsby sandwiches. Braai under sunny skies and low-latency full-stack apps. Front end, Postgres, Redis, the works: if your users support the Springboks and Banyana Banyana, you should put your whole app in JNB."
""
""
""
"By and large, SQLite is configuration-free. You can get pretty far by just using the default settings. As your application grows and you start tweaking settings, one of the first knobs you‚Äôll come across is the . This setting determines how SQLite performs transactions on disk and there are essentially two modes: the rollback journal & the write-ahead log, or WAL."
"The rollback journal was the original transaction mechanism and it‚Äôs still the default. The WAL mode is the shiny new transaction mode. If you start reading blog posts & forums about SQLite, one tip you will repeatedly hear is,"
"If your database is slow, you should use the WAL mode."
"If you have concurrent users, you should use the WAL mode."
"WAL mode. WAL mode. WAL mode."
"In the SQLite world, the write-ahead log is as close to a  as you can find. It‚Äôs basically magic fairy dust that makes your database better and you should  always use it."
"However, , our distributed SQLite file system, only supported the rollback journal mode. Until now! With the release of , we now support all journaling modes."
""
"We‚Äôve written about the internals of the  and the  in previous posts, but here‚Äôs a refresher."
"With the rollback journal, SQLite:"
"Writes new pages directly to the database file."
"Because the pages in the database file are moving around and being deleted, this mode does not allow read transactions & write transactions to occur at the same time."
"The WAL works the opposite way:"
"New pages are written to a separate write-ahead log file."
"Since the original data is never changed during the transaction, readers can continue running in parallel while another process is writing to the database. In addition to improved concurrency, the WAL also tends to have better write performance."
""
"Most developers think of databases as just a collection of tables & rows. And that‚Äôs how you should view it when you‚Äôre building an application. However, when designing database tooling like LiteFS, it‚Äôs better to think in terms of change sets."
"A good analogy is baseball card collections. You might start off buying a pack of cards to start your collection. Over time, you may buy more packs or you might trade cards with friends. Each of these actions is a ‚Äúchange set‚Äù, adding and/or removing a set of cards from your collection."
"Eventually, word gets out about your sweet baseball card collection and your friends want to have the same set. So each time you make a change, you send each friend a list of which cards were added and removed so they can update their collections. Now everyone has the same collection just by communicating change sets."
"That, in a nutshell, is how LiteFS nodes keep distributed copies of your database in sync. However, instead of baseball cards, these LiteFS nodes communicate change sets of fixed-sized blocks called ."
"SQLite applies these change sets of pages safely & atomically by using either a rollback journal or the write-ahead log. These two methods have a different approach but, at the end of they day, they both transactionally update a set of pages in a SQLite database."
"In LiteFS, we track the beginning and end of these transactions through the file system API. We can see which pages have changed and bundle them up in an internal file format called ."
""
"The rollback journal is a simple mechanism,  which makes it easy for LiteFS to determine when write transactions start & end. From a high-level, SQLite implements transactions like this:"
"Obtain an exclusive lock on the  &  lock bytes."
"LiteFS acts as a passthrough file system so it can see all these file system calls. On the initial journal creation, it begins watching for page changes. On , it marks a page as changed. And finally, on  it will copy the page change set to an LTX file and then delete the journal."
""
"SQLite‚Äôs operations when it uses the WAL mode are a bit more complicated but it still has similar start & end triggers."
"Obtain the  lock byte in the database file but also obtain WAL-specific locks such as ."
"LiteFS can read the list of changed pages from the WAL and copy them out to an LTX file when the final WAL write for the transaction comes in. Again, both the rollback journal and WAL are implementation details so we end up with the same LTX format with either one."
"In the WAL mode, SQLite will also maintain a shared-memory file (aka SHM) and uses it as an index to look up pages in the WAL. This piece is managed by SQLite so LiteFS doesn‚Äôt touch it during a write."
""
"Once an LTX file is created on the primary LiteFS node, it will send it to all connected replica LiteFS nodes. These replicas will validate the file, perform some consistency checks, and then apply the change set to the SQLite database."
"The LiteFS replica imitates a SQLite client and takes the same locks in order to apply the transaction. That means it looks like just another SQLite client doing an update so it‚Äôs safe across other processes using the database."
""
"Previously, it was tough to convert an existing application to use LiteFS. You‚Äôd need to create a SQL dump of your database and import in using the  command line. That was a pain."
"We‚Äôve improved this workflow with the new  command. This command lets you remotely send a SQLite database to your LiteFS cluster and it will transactionally replace it. That means you can start a cluster with an existing database or you can even revert to an old snapshot on a live application."
""
""
"LiteFS uses a fast, incremental checksum for ensuring the state of the entire database is consistent across all nodes at every transaction. The method is simple: we XOR the  checksums of every page in the database together. This approach let us incrementally update individual pages by XOR'ing out the old checksum for a page and XOR'ing in the new checksum for the page. That‚Äôs pretty cool."
"However, in practice, it was difficult to ensure we were calculating the correct previous checksum for a page every time we performed an update as page data is spread across the database file, journal file, & WAL file. The edge cases for determining the previous page data were too easy to get wrong."
"So in v0.3.0, we decided to rework the database checksum. It still uses the same algorithm of XOR'ing page checksums but now we maintain a map of the current checksum of every page in the database so they can be XOR‚Äôd together on commit. We no longer need to track the previous checksum and this change made a lot of edge cases disappear."
"This approach is not without its trade-offs though. First, it requires additional memory. The map keys are 4-byte unsigned integers and the values are 8-byte hash values so we need about 12 bytes per page. SQLite uses 4KB pages by default so that‚Äôs 262,144 pages per gigabyte. Our total memory overhead for our map of page hashes ends up being about 3MB of RAM per gigabyte of on-disk SQLite database data. LiteFS targets database sizes between 1 to 10 GB so that seemed like a reasonable trade-off."
"Second, this approach adds CPU overhead after each commit. Map iteration and XOR computation are quite fast but these do begin to show up in performance profiles as the database grows. In our tests, we‚Äôve found it adds about 5ms per gigabyte of SQLite data. That‚Äôs pretty high. Fortunately, much of this iteration can be cached since XORs are associative. We‚Äôll be implementing this cache in the next version of LiteFS."
""
"One benefit to having checksum bugs in v0.2.0 was that it gave us plenty of time to get our hands dirty with debugging. The best tools come out of necessity and the LiteFS trace log is one of those tools."
"Debugging a failed database or distributed system is  in that you know how it ended but you need to put the pieces together to figure out how it happened."
"In the previous version of LiteFS, we didn‚Äôt have many clues when one of these failures happened so it required a Sherlock Holmes level of deductive reasoning to figure out the mystery. The trace log simplifies this process by writing out every internal event to a log file so we can see where things went awry after the fact."
"SQLite uses the POSIX file system API so debugging with a normal  would look like a series of seemingly opaque system calls. LiteFS translates these system calls back into SQLite related actions such as  or . When we write those events to the trace log, we can decorate the log lines with additional information such as page numbers and checksums. All this makes reading the trace much more straightforward."
"The trace log is not without its costs though. It will increase I/O to your disk as there are a lot of events that are written. It‚Äôs typical to see your disk I/O double when you enable the trace log. However, it does cap the total size of the trace log by using a rolling log so you don‚Äôt need much space available. By default, it will roll over to a new log file every 64MB and it will retain the last 10 logs in a gzipped format."
"The trace log is disabled by default, however, you review the  if you need it to debug any LiteFS issues."
""
"The WAL support & stability improvements have been huge steps in moving LiteFS to be production ready but there‚Äôs still more work to come. In the next release, we‚Äôll be focused on making LiteFS easier to integrate into your application by adding support for . That will let you write to your database from any node and have LiteFS automatically forward those writes to the primary instead of having your application redirect writes."
"We‚Äôll also be making performance improvements by adding  to the LTX files. This will reduce latency between nodes and it will significantly cut down on bandwidth costs."
""
"Finally, we‚Äôd like to give a huge shoutout for everyone who has tried LiteFS and given feedback. It makes a world of difference!  even live streamed his experience with LiteFS and it gave us incredible, detailed feedback. Thank you!"
""
""
""
"We love databases that scale globally. As an  database provider, we built a global, automated , and we  on scrappy startup weekends. But the Fly.io forecast called for integration over invention. So we partnered up on launching a simple, global, low-latency Redis service built by the intrepid crew at ."
"sounds good enough to launch a cologne. We think it‚Äôs as big a deal. Oh, and there‚Äôs a ."
"Keep reading to learn how our first integration came to life. Or, just  and give it a try:"
""
""
""
"So what‚Äôs special here? I assure you: this isn‚Äôt stock Redis with a price tag slapped on."
"Complex features like global read replicas demand good DX to get noticed. But in the managed Redis market, read replicas are elusive, hidden behind sales calls, enterprise pricing plans and confusing UI."
"With  and a few keystrokes, you can spin up global Redis replicas in seconds, with  switched on. Reads  writes make their way to the geographically-nearest replica, which happily forwards writes along to its primary,  along the way. So, with a single Redis URI, you can safely experiment with global deployment without changing your app configuration."
"VM-to-Redis requests are reliably fast, in every region, because your apps run on the same bare metal hardware as your databases, one network hop away at most. Check out Upstash‚Äôs  to compare Fly.io with serverless platforms like Vercel or AWS. This comparison is not entirely fair, as we run apps on real VMs; not in JavaScript isolates. But we love the colors."
"Finally, it‚Äôs worth mentioning these databases are secure: only reachable through your Fly.io encrypted, private IPv6 network."
""
"When this integration was on the cards, we had two clear goals: don‚Äôt expose Redis to the internet, and give Upstash full control of their service without compromising customer app security. Serendipity struck as we pondered this."
"We were knee-deep in fresh platform plumbing ‚Äî the  and . The API grants precise control over where and how VMs launch. And Flycast yields anycast-like powers to apps on the private, ."
"So Upstash Redis is a standard Fly.io app ‚Äî a multitenant megalith running on beefy VMs in all Fly.io regions. These VMs gossip amongst themselves over their private IPv6 network. Upstash uses our API to deploy. We support Upstash like any other customer. Awesome."
"But Redis runs in its own Fly.io organization, and therefore, in its own isolated network. And customer apps, each in their own. We needed a way to securely connect two Fly applications. Enter Flycast, stage left."
"Flycast is a beautiful, complex cocktail of BPF, iptables and tproxy rules: fodder for another post! Flycast offers public proxy features ‚Äî geo-aware load balancing, concurrency control and TLS termination ‚Äî between apps that share a private network. With a small tweak, Flycast could now surgically join services with customer networks."
"Customer apps can connect to their provisioned Redis, but not to anything else in the Upstash private network. Upstash can‚Äôt access the customer‚Äôs network at all. Mission accomplished."
""
"You might be curious how provisioning Redis works, end-to-end."
"Your  hits the Fly.io API. We mint a fresh Flycast IP address on your network and pass that IP along to Upstash‚Äôs API with the desired database configuration."
"In the same request, Upstash informs their Fly.io mega-deployment about your database, and we (Fly.io) point the Flycast address at Upstash‚Äôs app. We blast this info to our global proxies. They‚Äôll now proxy connections on this IP to the nearest healthy mega-Redis instance. This all happens in a matter of seconds."
"Alright, so now you have a Redis connection URL to chuck requests at."
"Remember that Upstash‚Äôs Redis deployment is . Upstash hosts scores of customer databases within a single OS process. With a clever shuffling of data from RAM to , many, many more databases can fit in this instance than your average Redis running on its own VM."
"But multitenancy poses a problem. How can mega-Redis identify the target database for a given request?"
"Your Redis URL includes a unique database password (remember this is all private, encrypted traffic). Could we use this password to identify your database? Technically, yes, but if you leak your Redis password on a live coding stream, anyone else with a Redis database could hijack yours! Yeah, let‚Äôs not."
"Before, we passed your Flycast IP address to Upstash, so they have it on record. Could they match that against the source address of the incoming Redis TCP connection? Not quite! Connections to Redis pass through our proxy. So, traffic will appear to arrive from the proxy itself; not from your Flycast IP."
"No worries! We‚Äôve got another trick up our sleeve."
""
"Bonus: our proxy supports prepending  headers to TCP requests."
"This curious 10-year-old internet resident is understood by most web servers and programming languages. At the top of the protocol , we spot our problem:"
"Relaying TCP connections through proxies generally involves a loss of the
original TCP connection parameters such as source and destination addresses,
ports, and so on."
"Redis runs on port 6379, just because. Here‚Äôs a typical header for Redis connection initiation:"
""
"Here we have two IPs ‚Äî source and destination ‚Äî on the same lovingly-named network, . The source IP belongs to the application VM, which is assigned randomly and is of little use here. But the destination address is the Flycast IP assigned to our particular database. Ace."
"Now we‚Äôre in the home stretch. Redis parses this header, plucks out that Flycast IP, finds the associated customer database, and forwards traffic to it. In wafts the sweet aroma of victory."
""
"Let‚Äôs talk about a clear-cut use case for global Redis: caching HTML at the edge."
"Last year we turbo-boosted our Paris-based, recipe finder Rails app by . But our database has grown. We don‚Äôt need to replicate all of its contents, and we‚Äôre too busy to spend time optimizing our queries. Let‚Äôs just lean on a lightweight HTML cache, which Rails is good at."
"We know we can get similar or better performance by caching HTML in Redis alongside our deployed VMs. And we can do this in a few minutes, really. First, let‚Äôs add a few read replicas in distant, exotic lands."
""
"Then, with , our naive HTML cache is on the scene. Metrics can be boring, so, trust us that our  is still in the low milliseconds, globally, for GET requests on cached recipe pages."
""
"Now and then, one must write. And  is a thing you need to care about when hitting speed-of-light latency in global deployments. That‚Äôs life, kids."
"Readers hitting database replicas may not be served the very freshest of writes. We‚Äôre OK with that. Except in one case: when that replica is serving the author of the write. Good UX demands that a writer feel confident about the changes they‚Äôve made, even if they have to wait a few hundred milliseconds."
"To that end, Upstash Redis replicas take one of two paths to ensure a consistent read-your-own-write experience, with some trade-offs. Let‚Äôs talk it out."
"Isa ‚Äî one our recipe editors in Santiago ‚Äî is worried that the recipe for  mentions New Mexico Green Chiles. While they may be the first chiles , they‚Äôre generally not tossed into . So she makes corrections and proudly smashes that  button."
"Meanwhile, Santiago Redis has been diligently keeping track of the unique IDs of the writes that pass through Isa‚Äôs Redis connection."
"So, that write is forwarded on to Paris, securely, over the WireGuard mesh. Santiago Redis holds blocks on the write command, waiting for replication to catch up to . On a clear internet day, we might wait 150ms, and Isa is redirected to the recipe page and sees her updated recipe sans chiles."
"But under poor network conditions, we may need to wait longer, and we don‚Äôt want to wait forever. Editing must go on. This kind of thing can happen, and we need to be prepared for it."
"So, the less happy path: Santiago Redis waits up to 500ms for the written value to return via replication. After that, Redis client connection is released, suggesting to the Redis client that the write completed. Now, this is risky business. If we redirect Isa to her recipe before her write makes that round trip, she gets spicy  once again. New Mexican space chiles haunt her confused mind."
"No fear - Santiago Redis has our back. Remember that it was tracking writes? When Isa‚Äôs recipe read is attempted, Santiago grabs the ID of the most recently tracked write on her connection. It checks to see if that ID exists in the replicated database contents. If so, Isa gets a fast, correct read of her updated recipe."
"But if her change didn‚Äôt arrive yet, Santiago  to our our source of truth ‚Äî Paris Redis ‚Äî at the cost of another full round trip to Europe. Such is the price of consistency."
""
""
""
"Ok, it‚Äôs been longer than a week since the last update because a lot of us at Fly were enjoying some time with ü¶É, ü•ß, and üë®‚Äçüë©‚Äçüëß‚Äçüë¶. Let‚Äôs get to it!"
""
"Dov Alperin wires up Replicache to WebSockets to show how any framework and Fly can be used to build realtime web applications. Check it out if you aspire to build the next Figma."
"Read"
""
"The Laravel team at Fly continues to crank out some pretty great tutorials."
""
"Use WebSockets to stream content from the server to a persons web browser. Chris Fidao walks through an example that shows how a log file could be streamed from a server to anybody watching it from a browser."
"Read"
""
"When paginating large datasets between the server and browser, you don‚Äôt want to load so much data that the users browser slows down and becomes unresponsive. Kathryn Anne Tan shows how this data can be unloaded so that the people using your website don‚Äôt have to deal with all your baggage."
"Read"
""
"In September,  either ‚Äúmonthly‚Äù, ‚Äúweekly‚Äù, ‚Äúdaily‚Äù, and ‚Äúhourly; however, there is no way to control the precise time those jobs run because it‚Äôs a hard problem to solve at scale."
"Now there‚Äôs a guide for those who need more precise control over cron that runs on both versions of the Fly Apps platform. Brad Gessler runs through how to wire up Superchronic in your Fly Dockerfiles and deploy cron to production."
"Read"
""
"Did you know that Fly actually wants you to use off-platform database services, like RDS, CrunchyData, or PlanetScale? Well then how the heck did we end up building Fly Postgres!? Chris Nicoll and Shaun Davis walk down memory lane and chronicle how it all happened."
"Read"
"P.S. If you‚Äôre CrunchyData, PlanetScale, or a cloud infrastructure provider you should run your infrastructure on Fly."
"If you‚Äôre in the northern hemisphere, stay warm! See you on the next edition of The Logbook."
""
""
""
"Fly.io is an ambivalent database provider‚Äîone might even use the word ‚Äúreluctant‚Äù. The reasons for that are interesting, as is the way Fly Postgres works. When we relate this in conversations online, people are often surprised. So we thought we‚Äôd take a few minutes to lay out where we‚Äôre coming from with databases."
"We started Fly.io without durable storage. We were a platform for ‚Äúedge apps‚Äù, which is the very 2019 notion of carving slices off of big applications, leaving the bulk running in Northern Virginia, and running the slices on small machines all around the world. In an ‚Äúedge app‚Äù world, not having durable storage makes some sense: the real data store is in , and the slices are chosen carefully to speed the whole app up (by caching, running an ML model, caching, serving images, and caching)."
"Of course, people asked for databases from day one. But, on days one through three hundred thirty-one, we held the line."
"Somewhere around day fifteen, we grew out of the idea of building a platform exclusively for edge apps, and started looking for ways to get whole big crazy things running on Fly.io. We flirted with the idea of investing in a platform built-in database. We rolled out an (ultimately cursed) shared Redis. We even toyed with the idea of offering a managed ; like us, Cockroach is designed to run globally distributed."
"And then we snapped out of it. Databases! Feh!"
"Here‚Äôs our 2020 reasoning, for posterity: just because we didn‚Äôt offer durable storage on the platform didn‚Äôt mean that apps running on Fly.io needed to be stateless. Rather, they just needed to use off-platform database services, like RDS, CrunchyData, or PlanetScale. Hooking globally distributed applications up to RDS was (and remains) something ordinary teams do all the time. What did we want to spend our time building? Another RDS, or the best platform ever for you to run stuff close to your users?"
"By day two hundred and ninety or so, the appeal of articulating and re-articulating the logic of a stateless global platform for stateful global apps began to wear off. RDS! Feh! Somewhere around then, Jerome and Steve figured out LVM2, , and killed off the stateless platform talking point."
"Now, disk storage is just one of the puzzle pieces for giving apps a reliable backing store. Storage capabilities or not, we still didn‚Äôt want to be in the business of replicating all of RDS. So we devised a cunning plan: Build the platform out so it can run a database app, build a friendly database app for customers to deploy on it, and add some convenience commands to deploy and manage the app."
"We wouldn‚Äôt have a managed database."
"No, we have an automated database."
"Postgres is a good database for this. It‚Äôs familiar and just works with the migration tools baked into full-stack frameworks."
"In January 2021, we  a  command that would deploy an automagically configured two-node Postgres cluster complete with metrics, health checks, and alerts. (The alerts were as cursed as our shared Redis.) This was a big-deal effort for us. Back in 2020, we were really small. Almost everyone here had a hand in it."
"When Shaun arrived at Fly.io later that year, he took over the job of making Fly Postgres more reliable and more convenient to manage‚Äîstill in hard mode: developing and shipping features that make the platform better for apps  Fly Postgres, and making Fly Postgres plug into those."
"This post is mostly ancient history! Shaun‚Äôs no longer a team of one, and lots has happened since this post should have been written and shipped. Everything still holds; it‚Äôs just more and better now."
""
"Here‚Äôs a way you can run Postgres on Fly.io:¬†point  at the latest official . Remove the default services in , since this isn‚Äôt a public app. Provision and mount a volume. Store  as a Fly Secret. Deploy."
"(Then  in and create a database and user for your app.)"
"If you‚Äôll only ever want this one instance, this is pretty good. If anything happens to your lonely node, though, your Postgres service‚Äîand so, your app‚Äîis down (and you may have lost data)."
"Here‚Äôs a better setup: one primary, or leader, instance that deals with all the requests, and one replica instance nearby (but preferably on different hardware!) that stays quietly up to date with the latest transactions. And if the leader goes down, you want that replica to take over automatically. Then you have what you can call a high-availability (HA) cluster."
"Postgres has a lot of levers and buttons built right in. You can deploy two Postgres VMs configured so one‚Äôs a writable leader and the other is a standby replica staying up to date by ."
"What Postgres itself doesn‚Äôt have is a way to adapt cluster configuration on the fly. It can‚Äôt notify a replica that the primary has failed and it should take over, and it certainly can‚Äôt independently elect a new leader if there‚Äôs more than one eligible replica that could take over. Something else has to manipulate the Postgres controls to get HA clustering behaviour."
"That‚Äôs where  comes in."
""
""
"Stolon is a Golang Postgres manager. We chose it for a few reasons: it‚Äôs open source, it‚Äôs easy to build and embed in a Docker image, and it can use Consul as its backend KV store (we‚Äôre good at Consul)."
"We spun up a Consul cluster for Fly Postgres to use, and since it was there, we also"
"Stolon comes with three components that run alongside Postgres in each instance‚Äôs VM: a sentinel, a keeper, and a proxy."
"The lead sentinel keeps an eye on the cluster state as recorded by keepers in the Consul store, and decides if leadership needs to change."
"If the leader instance fails, the proxies start dropping all connections and Stolon elects a new leader, using Consul to lock the database in the meantime. If both (all) your instances fail, the database is unavailable until one or the other recovers.  New connections go to the new leader as soon as it‚Äôs ready, without rebooting clients or changing their config."
"If you‚Äôve ever received a late-night email from Heroku saying your DB was replaced, you know why this is awesome."
""
"Stolon is chatty as hell with Consul, and this can be a problem."
"Keepers, sentinels, and proxies do all their communication via the Consul leader.  If a Stolon component can‚Äôt reach Consul, it repeats its request until it can. A single flapping Stolon cluster, early on, could saturate our Consul connections."
"Meanwhile, if a Stolon proxy can‚Äôt reach Consul, it throws its hands in the air and drops all client connections until it can. We had several Postgres outages traceable to either Consul falling over or faraway Postgres nodes not being able to connect to it."
"The more Postgres clusters people spun up, the more of a problem this was."
""
"The Stolon proxy relies on Consul to know which instance to route connections to."
"But Consul isn‚Äôt the intrinsic authority on who the leader is: Postgres on every instance knows its own role. If we can replace the Stolon proxy with one that can just ask the nodes who‚Äôs leader, that‚Äôs less load on our shared Consul cluster, and if there‚Äôs trouble with Consul there‚Äôs one component fewer to freak out about it."
"It‚Äôs , but it‚Äôs possible to use HAProxy with Stolon, and we did."
"Here‚Äôs how we‚Äôve got HAProxy set up:"
"HAProxy listens on port 5432 on all Fly Postgres instances for read or write requests."
"We also added Consul clusters in a couple more regions. This spreads the burden on Consul, but crucially,¬†it puts Consul clusters close to people‚Äôs primary Postgres VMs. Network flakiness between Stolon and Consul breaks Stolon. The internet is flaky. The less internet we can span, the happier Stolon is."
"Stolon and Consul are still intense: we‚Äôve been adding new Consul clusters ever since to keep up."
""
"We‚Äôre running a few things on each Fly Postgres VM:"
"Stolon keeper"
"This is a pretty deluxe Postgres cluster app. You can shell into a running instance and add a database, restart the PG process, trigger a failover, run stolonctl commands directly, and more."
"Our Golang supervisor, flypg, glues the other processes together and does nice things like try to recover from individual process crashes before giving up and letting the whole VM get rescheduled."
"are open source; you can  it and add  or whatever."
""
"So that‚Äôs the Fly Postgres app. You can deploy it with  like any Fly app, straight from a clone of the . It is faster to deploy the built  straight from Docker Hub, and the image has version metadata you can use to upgrade later."
"The following will create a 2-instance HA cluster that apps on your org‚Äôs internal WireGuard network can connect to:"
"Copy fly.toml from the postgres-ha repo"
"Then, to let an app use this Postgres:"
"Use aforementioned in-VM commands on the Postgres leader to create a new user and database for the consuming app (you find the leader by running  on each instance until you hit the one with the  role)"
"Now I don‚Äôt know if I made that look complicated or simple!"
"It‚Äôs simple for what you get. Every instance of your postgres-ha  app is a magical cluster building block! Add an instance and it automatically becomes a member of the cluster and starts replicating from the leader. If it‚Äôs in the , it‚Äôs eligible to participate in leader elections. You can add nodes in other regions, too; they can‚Äôt become leader, but you can read from them directly on port 5433. It‚Äôs all inside the app.  in your consuming app, and you can do your reads from the closest instance and send your writes to the primary region."
"But yeah, this isn‚Äôt  the Fly Postgres experience. Since we expect lots of people to deploy this exact app, it was reasonable to bundle up that mild cluster-creation rigamarole into a  command, which is much like  with one of our more mature framework launchers. There are similar  for managing your d database cluster."
""
""
"We‚Äôve mentioned that continual reliance on Consul is something of an Achilles‚Äô heel for Stolon-managed clusters. It‚Äôs not unique to Stolon and Consul, but a matter of needing a separate backend store for cluster state: in return for high availability and Borg-like assimilation of new instances, we accept an additional failure mode."
"If you‚Äôre running a single node, and you‚Äôre never going to add another one to make a cluster, there‚Äôs no upside to this high-availability machinery. A lone node is more reliable without any of it."
""
"But quite a lot of people do run Fly Postgres on a single instance (just for development, right??). It‚Äôs still automated, and you still get the knowledge that you‚Äôre in good company and deploying a maintained app."
"The great thing is: if you really want the simpler setup, you can just deploy your own Postgres app. It‚Äôs all apps on Fly.io!"
""
"You can, and should, make your own backups of data that‚Äôs important to you. That being said, a restore-your-database feature is guaranteed to make people‚Äôs lives easier."
"If you‚Äôre shipping Postgres as a Service and don‚Äôt care about the underlying infrastructure, you‚Äôll do Postgres native backups, copy data files and the WAL to object storage somewhere, then restore from those. Stolon will manage this for you."
"But if you‚Äôre building infrastructure that can run databases, this doesn‚Äôt move you forward: every database has its own mechanism for backing up individual files. Some require data dumps using specific tools, some let you copy files out of the file system, etc."
"Volumes, which hold users‚Äô persistent data‚Äîfor Postgres, SQLite, or whatever‚Äîare logical volumes on SSDs physically installed in our servers. We have low-level block device powers and the ability to take consistent, block-level snapshots of a disk."
"So that‚Äôs how we back up a Postgres database: by periodically grabbing a point-in-time version of the raw block device it‚Äôs on. You recover a database by restoring this to an entirely new block device and deploying a Postgres instance to use it."
"Conveniently, that approach works for pretty much anything that writes to a file system, solving backups for anything you want to run on Fly.io."
"Once we got user-facing snapshot restores working for Postgres apps, we could generalize that to Volumes at large. Which is good, because people run every database you can think of on Fly.io."
"This is a good example of ‚ÄúPostgres‚Äù work that was actually platform work with an elephant face taped on.  Like persistent storage itself, shared Consul, our crap health-check alerts, image version updates, and countless ‚Äúhow should flyctl and the platform behave‚Äù minutiae."
""
"So Fly Postgres is an app, not a database service. This is not a bummer: it‚Äôs fascinating, I tell you! Working on this one app helps us work through what we want the platform to offer to apps and how to implement that. It‚Äôs an intrinsic part of the process of building a platform you could run  fully managed database service on."
"Meanwhile, we don‚Äôt blame you if you‚Äôd actually prefer a boring managed database over our fascinating app. We love boring! Boring can be the best experience! We think the best solution to this is to partner with service providers to do integrations that really nail the Postgres, or MySQL, or Redis(!), or whatever, UX on Fly.io. After all, there‚Äôs no single best database for everyone."
"And for all that, heading for 2023, Fly Postgres is doing the job for lots of apps! Automated Postgres turned out more useful than we‚Äôd have predicted."
""
""
""
"Imagine this: you have invented the best design tool since Figma. But before you can compete with the design-industry heavyweight, you need to be able to compete on one of Figma‚Äôs main propositions: real-time collaboration. You do some research and find that this is an upsettingly hard problem."
"You start with a single server that coordinates users‚Äô changes for each document, using something like Replicache (which we‚Äôll come back to in a sec). Clients connect over WebSockets. But your business grows, and that one server gets overloaded with connections."
"You‚Äôll have to split your documents among servers, but that means routing connections for each document to the server that has it. What now? Write complex networking logic to correctly route connections? ‚ÄúThere has to be a better way,‚Äù you say to yourself."
"‚ÄúThere is!‚Äù I say, popping out of your computer!"
"OK, I may have passed through ‚Äúconversational writing style‚Äù right into ‚Äúwitchcraft.‚Äù Let‚Äôs reel it back in."
"I‚Äôm going to demonstrate what I think is a good solution for the problem of a distributed real-time backend, using ,  and a Fly.io feature : the ."
"Our demo app for today is‚Äîdrum roll‚Äîa real-time collaborative todo app!"
""
"Replicache is a ‚Äú.‚Äù It handles the hard parts of collaboration tech for us: conflicts, schema migrations, tabs, all the good (and bad) stuff."
"Unfortunately for us, for all that Replicache is super good at, it does not use WebSockets. But Websockets are perfect for frequent bidirectional updates to a document! Thankfully, using the Power of Software‚Ñ¢ we can just make Replicache bend to our WebSockety will."
"The protocol that Replicache uses can be described in three parts: a  endpoint that clients can use to push changes to the server, a  endpoint the client can use to pull changes made since the last time it pulled, and a persistent connection (usually either WebSockets or Server Sent Events) to  clients and let them know something has changed so they should pull. If the protocol requires a persistent connection anyway, we should make everything work over that connection."
"Don‚Äôt do what I am about to describe in production without some serious thought/tuning. While the way I do things totally , I also have not tested it beyond the confines of this basic demo, so like, proceed with caution."
"Building on  which implements the ,  , and  endpoints, I added a new endpoint for opening a WebSocket connection to a given ‚Äúroom‚Äù; in this case a room is just a given document."
"Here is the (slightly simplified) flow that happens when a WebSocket connection is opened via :"
"The connection is opened."
"The actual process is slightly more nuanced to prevent sending more over the wire than we really have to (like updates we know clients have already seen). Every time we send a message to a given client we remember that we sent it. This way, the next time we need to update the client we can just send it what has changed and not the whole document. If you are curious how the server sync logic works, the code is available ."
"This whole process is implemented on the client basically in the inverse by overriding the Replicache client‚Äôs  and  logic to use our persistent WebSocket connection. When the frontend receives a message it stores the changes from the message in a temporary array, then instructs the Replicache client to ‚Äú‚Äù. The trick is that we override the  logic from the Replicache client to just read straight from the array we‚Äôve been storing websocket messages in."
""
"We similarly override the  functionality to write the message over our websocket instead of HTTP."
""
""
"Let‚Äôs take a look at the architecture diagram for this demo."
"The Replicache WebSocket server we just talked about is what we can see running on each Fly machine in the backend section. For the sake of the Figma-like app example, we can think of each machine running the backend for a given design document. You can see them named room(a-d)."
"We can see something cool happening, though: instead of our clients having to know where to find the specific backend server where the document they want lives, all the clients connect via the same router. The router is the super cool part of this app."
""
"Let‚Äôs think for a second about what our router has to do:"
"Know the address of the server the user‚Äôs stuff is on"
"For the sake of this demo, we will consider requirement  out of scope and have our router use hardcoded values."
"For requirement , we just need to help the client find the right backend machine for its document when it makes a request for a WebSocket connection upgrade; the client and the backend can establish their connection and communicate directly from then on."
"We‚Äôll be running the backend servers as Fly Machines on the same Fly.io private network as the router app, which means we can use a super-cool feature called  to send a connection request on to a given VM."
"is a special header that fly-proxy, the aptly named Fly.io proxy, understands, that can be used to  a request somewhere else inside your private network. For instance, to replay a request in region  your app‚Äôs response could include the header . You can also do , to target a specific VM. This is what we‚Äôll use in our router."
""
"I unfortunately am not going to make the Next Best Thing Since Figma in this post for the sake of example, but I built something almost as good: a collaborative real-time todo list based on this  from Replicache."
"Our todo list has three layers (directions to actually run these yourself can be found  ):"
"The frontend: a simple  that connects to‚Ä¶"
"For the backend we  just have a pool of Fly machines, each one responsible for a single todo list. Each todo list will be identified by the id of the machine it runs on."
"So when a client connects to   on the router, the router responds with . This response is handled by fly-proxy, who replays the request against the appropriate backend machine, and : the client is now directly talking to the right backend machine."
"We now have a way over-engineered todo list(s): each list runs on its own VM, and a simple router leveraging  sends WebSocket connections to the correct backend."
"You can check out the demo for yourself at . You‚Äôll see a list of clickable IDs. Each ID is a machine running an instance of the backend which corresponds to an individual todo list. If you are so inclined to set this demo up for yourself, the code and instructions are ."
""
""
""
"we got improved ‚Äîthis week we get even more goodies that make it easier to deploy and monitor Elixir apps in production."
""
"Mark rolls up his sleeves, grabs a shovel, and digs into getting Github Actions working for Elixir CI. The best part? You don‚Äôt have to get as dirty to get it setup because Mark did all the hard work for you."
"Read"
""
"After your  automatically deploys your app to production, learn how to use OpenTelemetry to monitor and track down performance issues in your production deployments. Alexander Koutmos shows us how by tracking down an N+1 query issue."
"Read"
""
"Amazing things happen on the Internet, like the Python community getting together and documenting how to deploying Django apps to Fly. While we don‚Äôt have an official 1.0 set of docs yet, it‚Äôs getting mighty close thanks to community contributors."
"has been pushing forward a more comprehensive guide for Django that‚Äôs way better than our current  in this . There‚Äôs also a thread in the  about an updated blogpost for deploying a ‚ÄúHello World‚Äù Django app."
"If you‚Äôre a Django or Python developer, check out the  or read the ."
""
"Chris updates our docs on how to deploy your own self-hosted S3-compatible object storage server to Fly. We still think its easier to use an S3 host, like AWS S3, but sometimes that doesn‚Äôt make sense when you need object storage in the same datacenter as your application."
"Read the"
"I‚Äôll see you next week!"
""
""
""
""
"Chris McCord writes about how React inspired LiveView reminding us that seemingly very different frameworks actually have a lot to learn from each other."
"It‚Äôs worth taking this moment to think about what you could learn from other frameworks that evoke strong emotions‚Äîthere‚Äôs lots to learn about what they did well, or even some of the mistakes they may have made."
"Read"
""
"Well well well, our documentation just keeps getting better around here.  we saw improvements to . This week Elixir is taking a turn."
"Read the revamped"
""
"Fly tries to make it very clear that we provide tools that make it easy to provision and manage a Postgres database cluster, but the tool is so good at quickly getting Postgres databases up and running that it‚Äôs easy to forget that its  managed."
"The Postgres docs were updated to lay out, in more detail, exactly what Fly manages and what we expect customers to manage."
"Read about"
"If managing a Postgres database isn‚Äôt your thing, we even threw in a few links to some popular managed Postgres services."
""
"There‚Äôs lots to learn this week about Laravel Livewire. Our first teacher, Kathryn Anne, makes complex client-side pagination, grouping, and sorting in a table look easy with ."
"Read"
"Then Chris walks us through how to send server-side notifications from a Livewire app to peoples‚Äô browsers who are currently using your app."
"Read"
""
"When you run  you‚Äôll be whisked into the Upstash Redis console where you‚Äôll see stats on your Redis instances and instructions on how to connect it to your application. Don‚Äôt forget to run  to get the latest CLI before you run this spiffy new command."
""
"It‚Äôs pretty slick how they work: define your processes and many of them will run inside of one container. Shhhh, don‚Äôt tell the container police that we‚Äôre running multiple processes inside of one container."
"Read the"
"See you next week!"
""
""
"It‚Äôs hard to overstate the impact React has had since its release in 2013. For me, React came with a few revelations. First was a reactive HTML-aware component model for building UIs. Second was colocated markup . Third, it focused on efficiency in a world where SPAs were increasingly heavy-handed."
"It was also something that I could grok in a weekend."
"My previous attempts at drive-by learning other reactive frameworks of the day were not so successful. Phoenix borrowed a lot from React when we first shipped LiveView in 2018, but only recently have we gone all-in with an HTML-aware component system in Phoenix 1.7."
"It‚Äôs hard to imagine building applications any other way. What follows is a heartfelt homage to React‚Äôs impact on the frontend and backend world, and how Phoenix landed where it did thanks to the revelations React brought almost ten years ago."
""
"With LiveView, I was inspired by React components and their beautifully simple programming model. A component is an object that defines a render function, and returns some HTML (or in later versions, a function that renders HTML). That function makes use of component state, and whenever a state change occurs the render function is called again."
""
"This was such a simple model to understand when coming into React for the first time. Here we have a React component with some state, and a  function. The function returns some HTML, and calls  when a button is clicked. Any time  is called, React will call  again, and the UI updates. Easy peasy."
"We borrowed from this with LiveView by taking that model and slapping it on the server in a stateful process:"
""
"I‚Äôve talked previously about , like the fact we don‚Äôt write bespoke routes, controllers, and serializers, or JSON APIs or GraphQL endpoints. But here we‚Äôre just appreciating how easy this model is to understand. In a world of ever-increasing framework complexity, React‚Äôs take on interactive applications was a breath of fresh air that we were quick to borrow."
"Another choice React made was also extremely contentious at the time: putting HTML right in with your app code. People hated it. But React was right."
""
"Like many folks ten years ago, you might still be thinking ‚ÄúHTML in your app code?! Are we back to the 2000‚Äôs PHP days of mixing code and markup together in a file? And we call this progress?‚Äù"
"These kind of takes were common. They also missed the point. Unlike the PHP days of yore, React applications weren‚Äôt a string concatenation of app code, HTML, and business logic masquerading as a web application."
"React‚Äôs JSX templates place the most coupled pieces of UI together: the markup and stateful code supporting that markup. Think about it: you have a bunch of variables (state) in your app code that are also needed in your template code for UI rendering or behavior. You also have a bunch of UI interactions in your templates that make it back into app code‚Äîlike button clicks. These two things are necessarily tightly coupled. Change either side of the contract and the other side breaks. So React made the wise step to put those tightly coupled things together."
"This brings us to a lesson React taught me that I later carried over to Phoenix: if two pieces of code can only exist together, they should live together. Or to think about it another way, if two pieces of code must  together, they must live together."
"There‚Äôs no guesswork on what happens if I change some LiveView state or LiveView template variables because they live in the same file. I also don‚Äôt have to search throughout the codebase to find which coupled-but-distant template file needs to be added or changed to accommodate the code I‚Äôm writing."
"Now, there are times where it‚Äôs not practical to write app code and markup in a single file. Sometimes template reuse or a large document means it makes more sense to have a separate template. In these cases, you want the next best thing: colocated files. In general, the tightly coupled parts of your application should be as close as practically possible. If not the same file, then the same directory, and so on."
""
"React also popularized HTML-aware components with their JSX template system. On top of writing HTML in your component‚Äôs app code, you  components from markup in an HTML tag-like way."
"This is more than a cute way to make function calls. It‚Äôs also not something I appreciated right away. The advantage of this approach is a natural composition of static HTML tags alongside dynamic components and logic. Large HTML structures quickly lose their shape when mixing dynamic code and reusable UI with tags‚Äîan issue with Ruby or Elixir-like templating engines."
"For example, imagine you need to render a collection of items, then within that collection, conditionally call some other template code. With Rails or older Phoenix style  templates, the markup structure almost entirely gets lost in the mess of branches:"
""
"This has a few problems. First, the markup structure is completely lost when mixing code branches and comprehensions."
""
"This makes template editing a brittle and frustrating experience. If our goal is to dynamically build markup, why does the markup structure get lost in the mix? It gets worse when we try to encapsulate this table into a reusable piece of UI. The best we could do prior to adopting React‚Äôs approach is bespoke functions or templates that hide the entire table from the caller:"
""
"Then the caller can render the component:"
""
"This works, but extensible UI components are all but impossible. The moment we want to customize one aspect of the table, we need to write another template like  which slightly alters the cells or adds more actionable links to another cell, and so on. If we tried to make it extensible without an HTML-aware component primitive, we‚Äôd end up with something like:"
""
"Our bespoke functions now mask the HTML structure, which makes it difficult to figure out what‚Äôs happening. We also can‚Äôt easily encapsulate table row and cell styling."
"Worse, we prevent the caller from passing their own arbitrary block content to our components."
"For example, imagine instead of a string ‚ÄúUsers‚Äù as the table title, the caller wanted to render HTML within the , such as a subtitle, icon, or even another component? With template engines that only do string concatenation, passing strings around prohibits all of this. A caller may try passing a string of HTML instead, but it‚Äôs a nonstarter:"
""
"Passing strings around for arbitrary content quickly breaks down. It‚Äôs not only terrible to write, but the user would have to forgo HTML escaping and carefully inject user-input into their dynamic strings. That‚Äôs a no-go."
"React‚Äôs JSX showed us a better way. If we make our templating engine HTML-aware and component calls become tag-like expressions, we  solve the readability issues. Next, we can allow the caller to provide their own arbitrary markup as arguments."
"React allows passing markup as an inner component block, or as a regular argument (‚Äúprop‚Äù in React parlance) to the component. For example, in React, one could write:"
""
"Later frameworks like Vue, and the  standardized and expanded this concept with the ‚Äúslot‚Äù terminology."
"In Phoenix, HTML syntax for components along with slots turns our mess of mixed HTML tags and strings into this beautifully extensible UI component:"
""
"The Phoenix HEEx template engine supports calling components external to the current scope in a similar React style, such as . Phoenix also allows calling imported function components directly with the  notation."
"In the table example above, we call the  function with arguments passed in a tag-like attribute syntax, just like in React props. Next, the table accepts an internal block of arbitrary markup, and we here we can make use of slots to pass  and  information."
"The neat thing about slots in Phoenix is the fact that they are collection based. The caller can provide an arbitrary number of entries, such as in our  example. To render a table, internally the  component can simply iterate over the s we passed for each , and ‚Äúyield‚Äù back to us the individual user resources. You can see this in action via the  syntax in the col entries."
"The internal table can also iterate over the s to build the s for the table head. What results is far more pleasant to write than pure HTML and can be extended by the caller without bespoke functions. The function component and slot primitives allow us to encapsulate everything about building tables in our UI in a single place."
"Like React, you‚Äôll find that your Phoenix applications establish a surprisingly small set of core UI building blocks that you can use throughout your application."
""
""
"My SPA trials and tribulations began before React entered this world. I‚Äôve gone from jQuery spaghetti, Backbone.js, Angular 1, Angular 2, Ember, and finally React. React provided just the right amount of structure, while being quick to pick up and get going with. It was also super fast."
"React really pushed the industry forward with their virtual DOM features. Instead of replacing large parts of the browser‚Äôs DOM with a freshly rendered template on any little change, React kept a ‚Äúvirtual‚Äù DOM as a datastructure that it was able to compute diffs against. This allowed React to compute the minimal set of concrete DOM operations required to update the browser when state changes occur."
"This was groundbreaking at the time."
"Other SPA frameworks quickly followed suit with their own optimizations. Server-side frameworks are a different paradigm entirely, but they can learn a lot from React‚Äôs innovation. Phoenix certainly did."
"For Phoenix, we borrowed these ideas, but we have this pesky layer between the app and the client, known as the network. Our problem set is quite different from React, but if you squint, you can see all the same inspirations and approaches we took in Phoenix LiveView‚Äôs optimizations."
"For example, on the server we only want to execute the parts of the template that changed rather than the entire template. Otherwise we‚Äôre wasting CPU cycles. Likewise, we only want to send the dynamic parts of the template that changed down the wire instead of the entire thing to limit latency and bandwidth. While we don‚Äôt keep a virtual DOM on the server, we do keep track of the static and dynamic parts of the HEEx templates. This allows us to do efficient diff-based rendering on the server and send down minimal diffs to the client. Meanwhile, the client uses  to apply only the minimal patches necessary on the client."
"The end result is this: a state change occurs in the LiveView component tree, a diff of changes is computed on the server with noops where possible, and the minimal diff of changes is sent down the wire. On the client, we take those changes and apply them via a minimal set of DOM operations to efficiently update the UI. Sound familiar?"
""
"React changed the front-end game when it was released, and its ideas have trickled up to the backend world. And no, I don‚Äôt mean React Server Components (but React is also trickling up to the server too!). Outside of Phoenix, you‚Äôll find other backend frameworks now ship with their own HTML-aware component system, such as Laravel‚Äôs Blade templates in the PHP space."
"If you‚Äôre a backend framework in 2022 and not shipping an HTML-aware engine,  it‚Äôs time to follow React‚Äôs lead. I can‚Äôt imagine Phoenix not landing where we did, and my only regret is we didn‚Äôt follow React sooner. Thank you React for paving the way! ‚ù§Ô∏è"
""
""
""
""
"First up, some new documentation was created to run people through how to fail over a Postgres database."
""
"‚ÄúGetting Started‚Äù was updated to show how to setup a Postgres database and attach it to an application. There‚Äôs also docs on how to bring over your Postgres database from Heroku if you‚Äôre moving your apps over from there."
""
"If you have ideas for improving these docs, open the ‚ÄúEdit on Github‚Äù link at the bottom of each page to propose changes. Expect more improvements over the next few weeks."
""
"Want to know a secret that‚Äôs not a secret? Fly‚Äôs Postgres database  Fly does give you great tools to provision and upgrade Postgres instances, but if they run out of disk space and you don‚Äôt have monitoring hooked up, your customers will be telling you about it."
"Read the ."
"This isn‚Äôt to single anybody out‚Äîoutages happen to the best of us. I once  a production sever before containers made for easy recoveries, which is why I‚Äôm on a Frameworks team and don‚Äôt let myself near the Fly.io production servers. We just want folks to know what they‚Äôre getting into when they deploy their apps on Fly.io."
""
"Not to be confused with , ELK is a way to process streams of data and store them in a way that can be quickly retrieved later. In this example you‚Äôll learn how ELK can be used in a Laravel application to track user analytics and generate reports with them in a fancy pants dashboard."
"Read ."
""
"Why pay for something you‚Äôre not using? Chris McCord shows how a Phoenix app can shut itself down on  if it hasn‚Äôt received quests for a configurable period of time."
"Read ."
""
"You may have heard of Fly Machines, but did you know when you  an app today, it doesn‚Äôt deploy to a Machine?"
"Chris F lays out the differences you can expect between the way Fly apps currently behave today, and how they‚Äôll behave when they‚Äôre deployed to Fly Machines."
"Read the  post."
"does use Fly Machines, which you can read more about at  and the  post."
""
"A little change in the Fly dashboard goes a long way!"
"Read the  post."
"That‚Äôs it for this week. Happy Halloween, stay safe out there trick-or-treating, and I‚Äôll see you next week!"
""
""
""
"Full-stack developers are sleeping on SQLite, a database most devs think more suited to unit tests than production loads. That‚Äôs true enough for some apps. Most web apps are read-heavy, though, and we can use that to our advantage. With the right tooling, SQLite makes for faster, simpler web apps."
"To understand why we won‚Äôt shut up about SQLite, think about latency. You have a budget of around 100ms to make an app feel snappy. Individual Postgres queries add milliseconds of latency. Apps often run multiple queries before responding to users. Database round trips can take a big bite out of a latency budget."
"The same problem infects your full-stack code. Developing against a relational database requires devs to watch out for ‚ÄúN+1‚Äù query patterns, where a query leads to a loop that leads to more queries. N+1 queries against Postgres and MySQL can be lethal to performance. ."
"The challenge of building full-stack on SQLite is that it isn‚Äôt client-server: it‚Äôs a library that runs inside of your app. In the past, that‚Äôs made it hard to get durability and replication. Most devs aren‚Äôt comfortable with , where any downtime in your app server takes your whole app down."
"But you don‚Äôt need to make peace with single-server designs to take advantage of SQLite. Earlier this year, we wrote about why we‚Äôre . Litestream is SQLite‚Äôs missing disaster recovery system: it‚Äôs a sidecar process that hooks into SQLite‚Äôs journaling and copies database pages to object stores such as S3. Like SQLite itself, it has the virtue of being easy to get your head around; we explained most of the design , and using it just takes a couple commands."
"We want to see how far we can push this model, and so we‚Äôve been working on something new."
""
"At least, not as such."
"LiteFS extends the idea of Litestream with fine-grained transactional control. Where Litestream simply copies the raw SQLite WAL file, LiteFS can inspect and ship individual transactions, which span pages, and are the true unit of change in a SQL database."
"SQLite imposes on us a constraint that makes this transactional control harder: SQLite is baked into the apps that use it. If you build something that changes the SQLite library itself, you‚Äôre not building tooling; you‚Äôre building a new database. And we‚Äôre not interested in getting people to switch to a new flavor of SQLite."
"There‚Äôs two options for intercepting the file system API in SQLite:"
"Use the  abstraction in SQLite."
"The VFS option is easier so, naturally, we chose to build a FUSE file system. That‚Äôs how you‚Äôre supposed to do it, right?"
"LiteFS works by interposing a very thin virtual filesystem between your app and your on-disk database file. It‚Äôs not a file system like ext4, but rather a pass-through. Think of it as a file system proxy. What that proxy does is track SQLite databases to spot transactions and then LiteFS copies out those transactions to be shipped to replicas."
"In the default journaling mode, transactions are easy to identify: a write transaction starts when the  file is created, and ends when it‚Äôs deleted. The journal stores the page numbers and old page data and we can look up the new page data from the main database file."
"You see where this is going. SQLite‚Äôs exquisitely documented file format makes it easy for LiteFS to replicate whole databases. Now we‚Äôve got transaction boundaries. So we roll those transactions up into a simple file format we call . LiteFS replicas can replay those transactions back to recreate the current (or any previous) transaction state of a LiteFS-tracked SQLite database ‚Äî without touching app code. It seems like magic, but it‚Äôs a natural consequence of SQLite‚Äôs strong design."
""
"First off, we have nothing against the SQLite VFS system‚Äîit‚Äôs great! We‚Äôre planning on also releasing LiteFS as a VFS with a super catchy name like‚Ä¶ LiteVFS."
"If you‚Äôre unfamiliar with VFSes, they serve as an abstracted file system API. In fact, you use them all the time since SQLite ships with two built-in VFS modules: one for Unix & one for Windows. You can also load a third-party VFS as an extension, however, therein lies the first problem. There‚Äôs an extra step to use it. Every time someone needs to use the database, they have to remember to load the VFS. That includes when your application runs but also when you just load up the  CLI."
"LiteFS also needs to run an API server to replicate data between nodes. This gets complicated if you have multiple processes on a single machine trying to access the same local database. Which one runs the API server?"
"The FUSE file system solves many of these usability issues by being a single point that all database calls go through. Once you mount it, there‚Äôs no additional steps to remember and any number of processes can use it just like a regular file system."
""
"LiteFS‚Äô roots are in Litestream which was built with a simple purpose: keep your data safe on S3. However, it still ran with a single-server architecture which poses two important limitations."
"First, if your one server goes down during a deploy, your application stops. That sucks."
"Second, your application can only serve requests from that one server. If you fired up your server in Dallas then that‚Äôll be snappy for Texans. But your users in Chennai will be cursing your sluggish response times since there‚Äôs a 250ms ping time between Texas & India."
"LiteFS aims to fix these limitations."
"To improve availability, it uses leases to determine the primary node in your cluster. By default, it uses Hashicorp‚Äôs ."
"With Consul, any node marked as a candidate can become the primary node by obtaining a time-based lease and is the sole node that can write to the database during that time. This fits well in SQLite‚Äôs single-writer paradigm. When you deploy your application and need to shut down the primary, that node can release its lease and the ‚Äúprimary‚Äù status will instantly move to another node."
"To improve latency, we‚Äôre aiming at a scale-out model that works . That‚Äôs to say: writes get forwarded to the primary and all read requests get served from their local copies. Most app requests are reads, and those reads can be served lightning fast from in-core SQLite replicas anywhere in your deployment."
"But wait, that‚Äôs not all! There are many ways to do replication and each application has its own needs around data access. LiteFS also lets you use a static primary node if you don‚Äôt want to use Consul."
"We even have more topologies in the works. We‚Äôve had suggestions from the community to support other approaches like . That would allow folks to stream real-time database updates to customers outside their network instead of customers connecting in. Kinda niche, but cool."
""
"LiteFS uses asynchronous replication between a loose membership of ephemeral nodes. It trades some durability guarantees for performance and operational simplicity that can make sense for many applications."
"It‚Äôs able to do this because the primary election through Consul is dynamic and self-healing, which is again both the good and the bad news. Because dynamic topologies can have weird failure modes, LiteFS is designed defensively: we maintain a checksum for the entire state of the database and include it in each LTX file. This sounds expensive, but we can maintain it incrementally."
"We‚Äôre able to maintain this checksum by calculating the checksum for each page and XOR'ing the results together:"
""
"When a transaction changes pages in the database, we‚Äôll start with the checksum of the previous LTX file, remove the old checksums for the changed pages, and add in the new checksums for the changed pages:"
""
"Since XOR operations are commutative, we can even checksum across compacted LTX files or checksum the current state of the database. We can do this in LiteFS because we have fine-grained control over the file system writes."
"These database checksums ensure that an LTX file cannot be applied out of order and corrupt your database: they ensure byte-for-byte consistency for all the underlying data. We verify these on startup so that every database must be in a consistent state relative to its LTX checksum."
""
"We think LiteFS has a good shot at offering the best of both n-tier database designs like Postgres and in-core databases like SQLite. In a LiteFS deployment, the parts of your database that really want to be networked are networked, but heavy lifting of the data itself isn‚Äôt."
"It‚Äôs not just about performance. If you‚Äôre using a database server like Postgres or MySQL today, chances are you‚Äôre using a ‚Äúmanaged‚Äù database service, where some other team is making sure your database is up and running. Everybody uses managed services because keeping database servers happy is annoying. With SQLite, there‚Äôs not as much stuff that can break."
"And we‚Äôll keep saying this: the reason we think LiteFS and full-stack SQLite is a good bet is that the design is simple. You can  and understand what each of these components is doing. SQLite is one of of the most trusted libraries in the world; most of our job is just letting SQLite be SQLite. Your app doesn‚Äôt even need to know LiteFS is there."
"We‚Äôre plowing ahead on LiteFS features. Here are a few big ones to look out for:"
"today, LiteFS works with SQLite‚Äôs default rollback journal mode. But WAL mode is where it‚Äôs at with modern SQLite. The FUSE proxy model works fine here too: transactions start with a write to the  file, and end with another write that marks a header with the  field set."
"SQLite works with a single-writer, multiple-reader model and our primary/replica replication mimics that. However, it adds friction to require developers to forward writes to the primary node. Instead, we‚Äôre making it so any node can perform a write and then forward that transaction data to the primary. The primary can then replicate it out to the rest of the cluster."
"running a cluster of LiteFS nodes significantly improves your durability  over a single-server deployment. However, nothing gives quite the same warm fuzzy feeling as tucking away a copy of your database in object storage. This will work similarly to Litestream, however, LiteFS‚Äô LTX files are built to be efficiently compacted so restoring a point-in-time copy of your database will be nearly instant."
"we want developers to feel safe keeping SQLite replicas on services like S3. So we‚Äôve designed an AEAD encryption scheme that fits into LiteFS naturally and ensures that even if you manage to expose your LTX files to the Internet, you won‚Äôt have exposed any plaintext."
""
"After several months of work, we‚Äôre comfortable calling LiteFS beta-ready. We‚Äôd be happy if you played around with it."
"We‚Äôve set up a  so you can get going with it and understand how it works. The easiest way to get up and running is to walk through our  guide. It only takes about 10 minutes and you‚Äôll have a globally-distributed SQLite application running. Crazy, right!?"
"LiteFS is completely open source, developed in the open, and in no way locked into Fly.io, which invests resources in this solely because we are nerds about SQLite and not in any way because LiteFS is part of a secret plan to take over the world. Pinky-swear!"
""
""
""
"Running a Minecraft server for friends has become an archetypal first foray into the workings of the Internet. For some it‚Äôs learning to expose the tender underbelly of a home network to outside connections. For others it‚Äôs exploring the world of VMs, SSH, and infinite VPS options."
"For me, as for so many, a Minecraft server was an early experience of running a ‚Äúproduction‚Äù web service‚Äîone that others consumed and ‚Äúdepended‚Äù on. Mine was a DigitalOcean droplet held together with glue and duct tape."
"Just a few years of experience (and a gig at a cloud-compute company) later, here‚Äôs my new take on this: an over-engineered, scale-to-zero Minecraft server running on a ."
""
"Imagine this: you‚Äôre middle-school me and your Minecraft server has picked up a few more Daily Active Users than you‚Äôd expected. RAM is running low and the mortification of disappointing your peers is fast approaching as VPS resource utilization creeps up."
"You scale the VPS up: more vCPUs, more RAM, smoother gameplay. You are now munching hungrily through the free tier of your hosting provider, or worse,  to keep your friends in enchanted boots and rotten flesh. Wouldn‚Äôt it be awesome if the munching could stop when nobody‚Äôs actually playing? Even better if the VM could start up again and carry on automatically when someone attempts to connect again."
"This is the fundamental idea of scale-to-zero on Fly Machines: shut them down when no one is using them, but start them back up again when the user needs it, fast enough that no one is ever the wiser."
""
"Our magic scale-to-zero Minecraft server takes a few ingredients:"
", to abstract the Fly.io API into a declarative configuration file. We‚Äôll configure the app and specify the resources to provision within . Then  will make it all happen. You can deploy the same app with . But Terraform is what my whole gig at Fly.io is about! Naturally I‚Äôm going to take advantage of it here."
""
"If you don‚Äôt have Terraform yet, now‚Äôs a good time to ."
"Set the FLY_API_TOKEN environment variable. The Terraform provider uses this to authenticate us to the Fly.io API:"
""
"In a new terminal, open a proxy to give Terraform access to the internal APIs we‚Äôll be using. Leave it open:"
""
"Create a new directory to work in:"
""
"Then let‚Äôs start our Terraform prep by creating a file called  where we can import the Fly.io provider:"
""
"With this in place, run  to set up your workspace."
""
""
"We are going to create four different resources:"
"A Fly.io app, which is a sort of administrative umbrella that the VM will belong to;"
"We will use the following assumptions for now:"
"The app name is  (replace this with a name of your own), and"
"Add the following blocks to the   we created earlier:"
""
"The first block creates the Fly.io app, as you might guess. From there we have blocks that create a 15GB persistent storage volume and an IPv4 address."
"Now we get to the meat of it: the  block. We start off by defining some basics: the machine name, what app it belongs to, what region it should run in, and what image it should run. In this case we use the super awesome  Docker image from itzg."
"The  block sets environment variables used by  for configuration; for example, we‚Äôre setting the Autostop feature to shut down the VM when no one‚Äôs been connected for 120 seconds."
"The  block exposes port 25565 to the outside world via the IP we defined earlier, and the  block connects the previously defined volume to our machine."
"You may have noticed the MEMORY environment variable that we set to . A Minecraft server wants a fair amount of memory, and some CPU oomph to match. So we specify vCPUs and 8G of RAM for this VM."
"Finally, with  we tell Terraform to make sure the app and the volume are in place before trying to start a VM."
""
""
"Once you have finished tweaking anything you want to tweak in the Terraform file, go ahead and run  (and confirm when it prompts you) to create all the resources."
"Once the command stops running, open up your Minecraft Java Edition installation, head to the multiplayer screen and connect to  (once again replacing it with the app name you chose earlier) and find a tree to cut down with your fist!"
""
"Once you have played around for a few minutes, try quitting out of Minecraft and watch the logs on the Monitoring tab of the Fly.io dashboard. You‚Äôll see that once the configured timeout is hit, it will shut itself down. Try connecting again, you‚Äôll see the machine automatically start itself back up. Cool huh? :)"
"If you are done with this guide and don‚Äôt intend to use the server again, go ahead and destroy the app. We have a cornucopia of tools for destruction! Since you created this app with Terraform, you can use ; for any Fly.io app, including this one, there‚Äôs also ; or you can hit the red ‚ÄúDelete app‚Äù button under your app‚Äôs Settings tab in the Fly.io dashboard. Check in your dashboard, or use , to check that it‚Äôs gone."
""
""
""
"SQL is a weird concept. You write your application in one language, say JavaScript, and then send commands in a completely different language, called SQL, to the database. The database then compiles and optimizes that SQL command, runs it, and returns your data. It seems terribly inefficient and, yet, your application might do this hundreds of times per second. It‚Äôs madness!"
"But it gets weirder."
"SQL was  to interact with the database, however, it‚Äôs used almost exclusively by software developers peppering it throughout their applications."
"Why would this language made for ‚Äúbusiness folks‚Äù  become the industry standard for how applications are built?"
"One of the key benefits of SQL is that it is declarative. That means you tell the database what you want but not how to do it. Your database knows  more about your data than you do so it should be able to make better decisions about how to fetch it and update it. This lets you improve your data layer by adding indexes or even restructuring tables with minimal effects on your application code."
"SQLite is unique among embedded databases in that it not only has a transactional, b-tree storage layer but it also includes a robust SQL execution engine. Today, we‚Äôre diving into how SQLite parses, optimizes, & executes your SQL queries."
""
"If you‚Äôve read our previous sandwich-themed SQLite blog posts on the , the , & the , then you‚Äôre probably feeling pretty hungry by now. You‚Äôre also probably tired of the tedium of making sandwiches by hand, so we‚Äôll use a sandwich-making machine as our analogy in this blog post."
"This machine will do a few tasks:"
"Take an order for sandwiches."
"The process for building and executing SQL queries is similar to this sandwich-building process, albeit less delicious. Let‚Äôs dive in."
""
"The first step is to give our machine an order. We hand it an order slip that says:"
""
"To our computer, this order is just a string of individual characters: , , , , etc‚Ä¶ If we want to make sense of it, we first need to group these letters together into words, or more specifically, ‚Äútokens‚Äù. This process is called ‚Äútokenizing‚Äù or ‚Äúlexing‚Äù."
"After tokenizing, we see this list of tokens:"
""
"From there, we start the parsing stage. The parser takes in a stream of tokens and tries to structure it some way that makes sense to a computer. This structure is called an  or"
"This AST for our sandwich command might look like this:"
""
"From here, we can start to see how we might take this definition and begin building sandwiches from it. We‚Äôve added structure to an otherwise structure-less blob of text."
""
"SQLite does this same process when it reads in SQL queries. First, it groups characters together into tokens such as  or . Then the parser builds a structure to represent it."
"The SQLite documentation provides helpful ‚Äúrailroad diagrams‚Äù to represent the paths the parser can take when consuming the stream of tokens. The  shows how it can start with the  keyword (for ) and then move into the , , and  clauses."
"When the parser is done, it outputs the aptly named . If you had a SQL query like this:"
""
"Then you‚Äôll end up with an AST that looks something like this:"
""
""
"So now that we have our sandwich order AST, we have a plan to make our sandwich, right?  Not quite."
"The AST represents what you want‚Äîwhich is a couple of sandwiches. It doesn‚Äôt tell us how to make the sandwiches. Before we get to the plan, though, we need to determine the optimal way to make the sandwiches."
"Our sandwich-making machine can assemble a plethora of different sandwiches, so we stock all kinds of ingredients. If we were making a monster sandwich loaded with most of our available toppings it might make sense for the machine to visit each ingredient‚Äôs location, using it, or not, according to the AST."
"But for our BLT, we need only bacon, lettuce & tomato. It‚Äôll be way faster if we can have the machine look up the locations of just these three toppings in an index and jump directly between them."
"SQLite has a similar decision to make when planning how to execute a query. For this, it uses statistics about its tables‚Äô contents."
""
"When SQLite looks at an AST, there could be hundreds of ways to access the data to fulfill a query. The naive approach would be to simply read through the whole table and check every row to see if it matches. This what we in the biz call a  and it is painfully slow if you only need a few rows from a large table."
"Another option would be to use an index to help you quickly jump to the rows you need.  An index is a list of row identifiers that are sorted by one or more columns, so if we have an index like this:"
""
"Then all the row identifiers for people who love ‚Äúmauve‚Äù are all grouped together in our index. Using the index for our query means we have to first read from the index and then jump to a row in the table. This has a higher cost per row as it requires two lookups, however almost no one likes mauve so we don‚Äôt have too many matching rows."
"But what happens if you search for a popular color like ‚Äúblue‚Äù? Searching the index first and then jumping to our table for so many rows would actually be slower than if we simply searched the entire table."
"So SQLite does some statistical analysis on our data and uses this information to choose the (probably) optimal recipe for each query."
"SQLite‚Äôs statistics are stored in several ‚Äúsqlite_stat‚Äù tables. These tables have evolved over the years so there‚Äôre 4 different versions of stats but only two are still in use with recent versions of SQLite:  & ."
"The  table has a simple format. It stores the approximate number of rows for each index and it stores the number of duplicate values for the columns of the index. These coarse-grained stats are the equivalent of tracking basic averages for a data set‚Äîthey‚Äôre not super accurate but they‚Äôre quick to calculate and update."
"The  table is a bit more advanced. It will store a few dozen samples of  values that are spread across  an index. These finer-grained samples mean that SQLite can understand how unique different values are across the key space."
""
"Once we have an optimized plan for building a sandwich, we should have our machine write it down. That way if we get the same order again in the future, we can simply reuse the plan rather than having to parse & optimize the order each time."
"So what does this sandwich plan look like?"
"The plan will be recorded as a list of commands that the machine can execute to build the BLT again in the future. We don‚Äôt want a command for each type of sandwich, as we may have a lot of different types. Better to have a set of common instructions that can be reused to compose any sandwich plan."
"For example, we might have the following commands:"
"- looks up the bin position of an ingredient."
"We also have one more requirement that‚Äôs not immediately obvious. We only have so much space to hold our finished sandwiches so we need to make one sandwich at a time and have the customer take it before making the next sandwich. That way we can handle any number of sandwiches in an order."
"This process of handing off is called  so we‚Äôll have a  command when where we wait for the customer to take the sandwich."
"We‚Äôll also need some control flow so we can make multiple of the same kind of sandwich so we‚Äôll add a  command."
"So putting our commands together, our plan might look like:"
""
"This set of domain-specific commands and the execution engine to run it is called a  It gives us a level of abstraction that‚Äôs appropriate for the task we‚Äôre trying to complete (e.g. sandwich making) and it lets us reconfigure commands in different ways for different sandwiches."
""
"SQLite‚Äôs virtual machine is structured similarly. It has a set of database-related commands that can execute the steps needed to fetch the results of a query."
"For example, let‚Äôs start with a table of people with a few rows added:"
""
"We can inspect this with two different SQLite commands. The first command is called  and it gives a very high level plan of the query. If we run it for a simple  with a conditional then we‚Äôll see that it performs a table scan of the  table:"
""
"This command can give more information as you do more complex queries. Now let‚Äôs look at the other command to further inspect the plan."
"Confusingly, it‚Äôs called the  command. Simply drop the ‚Äú‚Äù part of the first command and it will show a much more detailed plan:"
""
"This is the ‚Äúplain English‚Äù representation of the byte code that your query is compiled down to. This may look confusing but we can walk through it step-by-step to break it down."
""
"Just like how a computer has low-level CPU operations such  and , SQLite has a similar instruction set but it‚Äôs just at a higher level. As of this writing, there are 186 commands, or , that the SQLite VM can understand. You can find the  on the SQLite web site but we‚Äôll walk through a couple of them here."
"The first opcode is an  which initializes our execution and then jumps to another instruction in our program. The parameters for the opcodes are listed as  through  and their definition is specific to each command. For the  opcode, it jumps to the instruction listed in  which is ."
"At address  we arrive at the  opcode which starts our transaction. For most opcodes, the VM will move to the next address after executing the instruction so we move to address . This  opcode stores string value  into register . The registers act like a set of memory addresses and are used to store values during execution. We‚Äôll use this value later for our equality comparison."
"Next, we move to address  which is a  instruction which has us jump to the instruction listed in its  parameter, which is address ."
"Now we get into the row processing. The  instruction opens a  on the  table. A cursor is an object for iterating over or moving around in a table. The next instruction, , moves the cursor to the first entry of the database to begin our table scan."
"The  instruction reads the  column into register  and the  instruction compares it with the  value in register . If the values don‚Äôt match then we‚Äôll move to the  instruction at address . If they do match, we‚Äôll fill in registers  , , &  with the column , , &  for the row."
"Finally, we get to where we can yield the result back to the caller using the  instruction. This will let the calling application copy out the values in registers . When the calling application calls , the program will resume from where it left off by calling  and jumping back to re-execute the row processing at instruction ."
"When Next no longer produces any more rows, it‚Äôll jump to the  instruction and the program is done."
""
"The query execution side of SQLite follows this simple parse-optimize-execute plan on every query that comes into the database. We can use this knowledge to improve our application performance. By using bind parameters in SQL statements (aka those  placeholders), we can prepare a statement once and skip the parse & optimize phases every time we reuse it."
"SQLite uses a virtual machine approach to its query execution but that‚Äôs not the only approach available. Postgres, for example, uses a node-based execution plan which is structured quite differently."
"Now that you understand the basics of how an execution plan works, try running  on one of your more complex queries and see if you can understand the step-by-step execution of how your query materializes into a result set for your application."
""
""
"If you scour Hacker News & Reddit for advice about databases, some common words of caution are that SQLite doesn‚Äôt scale or that it is a single-user database and it‚Äôs not appropriate for your web-scale application."
"Like any folklore, it has some historical truth. But it‚Äôs also so wildly out-of-date."
"In our , we talked about the  That was SQLite‚Äôs original transactional safety mechanism and it left much to be desired in terms of scaling."
"In 2010, SQLite introduced a second method called the , or as it‚Äôs more commonly referred to: the WAL."
""
"The rollback journal worked by copying the old version of changed pages to another file so that they can be copied back to the main database file if the transaction rolls back."
"The WAL does the opposite. It writes the new version of a page to another file and leaves the original page in-place in the main database file."
"So how does this simple change enable SQLite to scale? Let‚Äôs revisit our sandwich shop example from the  to see how the WAL would make things run more smoothly."
""
"In our sandwich shop example, we had to choose between a single sandwich maker making sandwiches and one or more inventory specialists inventorying ingredients. We couldn‚Äôt do both at the same time. This is how the rollback journal works; a writer can alter the database or readers can read from the database‚Äîbut not both at the same time."
"This is a problem since making a complicated, time-consuming sandwich will prevent inventory from being taken. Also, a single slow inventory counter will prevent any sandwiches from being made."
"A simple solution would be to take a photo of every ingredient after a sandwich is made. That way inventory counters could look at the photos to take inventory. However, it would be slow and inefficient to take a photo of every ingredient after a sandwich since many ingredients wouldn‚Äôt change. For example, if you‚Äôre making a grilled cheese then you‚Äôre not going to touch the pickles, right? Right!?"
"A better solution would be to only take photos of the ingredients you took from after each sandwich. You can add these photos to a binder and now the inventory folks can see a point-in-time snapshot of the ingredients without interfering with the sandwich maker."
"This is how the WAL works, in concept."
""
"Let‚Äôs create a  that will store our current count of ingredients:"
""
"To enable our write-ahead log journaling mode, we just need to use the  PRAGMA:"
""
"Internally, this command performs a rollback journal transaction to update the database header so it‚Äôs safe to use like any other transaction. The database header has a read & write version at bytes 18 & 19, respectively, that are used to determine the journal mode. They‚Äôre set to  for rollback journal and  for write-ahead log. They‚Äôre typically both set to the same value."
""
"Now that we are using the WAL, we can add our initial inventory counts:"
""
"Instead of updating our  database file, our change is written to a  file in the same directory. Let‚Äôs fire up our  tool and see what‚Äôs going on."
""
"The WAL file starts with a 32-byte header:"
""
"Most SQLite files start with a  and the WAL is no exception. Every WAL file starts with either  or  which indicate whether checksums in the file are in little-endian or big-endian format, respectively. Nearly all modern processors are little-endian so you‚Äôll almost always see  as the first 4 bytes of a SQLite WAL file."
"Next, the  is the WAL format version. This is the big-endian integer representation of  which means it‚Äôs the WAL version created in SQLite 3.7.0. There‚Äôs currently only one version number for WAL files."
"The next four bytes, , are the page size. We‚Äôre using the default page size of 4,096 bytes. The next four after that are  which is the checkpoint sequence number. This is a number that gets incremented on each . We‚Äôll discuss checkpointing later in this post."
"After that, we have an 8-byte ‚Äúsalt‚Äù value of . The term ‚Äúsalt‚Äù is typically used in cryptography (and sandwiches, actually) but in this case it‚Äôs a little different. Sometimes the WAL needs to restart from the beginning but it doesn‚Äôt always delete the existing WAL data. Instead it just overwrites the previous WAL data."
"In order for SQLite to know which WAL pages are new and which are old, it writes the salt to the WAL header and every subsequent WAL frame. If SQLite encounters a frame whose salt doesn‚Äôt match the header‚Äôs salt, then it knows that it‚Äôs a frame from an old version of the WAL and it ignores it."
"Finally, we have an 8-byte checksum of  which is meant to verify the integrity of the WAL header and prevent partial writes. If we accidentally overwrite half the header and then the computer shuts down, we can detect that by calculating and comparing the checksum."
""
"The WAL works by appending new data to the  file so we‚Äôll see an entry for a single page in our WAL file. It starts with a 24-byte header and then writes 4,096 bytes of page data."
""
"The first 4 bytes, , are the page number for the entry. This is saying that our page data following the header is meant to overwrite page 2."
"The next 4 bytes, also , indicate the database size, in pages, after the transaction. This field actually performs double duty. For transactions that alter multiple pages, this field is only set on the last page in the transaction. Earlier pages set it to zero. This means we can delineate sections of the WAL by transaction. It also means that a transaction isn‚Äôt considered ‚Äúcommitted‚Äù until the last page is written to the WAL file."
"After that we see our salt value  copied from the header. This lets us know that it is a contiguous block of WAL entries starting from the beginning of the WAL. Finally, we have an 8-byte checksum of  which is computed based on the WAL header checksum plus the data in the WAL entry and page data."
""
"Every transaction that occurs will simply write the new version of changed pages to the end of the WAL file. This append-only approach gives us an interesting property. The state of the database can be reconstructed at any point in time simply by using the latest version of each page seen in the WAL starting from a given transaction."
"In the diagram below, we have the logical view of a b-tree inside SQLite and an associated WAL file with 3 transactions. Before the WAL file exists, we have three pages in our database, represented in black."
"The first transaction (in green) updates pages 1 and 2. A snapshot of the database after this transaction can be constructed by using WAL entries for pages 1 and 2 and the original page from the database for page 3."
"Our second transaction (in red) only updates page 2. If we want a snapshot after this transaction, we‚Äôll use page 1 from the first transaction, page 2 from the second transaction, and page 3 from the database file."
"The last transaction (in orange) updates pages 2 & 3 so the entire b-tree is now read from the WAL."
"The beauty of this approach is that we are no longer overwriting our pages so every transaction can reconstruct its original state from when it started. It also means that write transactions can occur without interfering with in-progress read transactions."
""
"You may have noticed one problem with our append-only album of ingredient photos‚Äîit keeps getting bigger. Eventually it will become too large to handle. Also, we really don‚Äôt care about the ingredient photos that we took 400 sandwiches ago. We only want to allow sandwich makers and inventory counters to do their work at the same time."
"In SQLite, we resolve this issue with the ‚Äúcheckpointing‚Äù procedure. Checkpointing is when SQLite copies the latest version of each page in the WAL back into the main database file. In our diagram below, page 1 is copied from the first transaction but pages 2 & 3 are copied from the third transaction. The prior versions of page 2 are ignored because they are not the latest."
"SQLite can perform this process incrementally when old transactions are not in use but eventually, it needs to wait until there are no active transactions if it wants to fully checkpoint and restart the WAL file."
"This naive approach can be problematic on databases that constantly have open transactions as SQLite will not force a checkpoint on its own and the WAL file can continue to grow. You can force SQLite to block new read & write transactions so it can restart the WAL by issuing a  PRAGMA:"
""
"or"
""
""
"As our photo album grows, it gets slower to find the latest version of each photo in order to reconstruct our sandwich shop state. You have to start from the beginning of the album and find the last version of a page every time you want to look up a photo."
"A better option would be to have an index in the photo album that lists all the locations of photos for each ingredient. Let‚Äôs say you have 20 photos of banana peppers. You can look up ‚Äúbanana peppers‚Äù in the index and find the location of the latest one in the album."
""
"SQLite builds a similar index and it‚Äôs stored in the ‚Äúshared memory‚Äù file, or SHM file, next to the database and WAL files."
"But SQLite‚Äôs index is a bit funny looking at first glance: it‚Äôs a list of page numbers and a hash map. The goal of the index is to tell the SQLite client the latest version of a page in the WAL up to a given position in the WAL. Since each transaction starts from a different position in the WAL, they can have different answers to exactly which version of a page they see."
"The SHM index is built out of 32KB blocks that each hold 4,096 page numbers and a hash map of 8,192 slots. When WAL entries are written, their page numbers are inserted into the SHM‚Äôs page number list in WAL order. Then a hash map position is calculated based on the page number and the index of the page number is stored in the hash map."
"Clear as mud? Let‚Äôs walk through an example."
"In the diagram above, our first transaction in the WAL (green) updates pages 1 & 2. They get written to the WAL, but the page numbers are also added to the page numbers list in the SHM file. SQLite calculates a hash map slot position for each page using the formula: . In the hash map slot, we‚Äôll write the index of the page in our page number list. This is also  & , respectively. Don‚Äôt read too much into the exact hash map positions in the diagram. There‚Äôs some loss of fidelity in simplifying 8,192 slots down to 14!"
"This hash-based mapping will generally spread out our page numbers across our hash map and leave empty space between them. Also, we are guaranteed to have a lot of empty slots in the hash map since there are double the number of hash map slots as there are page number spots. This will be useful when looking up our pages later."
"Our next transaction (red) only updates page 2. We‚Äôll write that page to the third entry in our page number list. However, when we calculate our hash map position, we have a collision with the entry for page 2 in transaction 1. They both point at the same slot. So instead of writing to that slot, we‚Äôll write our page number list index, , to the next empty slot."
"Finally, our third transaction updates pages 2 & 3. We‚Äôll write those to indexes  &  in our page number list and then write those indexes to our hash map slots. Again, our page 2 collides with updates in the first two transactions so we‚Äôll write the index to the first empty slot after the hash map position."
""
"Now that we have our index built, we can quickly look up the latest version of any given page for a transaction. Let‚Äôs say we‚Äôve started a read transaction just after transaction #2 completed. We only want to consider versions of pages in the WAL up to entry #3 since WAL entries in index 4 & 5 occurred after our read transaction started."
"If we want to look up page 2, we‚Äôll first calculate the hash position and then read all the indexes until we reach an empty slot. For page 2, this is indexes 2, 3, & 4. Since our transaction started at entry #3, we can ignore entries after index 3 so we can discard index 4. Out of this set, index 3 is the latest version so our SQLite transaction will read page 2 from WAL entry 3."
"Astute readers may notice that we can have collisions across multiple pages. What happens if page 2 & page 543 in a database compute the same slot? SQLite will double check each entry in the page numbers list to make sure it‚Äôs the actual page we‚Äôre looking for and it will discard any others automatically."
""
"While there are always trade-offs between design choices, the vast majority of applications will benefit from WAL mode. The SQLite web site  where the rollback journal would be a better choice such as when using multi-database transactions. However, those situations are rare for most applications."
"Now that you understand how data is stored and transactions are safely handled, we‚Äôll take a look at the query side of SQLite in our next post which will cover the SQLite Virtual Machine."
""
""
""
"‚ÄúRemote development environment!‚Äù"
"Whether you reacted with a thrill of enthusiasm, a surge of derision or a waft of indifference, we‚Äôre not really here to change your mind. That phrase means a lot of different things at this point in history. The meaning we pick today is ‚Äúnerd snipe.‚Äù"
"Let‚Äôs set up a remote in-browser IDE, configured for Elixir / Phoenix development, the hard way‚Äîthat is: using the command line and a Dockerfile."
""
""
"We‚Äôve leaned away from blog posts with a lot of code blocks in them. Too many code blocks make our eyes glaze over. But we really wanted to show off a fun way to play with , which are VMs that you manage directly. And a personal remote development environment is just the ticket: for individual use, we don‚Äôt need load-balancing, or lots of instances, or always-on‚Äîin fact, it‚Äôs better if we can turn it on and off."
""
"So here we are. Once we got those code blocks flowing, we didn‚Äôt stop until we‚Äôd deployed, step-by-step, not one, but two separate apps on Fly.io."
""
"If you perform the ritual to completion, you‚Äôll have deployed  to Fly.io, from your own personal Elixir / Phoenix development environment that you‚Äôve configured and deployed on Fly.io, complete with¬† IDE. You‚Äôll use the power of Machines to get the VM to go to sleep when you‚Äôre not using it, making it cheaper to run."
"The steps to get there look roughly like:"
"Configure and deploy the development environment on a Fly.io Machine:"
""
""
"As we‚Äôve mentioned, , an in-browser VS Code, is our IDE of choice for today‚Äôs exercise. It‚Äôs far from the only possibility, looking at the range of VS Code-flavoured possibilities alone (starting with zero amount of VS Code, and stopping short of fully-managed services). Say we‚Äôre connecting over SSH. A perfectly good remote dev environment, according to some people, would be tmux and Vim over SSH.  is a more comfortable option for most of us. If we can‚Äôt, or don‚Äôt want to, install VS Code on our local device,  makes it into a web app. We can ."
"We can also get code-server in the browser over an HTTPS connection (with a Let‚Äôs Encrypt certificate and a TLS-terminating proxy), and put a password in front of it. Since Fly.io will provide us the cert and proxy almost without us noticing, that‚Äôs the instant-gratification route. We‚Äôll go that way today, and skip over questions of SSH and WireGuard. If you want to talk about SSH and Fly.io remote dev setup, ."
"We‚Äôll build from a Dockerfile. Our Docker image will hold a clean-slate (but mostly-configured) development environment. If we ever get mired in dependency hell, or our SSD goes fizzle, we can deploy a fresh machine using that."
"Working files will live on a persistent storage volume. Nothing stops us checking our work into a remote Git repository regularly too."
"We want to shut it down when it‚Äôs not in use (because we don‚Äôt get charged for CPU or RAM while the Fly Machine is ). Machines can be started and stopped manually using their  or , but here we‚Äôll also run a proxy called  that shuts the server down if it doesn‚Äôt get any HTTP requests for some time. As for waking it up: Fly‚Äôs proxy itself tries to wake machines for HTTP requests (and TCP connections)."
""
"Let‚Äôs get our hands dirty, starting by walking through the three files we use to build our image. If you don‚Äôt want to type them in, you can clone :"
"If you really don‚Äôt want to bash out the commands, we do have a . It will immediately deploy the same remote dev environment we‚Äôre creating in this demo."
""
""
"To summarize that:"
"It‚Äôs a multi-stage build that gets the code for Tired Proxy from its public Docker image, and uses an official Elixir base image to save us the trouble of finding things like Elixir, Mix, etc., that every Elixir dev environment should have."
""
"Over that, it installs some other things we know we want, including code-server (our IDE), flyctl (so we can deploy apps from the code-server terminal), and the  extension for code-server (to make developing Elixir apps more comfy)."
"It copies in two other files from the local working directory:  (just to get the dark theme in VS Code) and  (a shell script which encapsulates all the things the VM should do every time it starts up). The Tired Proxy executable is copied from the first stage."
"Finally, it sets ENTRYPOINT to run ."
""
""
"Here‚Äôs what that does:"
"First, it sets the TIME_TO_SHUTDOWN environment variable to 3600 seconds (1 hour). This is used in the  command later on."
"It creates a folder for the Elixir project to live in, if one doesn‚Äôt already exist. The  tag prevents errors in the case that  already exists (as it should the second time you start the VM)."
"It initializes the environment, if that hasn‚Äôt already happened, by cloning project files from the repo indicated in the GIT_REPO environment variable (which we‚Äôll set when we run the VM), installing Hex and Rebar locally (non-interactively, with the  flag), and getting project dependencies."
"Finally, the trick we have up our sleeve: it spawns a code-server, with the  folder open, listening on port 9090‚Äîbut we don‚Äôt expose this port directly. Tired Proxy maps port 8080 to 9090, and if there‚Äôs no incoming HTTP connection for $TIME_TO_SHUTDOWN seconds, it exits. That‚Äôs it. That‚Äôs the whole trick."
""
"We provide a  just to get the dark theme in our IDE."
"If you‚Äôre a VS Code user, you can provide your own preferences in this file."
""
""
"If you‚Äôre new to Fly.io, , the Fly.io CLI tool, and run . If you already have flyctl installed, it‚Äôs worth making sure it‚Äôs up to date with ."
""
""
""
"a new machines app on Fly.io with a name and an organization. The remote IDE URL will be , so choose well."
""
""
"called , tied to this app, with size 2GB. You can choose to make it smaller. The VM will be tied to the hardware this volume is on."
""
""
"By default, Fly.io apps have private IPV6 addresses for use within their organization‚Äôs WireGuard network. If you want to access this app without a WireGuard tunnel, it needs a public IP."
"Since you‚Äôre not running  on this app, you need to ."
""
"Use  to pass in secret environment variables. Note the  flag, which is needed (at this time) because setting secrets on a machines app triggers a deploy by default, and we don‚Äôt want that in our case."
""
""
"code-server asks for a password when you first open it. It will generate its own random password on installation if the PASSWORD environment variable isn‚Äôt set. You can still ssh into the VM later and extract it from a config file, but it‚Äôs easier to set it ahead."
"Providing your  allows you to deploy other apps to Fly.io from within this app. Trippy!"
""
"Here‚Äôs the invocation to bring the code-server VM into being! Your app will be discoverable on the Internet as soon as the VM is up and listening for requests."
""
": Run a new Fly Machine VM. The first argument is the image or the path to the Dockerfile. In this case it‚Äôs the current folder (don‚Äôt miss out the )."
"The above command should result in output close to this:"
""
""
"Now we can visit your freshly-minted remote development environment at . It‚Äôll ask for the password you set earlier with . Fear not the light theme. Once  is read in, it‚Äôll switch to dark."
"Once you‚Äôre in, you‚Äôll see the  folder open, complete with the cloned  project files. README.md contains instructions for building, previewing, and deploying that app. In case you‚Äôre just following along in your imagination, we‚Äôll repeat them here."
"Open the integrated VS Code terminal with ."
"Run  to compile the app and start up the dev server. When that finishes, you can check it out in the browser at . You‚Äôll recall you exposed port 4000 when you created the machine with . This does mean everybody can see the dev server at that address, because this Phoenix app doesn‚Äôt have any password protection."
"After dutifully clicking the button to run migrations, you should see something like this:"
""
""
"In the VM‚Äôs Dockerfile, you installed flyctl, so you can run any  command from the integrated terminal. You‚Äôre authed, because you set the FLY_API_TOKEN secret, which the CLI will read from the environment if it‚Äôs available."
"It‚Äôs time for the second round of app-configuration, secret-setting, and volume-creation with flyctl, this time all for your Phoenix app."
"Register the new app, but don‚Äôt deploy it. New app, new name. Use the  provided by the project repo. Deploy it wherever you like‚Äîit‚Äôs a whole independent app."
""
""
"Generate a new secret for the Phoenix app."
""
""
"Set that as the secret SECRET_KEY_BASE that the app will have access to."
""
"This sample app is configured to use an SQLite database, so you need some storage."
"Provision a 1GB volume in the same region as the Phoenix app."
""
""
"That‚Äôs it! Deploy the Phoenix app."
"It‚Äôll go live at ."
"You can  the machine using , and revive it just by visiting the app in your browser (or with ). If you close the tab, it will just sleep after an hour without activity."
"your Code Server app if you‚Äôre done with it.  Also destroy the Phoenix app if you don‚Äôt want that!"
""
"This project was built to demonstrate our new Fly Machines feature, and how simple it can be to launch an app like code-server with it."
"The Dockerfile serves as an example of how you can customize your setup ready to do some work, and it does some heavy lifting: cloning the repo, installing flyctl, and installing an entire Elixir developer environment. It wouldn‚Äôt be hard to swap out the Elixir bits for  ones, if that‚Äôs your bag!"
"Fly machines are very keen to start themselves if someone reaches them over HTTP (thanks, fly-proxy), but they won‚Äôt stop by themselves with the code-server process running. You can reuse our Tired Proxy to send a VM to sleep, so you don‚Äôt get billed for it 24/7. One caveat: with this simple setup, if a random bot hits your port 8080, fly-proxy will treat that the same as you opening up the app in a tab‚Äîand try to wake the machine. Oh. Two caveats: Our experiments indicate that leaving a code-server tab open with the terminal pane active may keep it alive too."
""
"You can also start and stop and remove machines using  or the ; you can write a little app with ‚Äústart‚Äù and ‚Äústop‚Äù buttons for your machines if you want to play. Obviously, the idea is that you could use the Machine API to write much bigger, more interesting apps than that. We leave that as an exercise for the reader!"
""
""
"When database vendors recite their long list of features, they never enumerate ‚Äúdoesn‚Äôt lose your data‚Äù as one of those features. It‚Äôs just assumed. That‚Äôs what a database is supposed to do. However, in reality, the best database vendors ."
"I‚Äôve written before about . In order not to lose any of it when a transaction goes wrong, SQLite implements a journal. It has two different modes: the rollback journal & the write-ahead log. Today we‚Äôre diving into the rollback journal: what it is, how it works, and when to use it."
""
"To understand why you need a database journal, let‚Äôs look at what happens without one. , we talked about how SQLite is split up into 4KB chunks called ‚Äúpages‚Äù. Any time you make a change‚Äîeven a 1 byte change‚ÄîSQLite will write a full 4KB page."
"If you tried to overwrite a page in your database file directly, it would work fine 99% of the time. However, that 1% of the time is catastrophic. If your server suddenly shut down halfway through a page write then you‚Äôll end up with a corrupted database."
"The database needs to ensure that all page writes for a transaction either get written or don‚Äôt. No halfsies. This is called ."
"But that‚Äôs not all. If another process is querying the database, it‚Äôll have no consistent view of the data since you‚Äôre overwriting pages willy-nilly. The database needs to ensure each transaction has a snapshot view of the database for its entire duration. This is called ."
"Finally, we need to make sure bytes actually get flushed to disk. This part is called ."
"Those make up 3 of the 4 letters of the  that every database blog post is required to mention. The ‚ÄúC‚Äù stands for  but that doesn‚Äôt involve the rollback journal so we‚Äôll skip that."
""
"Every textbook definition of transactions involves a bank transfer where someone withdraws money from one account and deposits in another. Both actions must happen or neither must happen."
"This example gets trotted out because atomicity is so unusual in the physical world that it‚Äôs hard to find anything else that‚Äôs as intuitive to understand."
"But it turns out that atomicity doesn‚Äôt ‚Äújust happen‚Äù in databases either. It‚Äôs all smoke and mirrors. So let‚Äôs use a better example that involves our favorite topic: sandwiches."
""
"When you go to a sandwich shop, you walk up to the counter, announce your order, and you get a tasty sandwich in hand a short time after. To you, the consumer, this is atomic. If you order a ham-and-cheese sandwich, you won‚Äôt receive just a slice of ham or two pieces of dry bread. You either get a sandwich or you don‚Äôt."
"But behind the counter, there are multiple steps involved: grab the bread, add the ham, add the cheese, hand it to the customer. If the sandwich maker gets to the cheese step and realizes they‚Äôre out of cheese, they can tell you they can‚Äôt make the sandwich and then put the ham and bread back where they found it. The internal state of the sandwich shop is restored to how it was before the order started."
"The rollback journal is similar. It records the state of the database before any changes are made. If anything goes wrong before we get to the end, we can use the journal to put the database back in its previous state."
""
"Let‚Äôs start our first transaction by creating a table in a  database:"
""
"SQLite starts by creating a  file next to our  database file and :"
""
"The first 12 bytes are filled with zeros but they‚Äôll be overwritten at the end of our transaction so let‚Äôs skip them for now."
"The value  is called a nonce and it‚Äôs a randomly generated number that we‚Äôll use to compute checksums for our entries in the journal. SQLite has  where it‚Äôll overwrite the journal instead of delete it so the checksums help SQLite know when its working with contiguous set of entries and not reading old entries left behind from previous transactions."
"Next, we have  which is the size of the database before the transaction started. Since this is the first transaction, our database was empty before the transaction."
"Then we specify the sector size of  (or 512).  A disk sector is the smallest unit we typically work with for disk drives and SQLite keeps the journal header on its own sector. It does this because journal header is later rewritten and we don‚Äôt want to accidentally corrupt one of our pages if a sector write fails."
"Finally, we have  (or 4,096) which is the page size for our database, in bytes."
"SQLite can now freely write changes to the database file while knowing that it has written down the state of the database from before the transaction started."
"When you go to commit the changes, SQLite will rewrite the first 12 bytes of the journal header with two new fields:  & the number of page entries in the journal."
""
"The ‚Äúmagic number‚Äù is a ridiculous name for a constant value that is written to the beginning of a file to indicate its file type. For journal files, this magic number is . We don‚Äôt have any page entries since our database was empty so the page count stays as zeros."
"Next, we‚Äôll  to make sure we don‚Äôt lose it."
"The final step that ends the commit is when SQLite deletes the file. If any of the previous steps fail then SQLite can use the rollback journal to revert the state of the database. Just like with your ham-and-cheese, the transaction doesn‚Äôt happen until you have a sandwich in your hand."
""
"Now let‚Äôs see how the journal works with an existing database. Our first transaction left us with a 2-page database. The first page holds our database header and some metadata about our schema. The second page is an empty leaf page for our  table."
"We‚Äôll insert our sandwich into our table:"
""
"This will create a new journal with the following header:"
""
"It looks similar to before but we have a new randomly-generated nonce () and our database size before the transaction is now  pages instead of zero."
"Since our transaction is updating the leaf page, SQLite needs to copy out the original version of the page to the journal as a page record. The journal page records are comprised of 3 fields."
"First, we have the page number to indicate that we‚Äôre updating page 2:"
""
"Then it‚Äôs followed by a copy of the 4,096 bytes that were in the page before the transaction started. Finally, it computes a 32-bit checksum on the data in the page:"
""
"Interestingly, the checksum is only calculated on a very sparse number of bytes in the page and is primarily meant to guard against incomplete writes. Since SQLite 3.0.0 dates back to 2004 and it works on minimal hardware, reducing any overhead can be critical. You can see the evolution of computing power as the WAL mode, which was introduced in 2010, checksums the entire page."
"With our original copy of the page in the journal, we can update our copy in the main database file without having to re-copy the page. We can add a second sandwich to our transaction and SQLite will only update the main database file:"
""
"The database and journal end up looking like this:"
""
"Back to our sandwich shop example, let‚Äôs say there is a catastrophic sandwich event that occurs in the middle of your order. Perhaps your sandwich artist couldn‚Äôt stand to make one more ham-and-cheese sandwich and abruptly quit."
"So our shop owner subs out a new employee to replace the old one so the sandwich production can continue. But how do we deal with the in-process sandwich? The new employee could try to finish the sandwich but maybe the customer gave specific instructions to the old employee. When you‚Äôre dealing with something as critical as lunch, it‚Äôs best to start over and do it right."
"When SQLite encounters a failure scenario, such as an application dying or a server losing power, it needs to go through a process called ‚Äú‚Äù. For a rollback journal, this is simple. We can walk through our journal page records and copy each page back into the main database file. At the end, we truncate our main database file to the size specified in the journal header."
"Rollback journals are even resistant to failures during their own recovery. If your server crashes midway through a recovery process, SQLite will simply start the recovery process from the beginning of the journal file."
"The procedure is idempotent and is not considered complete until the pages copied back are synced to disk and the journal file is deleted. For example, let‚Äôs say we‚Äôd only copied half of page 2 in our diagram from the journal back to the database file and then our server crashed. When we restart, we still have our journal file in place and we can simply try copying that page again."
""
"Our sandwich shop owner begins to suspect that employees are skimming pickles off the line and decides to hire folks to inventory ingredients periodically. However, the owner quickly realizes that the inventory numbers are off because the inventory specialists are trying to count ingredients while sandwich makers are taking those same ingredients to put into sandwiches."
"To fix this, the owner decides that the store must be locked while a sandwich is being made. However, when a sandwich isn‚Äôt being made, any number of inventory specialists can come in and count ingredients."
"This is how it works in SQLite when using the rollback journal. Any number of read-only transactions can occur at the same time. However, when we start a write transaction then we need to wait for the readers to finish and block all new readers until the write is done."
"This makes sense now that you know that we‚Äôre changing the main database file during a write transaction. We‚Äôd have no way to give read transactions a snapshot view of the database if we‚Äôre updating the same underlying data."
""
"Since SQLite allows multiple processes to access it, it needs to perform locking at the file system level. There are 3 lock bytes that are used to implement the read/write lock at the file system level:"
"- held by read transactions, prevents writers from starting"
"When a read transaction starts, it checks the  lock first to ensure a writer is not inside a write transaction or that a writer is not waiting to start a transaction. If the reader can obtain the  lock then it obtains a shared lock on the  lock byte and holds it until the end of the transaction."
"For write transactions, it first obtains an exclusive lock on the  lock byte to prevent new read transactions from starting. It then tries to obtain an exclusive lock on the  lock byte to wait for in-process read transactions to finish. Finally, it obtains an exclusive lock on the  lock byte to indicate that a write transaction is in-process."
"This series of steps ensure that only one write transaction is in effect at any time and that new readers won‚Äôt block it."
"Locks are located on a page at the 1GB position in the database file and this page is unusable by SQLite as  instead of advisory locks. If a database is smaller than 1GB, this page is never allocated and only exists within the operating system‚Äôs lock accounting system."
"Within the lock page, a byte is used for the  lock and another byte for the  lock. After that, 510 bytes are used for the  lock. A byte range is used here to accommodate older Windows versions with mandatory locks. In those cases, a randomly chosen byte is locked by a client within that range. On Unix, the entire range is locked using  and ."
""
"The rollback journal is a simple trick to simulate atomicity and isolation and to provide durability to a database. Simple tricks are the best kind of tricks when you write a database so it‚Äôs a great place to start."
"But it certainly has its trade-offs. Kicking out all other transactions whenever you need to write something can become a bottleneck for many applications that have concurrent users. When people say that SQLite doesn‚Äôt scale, it‚Äôs typically because they used the rollback journal."
"However, SQLite continued to improve and eventually introduced the write-ahead log (WAL) journaling mode and even the  journaling mode. These provide significantly better support for concurrent readers."
"This means that our inventory specialists in our example could each have a point-in-time view of all the ingredients‚Äîeven while the sandwich maker continues to make sandwiches! We‚Äôll get into how this works in our next post on WAL mode."
""
""
""
"Fly Volumes are the persistent storage that makes it possible to run full stack apps entirely on the Fly.io platform, keeping your configuration, session or user data in place across deployments. Looking at them from another angle, volumes are space on NVMe drives on our servers that you can rent for your apps to use."
"We‚Äôve recently made two major improvements to volumes: extending volume size, and self-service snapshot restores."
""
"Until recently, if you needed your volume to be bigger, you‚Äôd have to provision a new empty one and copy your data to it. This is not ideal, to put it mildly."
"But you can now extend a volume on the CLI with ."
"The app instance attached to the volume does have to restart to allow the file system to be resized. This will happen automatically for ‚Äúregular‚Äù apps, but  will have to be restarted manually."
"More details in  and in the ."
"Ideally, we‚Äôd be able to alert you when you hit a usage threshold on a storage volume, or even better, give you the option to increase your volume size automatically when you hit a threshold. We‚Äôre not there yet!"
""
"It‚Äôs been possible for some time to restore a Fly.io  database from a snapshot, but if you were using another database, you had to ask us to dig up and restore a snapshot for you."
"But now you can restore regular volumes: as of , individual volume restores can now be performed by specifying¬† at creation time."
"Which means you can get back  by yourself (is there something other than sandwiches that you might store in an app‚Äôs database?), at your own convenience."
"Volume snapshots are taken daily (but not at the same time every day), and shunted off to object storage where they live for five days before they expire."
"If you need to restore from a snapshot, you identify the volume you want, list its snapshots, get the ID of the one you want from the list, and create a new volume by pointing  at that ID."
"You can restore to a bigger volume, if you like, but not a smaller one than the snapshot came from."
""
""
""
""
"Ok, I‚Äôll admit it‚ÄîI‚Äôm a SQLite shill. There are few holes that I don‚Äôt try to put a SQLite-shaped peg into. It‚Äôs not that I dislike other databases, they‚Äôre great. But SQLite is so easy to use and, more importantly, it‚Äôs simple. Simplicity leads to reliability and I don‚Äôt know of a more reliable database than SQLite."
"There‚Äôs a comfort with being able to read through a spec or a code repository and know that you‚Äôve covered the full breadth of a tool. That‚Äôs why I love  and that‚Äôs why I love SQLite‚Äôs 130KLOC core code base. It‚Äôs something that you can read through in a long weekend if, ya know, that‚Äôs what you do on weekends."
"This constrained size means that SQLite doesn‚Äôt include every bell and whistle. It‚Äôs careful to include the 95% of what you need in a database‚Äîstrong SQL support, transactions, windowing functions, CTEs, etc‚Äîwithout cluttering the source with more esoteric features. This limited feature set also means the structure of the database can stay simple and makes it easy for anyone to understand."
"We here at Fly.io have an unreasonable affinity for explanations involving sandwiches and this post will continue in that sacred tradition."
""
"Recently, I tried to remember a sandwich I ate last week but to no avail. Like any 10x engineer, I quickly over-engineered a solution by making a SQLite database to track every sandwich consumed."
"We‚Äôll start off with our table definition:"
""
"Now we‚Äôll have a record of every sandwich, its size in inches, and the number eaten."
"I live in Denver where we were known in the early 2000s for , and then in the 2010s for  so we‚Äôll kick off with a toasted Italian sub."
""
"Voila! Our data is safe on disk. It‚Äôs easy to gloss over all the steps it takes to get from hitting the ‚Äúenter‚Äù key to bytes getting saved to disk. SQLite virtually guarantees that your database will never be corrupted or that your transaction will be half-written. But instead of glossing over, let‚Äôs dive in deep and see how our Italian sub looks on disk."
""
"Our row of sandwich data exists as an array of bytes inside SQLite that‚Äôs encoded using its . For our inserted row, we see the following bytes on disk:"
""
"Let‚Äôs break these bytes down to see what‚Äôs going on."
""
"The first byte of  is the size of our row‚Äôs payload, in bytes. After this is our rowid which is used as our . Since this is the first row, its  has a value of ."
"These first two fields use what‚Äôs called a variable-length integer (‚Äúvarint‚Äù) encoding. This encoding is used so that we don‚Äôt use a huge 8-byte field for every integer and waste a bunch of space. It‚Äôd be like if a sandwich shop packaged every sandwich in enormous 6-foot party sub containers because they only could use one size of container. That‚Äôd make no sense! Instead, each size of sandwich gets its own container size."
"Varints use a simple trick. The high bit is used as a flag to indicate if there are more bytes to be read and the other 7 bits are our actual data. So if we wanted to represent 1,000, we start with its binary representation split into 7 bit chunks:"
""
"Then we add a ‚Äú1‚Äù flag bit to the beginning of the first chunk to indicate we have more chunks, and a ‚Äú0‚Äù flag bit to the beginning of the second chunk to indicate we don‚Äôt have any  more chunks:"
""
"With varints, we can now store our integer in 2 bytes instead of 8. This may seem small but many SQLite databases have a lot of integers so it‚Äôs a huge win!"
"The next two bytes after the rowid specify the data that is not spilled to overflow pages but  so we‚Äôre gonna wave our hands over that part."
""
"Next, we have a list of column types for our , , and  fields. Each data type has a different encoding that‚Äôs specified as a varint."
"For our name column, the  value specifies that it is a  type and has a length of 7 bytes. Type values that are odd and are greater or equal to 13 are  fields and can be calculated with the formula . So our 7-byte string is  which is 27, or  in hex."
"fields are similar except they‚Äôre even numbers calculated as . SQLite alternates these  and  type values so small lengths of both types can be encoded efficiently as varints."
"Next, we have our ‚Äúlength‚Äù field which is a floating-point number. These are always encoded as a ."
"After that, we have our ‚Äúcount‚Äù field which is an integer. These get packed down similar to  but in a slightly different format. Integers that can fit in an 8-bit integer are represented with a type value of . 16-bit integers are , 24-bit integers are  and so on."
""
"Once our types are all encoded, we just need to pack our data in. The text value of  is represented as UTF-8:"
""
"Then our length of  is represented as an . SQLite can optimize integer floating-point values by storing them as pure integer fields but since we have a decimal place it is stored with 8-bytes:"
""
"And finally we use a single byte to hold our count of 2:"
""
"Congrats! You‚Äôre now an expert on SQLite record formatting."
""
"As my sandwich addiction continues unabated, I fill my SQLite database with more and more rows. I even make friends on the  subreddit and start collecting their sandwiches. My sandwich database seems to grow without bound."
"Surprisingly though, adding or updating rows is still nearly as instantaneous as when I had a single row. So how does SQLite update a multi-gigabyte sandwich database in a fraction of a second? The answer is pages & b-trees."
"A naive approach to a database would just be to pack records in sequentially in a file. However, there‚Äôs no way to insert or update rows in the middle of the file without shifting and rewriting all the bytes after the new row."
"Instead, SQLite groups rows together into 4KB chunks called ‚Äúpages‚Äù. Why 4KB? That‚Äôs what file systems typically use as their page size so keeping everything aligned reduces page fetches from disk. Disks are usually the slowest part of a database so limiting page fetches can have a huge performance win."
""
"If we inspect our page, we can see its header:"
""
"There are several parts of this header but I masked out several bytes so we can focus on two particularly important fields. The first byte, , indicates the . This page type is a . We‚Äôll talk about those more with b-trees."
"The second important field is the , which is . This tells us that 3 records exist in this page."
"After the header, we have the :"
""
"This is a list of 2-byte values that represent offsets in the page for each record. The first record exists at offset 4,073 (), the second record exists at offset 4,050 (), etc. SQLite packs rows at the end of the page and then works backwards."
"After the index, we have a bunch of zeros until we reach the content area of the page which holds our row data in record format."
""
"Now that we‚Äôve chunked our data into pages, we can update a subset of our data without having to rewrite the whole file. That‚Äôs great for writing but now we have a list of pages to search through if we want to query our data and that won‚Äôt scale as-is."
"The simplest approach would be to start at the first page and then search every page for a given row. This is called a ‚Äútable scan‚Äù and it can be really slow‚Äîespecially if your data is at the end of your table. If you‚Äôre into , it‚Äôs also referred to as ‚Äúlinear time complexity‚Äù, or . That means the amount of time it takes to search for a record has a linear relationship to the number of records you have, which is referred to as ‚Äú‚Äù."
""
"If you are searching by your primary key, you could perform a binary search since the table is sorted by primary key. For a binary search, you search the page right in the middle of your table for your sandwich record. If the record exists, great! You‚Äôre done."
"If the sandwich you‚Äôre searching for is before that page, then you find a new ‚Äúmiddle‚Äù page in the first half of your table. If it‚Äôs after the page, then you find a new middle page in the second half of your table. Keep slicing the search space in half and searching until you find your sandwich. If you squint a bit, this slicing and subdividing has the feel of a tree-like structure."
"A binary search has a logarithmic time complexity, or . That‚Äôs considered pretty good for data structures since it means you can scale up to a large number of records, , while the cost grows at a much slower rate."
""
"While logarithmic time complexity is great, we still have a problem. Let‚Äôs run some numbers."
"If we have a small 2MB database with 4KB pages then that means we have 512 pages. A binary search of that many pages would have a worst-case scenario of , or 9 pages. That means we might have to read nine pages in our tiny database just to find one record! Page fetches are painfully slow in databases so we want to reduce that as much as possible."
"SQLite is structured as a b-tree, which is a data structure where each node can point to two or more child nodes and the values in these child nodes are all sorted. There are a ton of different variants of b-trees but the one that SQLite uses is called a b+tree. This type of tree stores all data in the leaf nodes, which is what our sorted list of pages represents, but also have an index of key ranges in the branch pages. SQLite refers to these branch pages as ‚Äúinterior pages‚Äù."
"To illustrate this, let‚Äôs say our leaf pages hold sandwich records that are each 40 bytes. The record also contains an integer primary key that is 4 bytes on average. That means we can fit about 100 records into one 4KB page. If we have less than 100 records, we only need one page. Easy peasy."
"But what happens when we add a 101st sandwich and it doesn‚Äôt fit anymore? SQLite will split the page into two leaf pages and add an interior page as the root of our b+tree that points to our child leaf pages. This interior page stores the key ranges for the leaf pages so that when you search, you can see what ranges each child page holds without having to actually read that child page."
"This doesn‚Äôt seem like a big improvement over our binary search until we start adding more data. Interior pages are also 4KB and they store pairs of child primary keys and their page numbers so each entry in our interior page takes about 8 bytes. That means we can store about 500 entries in an interior page. For our 2MB database, that means we can hold the key range for all of our leaf pages in a single interior page. To find a given record, we only need to search the root interior page to find the correct leaf page. That means our worst case search is only 2 pages."
""
"What happens when our root interior page fills up and we need a database bigger than 2MB? Similar to leaf pages, we split the interior page in two and add a new root parent interior page that points to the split interior pages. This means that we need to search the new root interior page to find the correct second-level interior page and then we search page that to find our leaf page. We now have a tree depth of 3."
"Since our new root can hold about 500 references to second-level interior pages and those second-level pages hold about 500 references to leaf pages, we can store about 250,000 pages, or about 1GB of data. If we continue adding rows, we‚Äôll need to split the root page again and increase our tree depth to 4."
"At a tree depth of 4, we can hold about 500¬≥ leaf pages, or about a 476GB database. That means we only need to read 4 pages to find a given record‚Äîeven in a huge database!"
""
"While it‚Äôs interesting to noodle around with internals, how does this actually apply to real-world scenarios?"
"Well, knowing about record formatting tells us that storing integers instead of floating-point numbers is wildly more efficient as SQLite doesn‚Äôt compress floats."
"Or perhaps knowing that b-tree time cost grows logarithmically will let you feel more comfortable designing an application with a multi-gigabyte table."
"Or maybe, just maybe, discovering the  subreddit will inspire your dinner tonight."
"Learning about the internals of our tools lets us feel comfortable with them and use them confidently. Hopefully low-level features like SQLite‚Äôs  seem a little less opaque now."
"I‚Äôll be writing more on SQLite internals in future posts‚Äîfrom rollback journals to write-ahead logs to the SQLite virtual machine. Want to know more about a specific topic? Hit me up on the  or ."
""
""
""
"Today we‚Äôre launching  - our new home for anything Laravel."
"We‚Äôre excited to support deploying Laravel across the globe - and we have lots to talk about!"
"We‚Äôve already made it  on Fly, but with the possibilities unlocked by global deployment, there‚Äôs still plenty more to consider. In future posts, we‚Äôll talk about the considerations that come with a global user base."
"Finally, we‚Äôll have lots of tips, tricks, strategies, how-to‚Äôs, and more (especially about  - we love real-time apps)!"
"Keep a lookout for new stuff in Laravel Bytes!"
""
"Laravel is supported in the  command, so the easiest way to get a feel for running Laravel is in our docs for ."
"The quickest version of that boils down to this (assuming the ):"
""
"For something a bit more in depth, we‚Äôve also written up a more complete  with Redis, MySQL, queues workers, and cron tasks."
""
""
""
""
"LiveView started with a simple itch. I wanted to write dynamic server-rendered applications without writing JavaScript. Think realtime validations on forms, or updating the quantity in a shopping cart. The server would do the work, with the client relegated to a dumb terminal. It did feel like a heavy approach, in terms of resources and tradeoffs. Existing tools couldn‚Äôt do it‚Äîbut I was sure that this kind of application was at least possible. So I plowed ahead."
"Three years later, what‚Äôs fallen out of following this programming model often feels like cheating. ‚ÄúThis can‚Äôt possibly be working!‚Äù. But it does. Everything is super fast. Payloads are tiny. Latency is best-in-class. You write less code. More than that: there‚Äôs simply less to think about when writing features."
"This blows my mind! It would be fun to say I‚Äôd envisioned ahead of time that it would work out like this. Or maybe it would be boring and pompous. Anyway, that‚Äôs not how it happened."
"To understand how we arrived where we are, we‚Äôll break down the ideas in the same way we evolved LiveView to what it is today: we‚Äôll start with a humble example, then we‚Äôll establish the primitives LiveView needed to solve it. Then we‚Äôll see how, almost by accident, we unlocked a particularly powerful paradigm for building dynamic applications. Let‚Äôs go."
""
"We‚Äôll start small. Say you want to build an e-commerce app where you can update the quantity of an item like a ticket reservation. Ignoring business logic, the actual mechanics of the problem involve updating the value on a web page when a user clicks a thing. A counter."
"This shouldn‚Äôt be difficult. But we‚Äôre used to navigating labyrinths of decisions, configuring build tools, and assembling nuts and bolts, to introduce even the simplest business logic. We go to build to a counter, and first we must invent the universe. Does it have to be this way?"
"Conceptually, what we really want is something like what we do in client-side libraries like React: render some dynamic values within a template string, and the UI updates with those changed values. But instead of a bit of UI running on the client, what if we ran it on the server? The live view might look like this:"
""
"We can render a template and assign some initial state when the live view mounts."
"Next, our interface to handle UI interactions could look something like traditional reactive client frameworks. Your code has some state, a handler changes some state, and the template gets re-rendered. It might look like this:"
""
"UI components are necessarily stateful creatures, so we know we‚Äôll need a stateful WebSocket connection with  which can delegate to our  and  callbacks on the server."
"We want to be able to update our UI when something is clicked, so we wire up a click listener on  attributes. The  binding will act like an RPC from client to server. On click we can send a WebSocket message to the server and update the UI with an  that we get as a response. Likewise, if the server wants to send an update to us, we can simply listen for it and replace the inner HTML in the same fashion. The first pass would look like this on the client:"
""
"This is where LiveView started‚Äîgo to the server for interactions, re-render the entire template on state change, send the entire thing down to the client, and replace the UI."
"It works, but it‚Äôs not great."
"There‚Äôs a lot of redundant work done on the server for partial state changes, and the network is saturated with large payloads to only update a number somewhere on a page."
"Still, we have our basic programming model in place. It only takes annotating the DOM with  and a few lines of server code to dynamically update the page. Excited, we ignore the shortcomings of our plumbing and press on to try out what we‚Äôre really excited about ‚Äì¬†realtime applications."
""
"Phoenix PubSub is distributed out of the box.  We can have our LiveView processes subscribe to events and react to platform changes regardless of what server broadcasted the event. In our case, we want to level up our humble reservation counter by having the count update as other users claim tickets."
"We get to work and crack open our  module:"
""
"We add a subscription interface to our reservation system, then we modify our business logic to broadcast a message when reservations occur. Next, we can listen for events in our LiveView:"
""
"First, we subscribe to the reservation system when our LiveView mounts, then we receive the event in a regular Elixir  callback. To update the UI, we simply update our state as usual."
"Here‚Äôs what‚Äôs neat ‚Äì now whenever someone  clicks reserve,  have their LiveView re-render and send the update down the wire. It cost us 10 lines of code."
"We test it out side-by-side in two browser tabs. It works! We start doubting the scalability of our naive approach, but we marvel at what we ."
""
""
"To make the reservation count update on all browsers, we only wrote a handful of lines of server code. We didn‚Äôt even touch the client. The existing LiveView primitives of a dumb bidirectional pipe pushing RPC and HTML were all we needed to support cluster-wide UI updates."
"Think about that."
"There was no library or user-land JavaScript to add. Our reservation LiveView didn‚Äôt even consider how the data makes it to the client. Our client code didn‚Äôt have to become aware of out-of-band server updates because we already send everything over WebSockets."
"And a revelation hits us. HTTP completely fell away from our thoughts while we implemented our reservation system. There were no routes to define for updates, or controllers to create. No serializers to define for payload contracts. New features are now keystrokes away from realization."
"Unfortunately, this comes at the cost of server resources, network bandwidth, and latency. Broadcasting updates means an arbitrary number of processes are going to recompute an entire template to effectively push an integer value change to the client. Likewise, the entire templates string goes down the pipe to change a tiny part of the page."
"We know there‚Äôs something special here, but we need to optimize the server and network."
""
"Optimizing the server to compute minimal diffs is some of the most complex bits of the LiveView codebase, but conceptually it‚Äôs quite simple. Our optimizations have two goals. First, we only want to execute those dynamic parts of a template that actually changed from the previous render. Second, we only want to send the minimal data necessary to update the client."
"We can achieve this in a remarkably simple way. Rather than doing some advanced virtual DOM on the server, we simplify the problem. An Elixir HTML template is nothing more than a bunch of HTML tags and attributes, with Elixir expressions mixed in the places we want dynamic data."
"Looking at it from that direction, we can optimize simply by splitting the template into static and dynamic parts. Considering the following LiveView template:"
""
"At compile time, we can compile the template into a datastructure like this:"
""
"We split the template into static and dynamic parts. We know the static parts never change, so they are split between the dynamic elixir expressions. For each expression, we compile the variable access and execution with change tracking. Since we have a stateful system, we can check the previous template values with the new, and only execute the template expression if the value has changed."
"Instead of sending the entire thing down on every change, we can send the client all the static and dynamic parts on , then only send the partial diff of dynamic segments for each update."
"We can do this by sending the following payload to the client on mount:"
""
"The client receives a simple map of static values in the  key, and dynamic values keyed by the index of their location in the template. For the client to produce a full template string, it simply zips the static list with the dynamic segments, for example:"
""
"With the client holding the initial payload of static and dynamic values, optimizing the network on update becomes easy. The server now knows which dynamic keys have changed, so when a state change occurs, it renders the template, which lazily executes only the changed dynamic segments. On return, we receive a map of new dynamic values keyed by their position in the template. We then pass this payload to the client."
"For example, if the LiveView performed , the following diff would fall out of the  call and be sent down the wire:"
""
"Thats it! And to turn this little payload back into an updated UI for the client, we only need to merge this object with our static dynamic cache:"
""
"Then we zip the merged data together and now our new HTML can be applied like before via an  update."
"Replacing the DOM container‚Äôs innerHTML works, but wiping out the entire UI on every little change is slow and problematic. To optimize the client, we can pull in , a DOM diffing library that can take two DOM trees, and produce the minimal amount of operations to make the source tree look like the target tree. In our case, this is all we need to close the client/server optimization loop."
"We build a few prototypes and realize we‚Äôve created something really special. Somehow our naive heavy templates are more nimble than those React and GraphQL apps we used to sling. But How?"
""
"One of the most mind blowing moments that fell out of the optimizations was seeing how naive template code somehow produced payloads smaller than the best hand rolled JSON apis and even sent less data than our old GraphQL apps."
"One of the neat things about GraphQL is the client can ask the server for only the data it wants. Put simply, the client can ask for a user‚Äôs username and birthday, and it won‚Äôt be sent any other keys of the canonical user model. This is super powerful, but it must be specified on the server via typed schemas to work."
"How then, does our LiveView produce nearly keyless payloads with no real typed information?"
"The answer is it was mostly by accident. Going back to our static/dynamic representation in the  struct, our only goal initially was thinking about how to represent a template in a way that allowed us to avoid sending all the markup and HTML bits that don‚Äôt change. We weren‚Äôt thinking about solving the problem of client/server payload contracts at all."
"There‚Äôs a lesson here that I still haven‚Äôt fully unpacked. In the same way as a user of LiveView I stopped concerning myself with HTTP client/server contracts, as an  of LiveView, I also had moved on from thinking about payload contracts. Yet somehow this dumb bidirectional pipe that sends RPC‚Äôs and diffs of HTML now allows users to achieve best in class payloads without actually spec'ing those payloads. This still tickles my mind."
"One of the other really interesting parts of the LiveView journey is how the programming model never changed beyond our initial naive first-pass. The code we actually wanted to write in the beginning never needed to change to enable all these powerful optimizations and code savings. We simply took that naive first-pass and kept chipping away to make it better. This lead to other happy accidents."
""
"As we built apps, we‚Äôd examine payloads and find areas where more data would be sent than we‚Äôd like. We‚Äôd optimize that. Rinse and repeat. For example, we realized the client often receives the same shared fragments of static data for different parts of the page. We optimized by sending static shared fragments and components only a single time."
"Imagine our surprise on the other side of finishing these optimizations when we realized we solved a few problems that all client-side frameworks must face, without the intention of doing so."
"Build tools and client side frameworks have  features where developers can manage how their various JavaScript payloads are loaded by the client. This is useful because bundle size is ever increasing as more templates and features are added. For example, if you have templates and associated logic for a subset of users, your bundle will include all supporting code even for users who never need it. Code splitting is a solution for this, but it comes at the cost of complexity:"
"Developers now have to consider where to split their bundles"
"With our optimizations, lazy-loading of templates comes free for free, and the client never gets a live component template it already has seen from the server. No bundling required, or build tools to configure."
"Here‚Äôs how it works. Imagine we want to update our reservation system to render a list of available events that can be reserved. It might look something like this:"
"Which we could render with a reusable  component:"
""
"We modified our initial reserve template to render a reservation button from a list of events. When LiveView performs its diffing, it recognizes the use of the shared statics and the following diff is sent down wire:"
"Note the  key inside the diff. It contains a map of shared static template values that are referenced later for each dynamic item. When LiveView sees a static () reference an integer, it knows that it points to a shared template value. LiveView also expands on this concept when using a live component, where static template values are cached on the client, and the template is never resent because the server knows which templates the client has or hasn‚Äôt seen."
"Even with our humble reservation counter, there are other bundling concerns we skipped without noticing. Our template used localization function calls, such as . We localized our app  For a dynamic app, you‚Äôd usually have to serialize  a bag of localization data, provide some way to fetch it, and code split languages into different bundles."
"As your LiveView application grows, you don‚Äôt concern yourself with bundle size because there is no growing bundle size. The client gets only the data it needs, when it needs it. We arrived here without every thinking about the problem of client bundles or carefully splitting assets because LiveView applications hardly have client assets."
""
"The best code is the code you don‚Äôt have to write. In an effort to make a counter on a webpage driven by the server, we accidentally arrived at a programming model that sidesteps HTTP. We now have friction-free dynamic feature development with push updates from the server. Our apps have lower latency than those client apps we used to write. Our payloads are more compact than those GraphQL schemas we carefully constructed."
"LiveView is, at its root, just a way to generate all the HTML you need on the server, so you can write apps without touching JS. More dynamic apps than you might expect, thanks to Elixir‚Äôs concurrency model. But even though I wrote the internals of it, I‚Äôm still constantly blown away by how well things came together, and finding surprising new ways to apply it to application problems."
"All this from a hack that started with 10 lines of JavaScript pushing HTML chunks down the wire."
""
""
""
"We have some real gems in this edition. Have you ever wished you could grow the storage volume on a Fly.io app? Now you can!!"
"What about this one: Ever wished that the $99  would include $99 of usage credits? OK, that one may have been a little bit specific. Conversely, have you ever wished that $99+ of monthly resource usage would come with support by email? Now it can!"
"I don‚Äôt want to write spoilers for everything, so read on."
"The changelog‚Äôs broken up into sections this time around, largely to corral the ongoing torrent of  improvements. Keep your flyctl up to date to take advantage. If you‚Äôre playing (or working) with our new fast-booting  and flyctl, be sure to scan these changes! As always, if you‚Äôre interested in digging deeper into flyctl changes, dive into the ."
""
"changelog The  now includes usage credits equivalent to its price: $99. ."
""
"(=) with  now formats and colorizes JSON requests and responses for readability."
""
"now supports machine-based apps by adding  to .  also works for them, and new machine apps may be launched with . More details about this coming soon, along with docs on the new config format."
""
"Added a volume size column to the volumes list on the dashboard app page (and formatted the date properly)."
"Changed the font in the image details section (in the  app overview tab) to monospace to make it nicer to read."
""
""
""
"If you‚Äôre off getting your app up and running on  and finding your checkbook, great! I won‚Äôt get in your way. The rest of you, though, I want to talk to you about what SOC2 is and how it works."
""
"SOC2 is the best-known infosec certification, and the only one routinely demanded by customers. I have , which you will soon share. But also, a few years ago, I wrote a  about what startups need to do to gear up for SOC2. Having now project-managed ‚Äôs SOC2, I‚Äôd like to true that post up, since I‚Äôm officially a leading authority on the process."
"SOC2 is worth talking about. It‚Äôs arcane in its particulars. Startups that would benefit from SOC2 are held back by the belief that it‚Äôs difficult and expensive to obtain. Consumers, meanwhile, split down the middle between cynics who‚Äôre certain it‚Äôs worthless and true-believers who think it sets the standard for how security should work."
"Everybody would be better off if they stopped believing what they believe about SOC2, and started believing what I believe about SOC2."
""
"Bottom-line: SOC2 is a weak positive indicator of security maturity, in the same ballpark of significance as a penetration test report (but less significant than multiple pentest reports)."
"SOC2 is an accounting-style, or ‚Äúreal‚Äù, audit. That means it confirms on-paper claims companies make about their security processes. They‚Äôre nothing at all like ‚Äúsecurity audits‚Äù or ‚Äúpenetration tests‚Äù, which are heavily adversarial, engineering-driven, and involve giving third parties free rein to find interesting problems."
"I‚Äôm underselling SOC2. It assures some things pentests don‚Äôt:"
"consistent policies for who in the company gets access to what"
"Depending on the kind of company you‚Äôre looking at, a SOC2 certification might be more or less meaningful. Intensely technical company? High-risk engineering? Look for the pentest. Huge number of employees? Get the SOC2 report."
"So: if you‚Äôre clicking on SOC2 blog posts because you‚Äôre wondering how seriously you should take SOC2, there‚Äôs your answer. Go in peace."
"The rest of you, buckle up."
""
""
"There‚Äôs a structure to the things you claim in SOC2, the AICPA‚Äôs ‚Äú‚Äù and something called ‚Äú‚Äù. These are broken down into categories: security, availability, transaction integrity, confidentiality, and privacy. ‚ÄúSecurity‚Äù is mandatory, and is the only one that matters for most companies."
""
"The ground truth of SOC2 is something called the DRL, which is a giant spreadsheet  that your auditor customizes to your company after a scoping call. You can try to reason back every line item on the DRL to first accounting principles, but that‚Äôd be approximately as productive as trying to reason about contract law from first principles after paying a lawyer to review an agreement.¬†Just take their word for it."
"With me so far? SOC2. It‚Äôs a big spreadsheet an accounting firm gives you to fill out."
""
"We waited as long as we felt we could."
"Careful, now. ‚ÄúGetting SOC2-certified‚Äù isn‚Äôt the same as ‚Äúdoing the engineering work to get SOC2-certified‚Äù. Do the engineering now. As early as you can. The work, and particularly its up-front costs, scale with the size of your team."
"The audit itself though doesn‚Äôt matter, except to answer the customer request ‚Äúcan I have your SOC2 report?‚Äù"
"So, ‚Äúwhen should I SOC2?‚Äù  is easy to answer.  Do it when it‚Äôs more economical to suck it up and get the certification than it is to individually hand-hold customer prospects through your security process."
"There‚Äôs a reason customers ask for SOC2 reports: it‚Äôs viral, like the GPL. The DRL strongly suggests you have a policy to ‚Äúcollect SOC2 reports from all your vendors‚Äù. Some SOC2 product vendors offer automated  for companies to fill out, and they ask for SOC2 reports as well. Your customers ask because they themselves are SOC2, and the AICPA wants them to force you to join the coven."
"That doesn‚Äôt mean you have to actually do it. If you can speak confidently about your security practice, you can probably get through anybody‚Äôs VendorSec process without a SOC2 report. Or you can pay an audit firm to make that problem go away."
"It makes very little sense to get SOC2-certified before your customers demand it. You can get a long way without certification. If it helps, remember that you can probably make a big purchase order from that Fortune 500 customer contingent on getting your Type I in the next year."
""
"We started preparing for SOC2 more than a year before engaging an auditor, following the playbook from . That worked, and I‚Äôm glad we did it that way. But to keep this simpler to read, I‚Äôm just going to write out all the steps we took as if they happened all at once."
": Every newly-minted CSO I‚Äôve ever asked has told me that SSO was one of the first 3 things they got worked out when they took the position. Put compliance aside, and it‚Äôs just obvious why you want a single place to control credentials (forcing phishing-proof MFA, for instance), access to applications, and offboarding. We moved everything we could to our Google SSO."
"Inside our network, we also use a certificate-based SSH access control system (I‚Äôll stop being coy, ). To reach Teleport, you need to be ; to get to , you need Google SSO. Teleport, however, is authenticated separately, via Github‚Äôs SSO. So, for SSH, we have two authentication sources of truth, both of which need to work to grant access."
""
"There is, infamously, an ‚Äú‚Äù that companies pay to get access to the kinds of SAAS accounts that support SAML or OIDC. I have . It‚Äôs definitely a pain in our asses. If it‚Äôs early days for your company, for SAAS vendors that don‚Äôt deal in sensitive information, you can skip the SSO and just restrict who you give access to for the app. But mostly, you should just suck it up and pay for the account that does SSO."
": I was surprised by how important this was to our auditors. If they had one clearly articulable concern about what might go wrong with our dev process, it was that some developer on our team might ‚Äúgo rogue‚Äù and install malware in our hypervisor build."
"It‚Äôs easy to enable protected branches in Github. But all that does is make it hard for people to push commits directly to , which people shouldn‚Äôt be doing anyways. To get the merit badge, we also had to document an approval process that ensured changes that hit production were reviewed by another developer."
"This isn‚Äôt something we were doing prior to SOC2. We have components that are effectively teams-of-one; getting reviews prior to merging changes for those components would be a drag. But our auditors cared a lot about unsupervised PRs hitting production."
"We asked peers who had done their own SOC2 and stole their answer: post-facto reviews. We do regular reviews on large components, like the  that powers our  and the Go flyd that . But smaller projects like our private DNS server, and out-of-process changes like urgent bug fixes, can get merged unreviewed (by a subset of authorized developers). We run a Github bot that flags these PRs automatically and hold a weekly meeting where we review the PRs."
": A big chunk of the SOC2 DRL is about monitoring systems for problems. Your auditors will gently nudge you towards centralizing this monitoring, but you‚Äôll want to do that anyways, because every logging system you have is one you‚Äôll have to document, screenshot, and write policy about."
"We got off easy here, because logging is a feature of our platform; we run  and , fed from  and , and we‚Äôre generally a single ElasticSearch query away from any event happening anywhere in our infrastructure."
"One thing SOC2 did force us to do was pick a ticketing system, which is something we‚Äôd done our best to avoid for several years. We send alerts to Slack channels and PagerDuty, and then have documented processes for ticketing them."
"Another thing that surprised me was how much SOC2 mileage we got out of HelpScout. HelpScout is where our support mails (and  mails) go to, and while I‚Äôm not a HelpScout superfan, it is a perfectly cromulent system of record for a bunch of different kinds of events SOC2 cares about, like internal and external reports of security concerns."
": We barely use anything in AWS other than storage. We compete with AWS! We run our own hardware! But SOC2 audit firms have spent the last 10 years certifying  AWS-backed SAAS companies, and have added a whole bunch of AWS-specific line-items to their DRLs. We‚Äôre now much better at indexing and alerting on CloudTrail than we were before we did SOC2. It‚Äôs too bad that‚Äôs not more useful to our security practice."
": Your auditor will probably know what Terraform and CloudFormation are, and they will want you to be using it. Your job will be documenting how your own deployment system (the bring-up for new machines in your environment) is similar to Terraform. Sure, whatever."
"An annoyance I did not see coming from previous experience was host inventory. Inventory is trivial if you‚Äôre an AWS company, because AWS gives you an API and a CLI tool to dump it. We run our own hardware, and while we have several different systems of record for our fleet of machines, they‚Äôre idiosyncratic and don‚Äôt document well; we ended up taking screenshots of SQL queries, which wasn‚Äôt as smooth as just taking a screenshot of our  or Google SSO settings."
": Here‚Äôs a surprise: in the year of our lord 2022, doing endpoint security in your SOC2 has fallen out of fashion. We were all geared up to document our endpoint strategy, but it turned out we didn‚Äôt have to."
"I should have some snarky bit of ‚Äúinsight‚Äù to share about this, but I don‚Äôt, and mostly all I can tell you is that you can probably cross this off your checklist of big projects you‚Äôll need to get done simply to get a SOC2 certification. You should do the work anyways, on its own merits."
""
": I‚Äôd been mercifully insulated from this aspect of SOC2 in my former role as engineering support for SOC2‚Äôs, but had no such luck this time. I knew there was a lot of annoying company documentation involved in doing SOC2. I won‚Äôt put you to sleep with many of the details; if you‚Äôre the kind of company that should get a SOC2, the company and management stuff isn‚Äôt going to be an obstacle."
"We had three ‚Äúboring company stuff‚Äù surprises that stick out:"
"First, We needed a formal org chart posted where employees could find it. We‚Äôre not a ‚Äútitles and management‚Äù kind of company (we‚Äôre tiny), so this was a bother. But, whatever, now we have an org chart. Exciting!"
"Next, our auditors wanted to see evidence of annual performance reviews. We don‚Äôt do annual performance reviews (we‚Äôre a continuous feedback, routine scheduled 1-on-1 culture). But if you‚Äôre not doing annual performance reviews, the AICPA can‚Äôt give assurances that an employee who exfiltrated our production database to Pastebin would be terminated. So now we have pro-forma annual reviews."
"This kind of SOC2 thing falls under the category of ‚Äú so they don‚Äôt think you‚Äôve suddenly decided to start stack ranking everyone‚Äù."
"Finally, background checks."
"Background checks are performative and intrusive. Ask around for horror stories about how they flag candidates for not being able to source the right high school transcripts. Also, for us, they‚Äôre occasionally illegal: we have employees around the world, including several in European jurisdictions that won‚Äôt allow us to background check."
"This is the only issue we ended up having to seriously back-and-forth with our auditors about. We held the line on refusing to do background checks, and ultimately got out of it after tracking down another company our auditors had worked with, finding out what they did instead of background checks, stealing their process, and telling our auditors ‚Äúdo what you did for them‚Äù. This worked fine."
": You‚Äôre going to write a bunch of policies. It‚Äôs up to you how seriously you‚Äôre going to take this. I can tell you from firsthand experience that most companies phone this in and just Google , and adopt something from the first search engine result page."
"2019 Thomas would have done the same thing. But actually SOC2'ing a company I have a stake put me in a sort of CorpSec state of mind. You read a template incident response or data classification policy. You start thinking about why those policies exist. Then you think about would could go wrong if there was a major misunderstanding about those policies. Long story short, we wrote our own."
"This part of the process was drastically simplified by the work  has published, for free, on his ‚Äú‚Äù site. We have, for instance, an Information Security Policy. It‚Äôs all in our own words (and ours quotes ). But it‚Äôs based almost heading-for-heading on , which is brilliant."
"One thing about writing policies inspired by Ryan‚Äôs examples is that it liberates you to write things that make sense and read clearly and don‚Äôt contain the words ‚Äúwhereas‚Äù or ‚Äúdesignee‚Äù. Ryan hasn‚Äôt published a Data Classification policy. But our Data Classification policy was easy to write, in a single draft, just by using Ryan‚Äôs voice."
""
"We use  as our company wiki / intranet. It‚Äôs great. Slab surprised me midway through the audit with a feature for ‚Äúverifying‚Äù pages, which might be the highest ROI feature/effort ratio I‚Äôve come across: I click a button and Slab adds a green banner to a page saying that it‚Äôs ‚Äúverified‚Äù for the next several months. That‚Äôs it, that‚Äôs the feature. Several DRL line items are about ‚Äúrecertifying‚Äù policies annually, and this gave us the screenshots we needed for that. Well done, Slab! Betcha didn‚Äôt even realize you implemented policy recertification."
""
"Ordered from most to least surprising (that is, there was no way we were going to do the stuff at the bottom of the list)."
"Install endpoint software. ."
""
"If you talk to people who‚Äôve done SOC2 before, you‚Äôll hear a lot of joking about screenshots. They‚Äôre not joking."
"The whole SOC2 audit is essentially a series of screenshots. This is jarring to people who have had ‚Äúsecurity audits‚Äù done by consulting firms, in which teams of technical experts jump into your codebase and try to outguess your developers and uncover flaws in their reasoning. Nothing like that happens in a SOC2 audit, because a SOC2 audit is an actual audit."
"Instead, DRL line items are going to ask for evidence supporting claims you make, like ‚Äúour production repositories on Github have protected branches enabled so that random people can‚Äôt commit directly to ‚Äù . That evidence will almost always take the form of one or more screenshots of some management interface with some feature enabled."
"And that‚Äôs basically it? We divided the evidence collection stage of the audit up into a series of calls over the course of a week, each of which ate maybe twenty minutes of our time, most of which was us sharing a screen and saying ‚Äúthat checkbox over there, you should screenshot that‚Äù. I was keyed up for this before the calls started, prepared to be on my A-game for navigating tricky calls, and, nope, it was about as chill a process as you could imagine."
""
"This was a lot of words, but SOC2 gives a lot of people a lot of feels, and I‚Äôd wished someone had written something like this down before I started doing SOC2 stuff."
"The most important thing I can say about actually getting certified is to keep your goals modest. I‚Äôve confirmed this over and over again with friends at other companies: the claims you make in your Type I will bind on your Type II; claims you don‚Äôt make in your Type I won‚Äôt. It stands to reason then that one of your Type I goals should be helping your future self clear a Type II."
"I was a little concerned going into this that the quality of our SOC2 report (and our claims) would be an important factor for customers. And, maybe it will be. We got good auditors! I like them a lot! It wasn‚Äôt a paint-by-numbers exercise! But in talking to a couple dozen security people at other companies, my takeaway is that for the most part, having the SOC2 report is what matters, not so much what the SOC2 report says."
""
""
"We do a lot of security work that SOC2 doesn‚Äôt care about; in fact, SOC2 misses most of our security model. We build software in memory-safe languages, work to minimize trust between components, try to find simple access control models that are easy to reason about, and then get our code ."
"SOC2 doesn‚Äôt do a good job of communicating any of that stuff. And that‚Äôs fine; it doesn‚Äôt have to. We can write our own security report to explain what we do and how our security practice is structured, which is something I think more companies should do; I‚Äôd rather read one of those than a SOC2 report."
"And for all my cynicism, SOC2 dragged us into some process improvements that I‚Äôm glad we‚Äôve got nailed down. It helped to have clueful auditors, and a clear eye about what we were trying to accomplish with the process, if you get my drift."
"I expected ‚Äúentire new cloud provider‚Äù to be a complicated case for SOC2 audits. But the whole thing went pretty smoothly (and the un-smooth parts would have hit us no matter what we were building). If it was easy for us, it‚Äôll probably be easier for you. Just don‚Äôt do it until you have to."
""
""
""
"Fly.io isn‚Äôt a ‚ÄúGartner Magic Quadrant‚Äù kind of company. We use terms like ‚ÄúFaaS‚Äù and ‚ÄúPaaS‚Äù and ‚Äúserverless‚Äù, but mostly to dunk on them. It‚Äôs just not how we think about things. But the rest of the world absolutely does think this way, and I want to feel at home in that world."
"I think I understand what ‚Äúserverless‚Äù means, so much so that I‚Äôm going to stop putting quotes around the term. Serverless is a magic spell. Set a cauldron to boil. Throw in some servers, a bit of code, some , and a credit card. Now behold, a bright line appears through your application, dividing servers from services‚Ä¶and, look again, now the servers have disappeared. Wonderful! Servers are annoying, and services are just code, the same kind of code that runs when we push a button in VS Code. Who can deny it: ‚Äú‚Äù"
"But, see, I work on servers. I‚Äôm a fan of magic, but I always have a guess at what‚Äôs going on behind the curtain. Skulking beneath our serverless services are servers. The work they‚Äôre doing isn‚Äôt smoke and mirrors."
"Let‚Äôs peek behind the curtain. I‚Äôd like to perform the exercise of designing the most popular serverless platform on the Internet. We‚Äôll see how close I can get. Then I want to talk about what the implications of that design are."
"Close your eyes, tap your keyboard three times and think to yourself, ‚ÄúThere‚Äôs no place like ‚Äù."
""
"The year is 2014, and the buzzword ‚Äúelastic‚Äù is still on-trend. Our goal: liberate innocent app developers from the horrors of server management, abstracting services written in Python or Javascript from the unruly runtimes they depend on. You‚Äôll give us a function, and we‚Äôll run it."
"Once this is invented, you‚Äôll probably want to use it to optimize sandwich photos uploaded by users of your social sandwich side project."
""
"The first tool in our toolbox is the virtual machine. VMs were arguably ‚Äúserverless‚Äù , and Lambda itself literally stood on the shoulders of  EC2, so that‚Äôs where we‚Äôll begin."
"Take a big, bare-metal x86 server sitting in a datacenter with all the standard hookups. Like every server, it has an OS. But instead of running apps on that OS, install a Type 1 (bare-metal) hypervisor like the ."
"The hypervisor is itself like a tiny operating system, but it runs guest OSs the way a normal OS would run apps. Each guest runs in a facsimile of a real machine; when the guest OS tries to interact with hardware, the hypervisor traps the execution and does a close-up magic trick to maintain the illusion. It seems complicated, but in fact the hypervisor code can be made a good deal simpler than the OSs it runs."
"Now give that hypervisor an HTTP API. Let it start and stop guests, leasing out small slices of the bare metal to different customers. To the untrained eye, it looks a lot like EC2."
"Even back in 2014, EC2 was boring. What we want is Lambda: we want to run functions, not a guest OS. We need a few more components. Let‚Äôs introduce some additional characters:"
"The  service, with an API, that can start and stop VMs across a pool of ."
"The  reads an  request for a  we want to run. (Someone‚Äôs just uploaded an image to your S3 sandwich bucket through your app.)   asks a  to provide the network address of a Worker VM containing an instance of your , where it can forward the request. The  either quickly returns an existing idle , or if none are currently available, asks a  service to create a new one."
"This is all easier said than done. For instance, we don‚Äôt want to send multiple requests racing toward a single idle instance, and so we need to know when it‚Äôs safe to forward the next request. At the same time, we need  to be highly available; our  can‚Äôt just be a Postgres instance. Maybe we‚Äôll use  for strongly-consistent distributed consensus, or maybe  will be more resilient."
"We can straightforwardly run a  on a  VM. But we can‚Äôt just use any old VM; we can‚Äôt trust a shared kernel with multitenant workloads. So: give each customer its own collection of dedicated EC2-instance . Have  bin-pack  onto them. Boot up new  as needed."
"Another catch: it takes seconds or even minutes to boot a new . This means some of our requested functions have unacceptably (and unpredictably) high ‚Äúcold start‚Äù time. (Imagine, in 2022, holding on to your excitement for over a minute waiting for your image of the local sandwicherie‚Äôs scorpion-pepper grilled cheese to insert itself into your chat.) Have  manage a ‚Äúwarm pool‚Äù of running VMs, shared across all customers. Now functions can scale up quickly. To scale down,   periodically vacuums idle VMs, returning them to the warm pool for reuse."
"Scale is our friend. We have lots of customers, so the warm pool  smooths out unpredictable workloads, reducing the total number of EC2 instances we need. But we‚Äôre not out of the woods yet. We can get huge spikes of consumption: say, an accidentally-recursive function. One broken customer brings everyone else back to cold-start latency.  The easiest fix: soft limits (‚Äúcontact us if you need more than 100 concurrent executions‚Äù). Beyond that, the service could adopt a token bucket rate-limiting mechanism to allow a controlled amount of  per customer or function."
"We‚Äôve sketched most of orchestration, but hand-waved the actual function invocation. It‚Äôs not all that complicated, though."
"Once  allocates enough resources on a , it can load up the  there. Remember, it‚Äôs still 2014, and , so we‚Äôll roll our own container the old-fashioned way.  A daemon on the  VM:"
"handles the function initialization request,"
""
""
"We‚Äôve come up with a relatively naive design for Lambda. That‚Äôs OK! We‚Äôre Amazon and we can paper over the gaps with money and still have enough left over to make hats. More importantly, we‚Äôre out in front of customers, and we can start learning."
"Fast forward to 2018. We made it. ‚ÄúServerless‚Äù is the new ‚Äúelastic‚Äù and it‚Äôs all the rage. Now let‚Äôs make it fast."
"What‚Äôs killing us in our naive design is Xen. Xen is a bare-metal hypervisor designed to run arbitrary operating systems in arbitrary hardware configurations. But our customers don‚Äôt want that. They‚Äôre perfectly happy running arbitrary Linux applications on a specific, simplified Linux configuration."
"."
"Firecracker is modern hypervisor built on KVM and exploits paravirtualization: the guest and the hypervisor are aware of each other, and cooperate. Unlike Xen, we don‚Äôt emulate arbitrary devices, but rather  designed to be efficient to implement in software. With no wacky device support, we lose hundreds of milliseconds of boot-time probing. We can be up and running in under 125ms."
"Firecracker can fit thousands of micro-VMs on a single server, paying less than 5MB per instance in memory."
"This has profound implications. Before, we were carefully stage-managing how  made their way onto EC2 VMs, and the lifecycle of those EC2 VMs. But now,  can potentially just be VMs. It‚Äôs safe for us to mix up tenants on the same hardware."
"We can oversubscribe."
"Oversubscription is a way of selling the same hardware to many people at once. We just bet they won‚Äôt all actually ask to use it at the same time. And, at scale, this works surprisingly well. The trick: get really good at spreading around the load across machines to keep resource usage as uncorrelated as possible. We want to maximize server usage, but minimize contention."
"Firecracker lets us spread load more evenly, because we can run thousands of different customers on the same server."
"Our  are now bare-metal servers, not EC2 VMs. We need a warm pool of them, too. It‚Äôs a lot of extra micro-management. And it‚Äôs worth it. The resource-sharing shell game is way more profitable.  Reportedly, Lambda runs in production with CPU and memory oversubscription ratios as high as 10x. Not too shabby!"
"There‚Äôs a tradeoff to this. We‚Äôve aggressively decorrelated our server workloads, shuffling customers onto machines like suits in a deck of cards. But now we can‚Äôt share memory across functions, like the classic  model."
"On a single server, a function with  concurrent executions might consume only slightly more memory than a single function. Shuffled onto  machines, those executions cost  times more. Plus, on the single server, instances can fork instantly from a parent, effectively eliminating cold-start latency."
"And now we have a  in performance. Functions are related; they‚Äôre intrinsically correlated. Think about serverless databases, or map-reduce functions, or long chains of functions in a microservice ensemble. What we want is network locality, but we also want related loads spread across different hardware to minimize contention. Our goals are in tension."
"So some functions might perform best packed tightly to optimize performance, while others are best spread thin for more distributed resource usage across servers. Some kind of hinting along the lines of  could help thread the needle, but it‚Äôs still a hard problem."
"At any rate, we have a design, and it works. Now let‚Äôs start thinking about the ramifications of the decisions we‚Äôve made so far, and the decisions that we have yet to make."
""
""
"Lambda‚Äôs one-request-per-instance concurrency model is simple and flexible: each function instance can handle one single request at a time. More load, more instances."
"This works like  (CGI) of yore, or more precisely, like implementations of its successor  which reuse instances across requests."
"Scaling is simple and straightforward. Each request is handled in its own instance, separate from all other concurrent requests. No locks, thread-safety or any other parallel programming concepts."
"But handling concurrent requests in a single instance can be more efficient, especially for high-performance web application servers that can leverage asynchronous I/O event loops and user-space threads to minimize context-switching overheads. Google‚Äôs Cloud Run product supports . Lambda‚Äôs design makes it harder for us to pull off tricks like that."
""
"If we‚Äôre Lambda, we bill per-second duration based on memory use, with a per-request surcharge; like a taxi meter, we have a base fee, and then the meter ticks up as long as we‚Äôre working."
"Two ways of looking at the request fee. First, it‚Äôs a fudge factor representing the aggregate marginal costs of the various backends involved in handling the request."
"But if you‚Äôre an MBA, it‚Äôs also a way to shift to ‚Äú‚Äù or ¬†pricing, a¬†¬†of Lambda. Value pricing says that you pay based on how useful the service is; if we figure out ways to deliver the service more cheaply, that‚Äôs gravy for us. Without the surcharge, we‚Äôre doing . You‚Äôd just pay for the resources we allocated to you."
"(Remember, we‚Äôre up to 10x oversubscribed. Customers are, on average, utilizing only 10% of the resources they pay for.)"
"We combine CPU and memory pricing to simplify duration-based pricing. Simple is good, but costs our users flexibility if they have lopsided CPU or memory-heavy functions. For that problem, there‚Äôs Fargate, Lambda‚Äôs evil twin."
"This pricing seems simple! But it‚Äôs actually a little bit complicated, if you are sensitive to cost."
"Your image-cruncher function might be making good use of its resources for most of its running time. But what if a function process is actually really fast?  It might actually skew cheap in resources and expensive in requests."
"And now, you‚Äôve added a function to periodically scrape the major socials for new pictures tagged with any sandwich, artisanal sandwich stockist, or vending machine known to your database. Or, better, say you‚Äôre . Now you‚Äôre paying full whack for CPU and RAM usage the whole time you wait (up to 10s) for a response from each one, to, you know, see if it‚Äôs online."
"The value-based pricing here hits the sweet spot for functions that a) run long enough per request to amortize the request cost, and b) make enough use of the provisioned resources, while they run, to justify paying for them that long."
"Prioritizing nimble scaling, combined with instance-per-request and per-request billing, does set up a potential footgun for our customers. Don‚Äôt  ."
"We‚Äôre counting on the product as a whole to add enough value to keep less price-sensitive customers coming back, even far from the sweet spot."
""
"The public runtime API to a Lambda function is the  REST API, which accepts a POST method specifying the function name and request ‚Äúpayload‚Äù, and requires a signature with appropriate AWS credentials. This conforms to Amazon‚Äôs monolithic,  API structure, but practically unusable outside the API-wrangling comfort of the AWS SDK."
"A cottage industry has  around frameworks just to help you hook Lambda up to the web. Amazon built one of them into . Problem: too much YAML. Solution: more YAML."
"The way out is : the runtime API can just pass HTTP requests directly to the function instance. Most of what ‚ÄúAPI gateways‚Äù do can be built into HTTP proxy layers. For the common case of web applications, an HTTP-based API eliminates a layer of indirection and plugs in nicely with the mature ecosystem of web utilities."
""
"Lambda‚Äôs  sets strict limits:"
"on function initialization (10 seconds)"
"This tightly-scoped lifecycle is great for the platform provider. It helps workloads quickly migrate away from overloaded or unhealthy instances, and makes it easy to shuffle functions around during server maintenance and upgrades without impacting services. And what‚Äôs good for the platform is probably good for most customers, too!"
"But it‚Äôs not ideal for apps"
"with expensive or time-consuming initialization steps"
"One alternative is for the platform to try to keep servers up and running forever, but sometimes you just  to patch stuff. Another option to recycling VMs is live migration, sending a snapshot of the running VM over the network to the new server with as little downtime as possible. Google Compute Engine  for its instances and uses the feature to seamlessly conduct maintenance on its servers ."
""
""
"I just designed a shameless knockoff of Lambda, the most popular specimen of the most serverless of serverless services: a fleeting scrap of compute you can will into being, that scales freely (not in the monetary sense) and fades into oblivion when it‚Äôs no longer needed."
"This article contains no small degree of bias! There‚Äôs also no small degree of appreciation for the craft that goes on behind the curtain at AWS and other purveyors of ‚Äúserverless‚Äù services."
""
""
""
"We‚Äôve had a lot of changelogs about our Phoenix/LiveView-based  in recent weeks. It‚Äôs pretty rad; we‚Äôve been vocal about being CLI-first, but we love a first-class dashboard. Our dashboard has sprouted a lot of new capabilities, and at this point you‚Äôre missing out if you never use it!"
"That doesn‚Äôt change the power and adaptability of the CLI‚Äîwe‚Äôll never not love  (alias ).  Speaking of which: we have a few flyctl‚ú® entries in this here collection. Because flyctl is open-source, you can  and see what that means in terms of commits, any updates we may have missed, and, notably, lots of fun activity around ."
"And now the changelog:"
"We now have a YUL region (Montreal, QC, Canada) üöÄ"
"- **[Feature]** Made the [Plans](/plans) UI clearer and simpler to use. Quickly switch between orgs with a dropdown selector."
"a flyctl  that wiped fly.toml env variables when  (or ) flags were used. Wrong type checks were causing existing ones to be overwritten. This was a neglected, annoying bug that Michael fixed (probably with glee) with his feet still moving on the hiring treadmill."
""
""
""
"We have a . It was leaking memory. We fixed it, and we‚Äôll talk about that, but to be really thorough, we‚Äôll look at how loading a web page works. Starting with hardware interrupts."
""
""
"You type  in your browser address bar and hit enter. What happens next?"
"First off, are you even using a keyboard? Not everyone can use a keyboard: voice input may be a suitable alternative there. Soft keyboards like the ones that pop up on mobile devices when you focus an input also don‚Äôt count ‚Äî they‚Äôre software, like the name implies."
"As keys get pressed, electrical contact is made between two conductive bits, which closes a circuit, and the microcontroller inside the keyboard (it‚Äôs computers all the way down) takes note and stuffs it in a buffer."
"Back when you plugged in said keyboard, or, more likely, when your computer woke up and started enumerating USB devices, they entered a negotiation: the keyboard announced that it was HID class (for human interface device), and needed an ‚Äúinterrupt transfer‚Äù at a certain rate, and that‚Äôs the rate at which the computer will poll that device for‚Ä¶data."
"(What about Bluetooth, proprietary wireless dongles, or even laptop keyboards? Chances are, these all end up being USB anyway, as far as your computer is concerned. Yes, even for internal devices. It‚Äôs just easier that way)"
"And then well, your computer does poll the device at the negotiated rate, and processes events in-order. So really, there‚Äôs no hardware interrupts involved."
"(To be pedantic, because it‚Äôs that kind of article, your USB keyboard can actually interrupt the CPU, but that‚Äôs only so the BIOS can be driven by your keyboard. By the time a real operating system has been started up, that behavior has been overriden.)"
"Your operating system then does translation between scan codes (that depend on where the keys are located on the keyboard) and key codes, like ‚Äúthe letter A‚Äù. Then that goes through a bunch of event loops in the OS and your browser, and finally, we have  somewhere in RAM."
"So far so good."
"And then, well, browsers are complicated beasts. If your browser is Chrome, then it checks some probabilistic data structure for ‚Äîif the domain is on the Bad List, then you get a scary page that tells you to click away! Now!"
"After that, or maybe in parallel, a DNS lookup happens, which translates the domain  into an IPv4 and/or IPv6 address. This may happen over UDP, or it may happen ! Or maybe it doesn‚Äôt happen, because it‚Äôs in the browser‚Äôs DNS cache, or the OS‚Äôs DNS cache, or your local router‚Äôs DNS cache. It‚Äôs caches all the way down, really."
"If that succeeds, your browser tries to establish a TCP connection to that IP address. Because it‚Äôs an  IP address, packets get routed to an edge node nearby. For me that‚Äôs Paris, France. For my colleagues, it‚Äôs Toronto, Canada. Or South Africa, Brazil, the UK etc. It‚Äôs really ."
"(That‚Äôs assuming BGP routes are behaving that day. BGP is like DNS in that it‚Äôs always to blame somehow. It‚Äôs how different AS (autonomous systems), or peers inside the same AS, know where to send a packet next, so that it eventually reaches its destination."
"When it works, it sends packets on‚Ä¶maybe not the best path, but a decent path. When the routes are wrong, it can send packets halfway around the world. And when it gets hijacked, well, . Take notes, TV writers!)"
"It‚Äôs not like your browser crafts packets itself‚Äîthat would let it spoof IP addresses, which is generally frowned upon. No, it asks the underlying operating system to please establish a TCP connection, and that sends a SYN packet."
"(Technically it‚Äôs ‚Äúa TCP segment with the SYN flag set, wrapped in an IP datagram, wrapped in an Ethernet frame‚Äù, but that doesn‚Äôt exactly roll off the tongue)."
"That packet goes on quite a journey."
"It goes from userland to kernel space out a NIC, shooting through the air, or through copper, then almost definitely fiber, crossing the land, maybe speeding through the ocean deep if you live too far from us‚Äîfinally it enters a datacenter, a NIC, and the Linux kernel networking stack."
"Therein lies our first bit of Rust: an eBPF program, built with ."
"Because our edge nodes have to listen on entire ranges of IPv4 and IPv6 addresses, and also all ports at the same time, we have a small program, loaded in the kernel, that decides whether the connection you‚Äôre trying to establish is allowed or not."
"That‚Äôs all determined by the . In our fictional scenario, your browser is connecting to  on port 443, and that‚Äôs a-ok. The TCP handshake completes, our second bit of Rust is ready to take over."
"At first your connection sits in an accept queue, unless someone is flooding us with SYN packets, in which case there‚Äôs  involved, no, not that kind, and unfortunately not the tasty kind either."
"We try to process that accept queue as fast as the CPU will let us, asynchronously with , which really actually uses , which really ‚Äújust‚Äù uses a kernel interface, in this case, ."
"(In practice, this just means we can handle a lot of connections concurrently, with only a spoonful of OS-level threads. It‚Äôs all event-based and all the functions are state machines in a trenchcoat. It‚Äôs a whole thing.)"
"Because the Fly.io app has a TLS handler, your browser and  engage in a multi-stage dance to establish a secure tunnel. Through that dance, we are able to prove that you are visiting the  Fly.io by presenting a valid certificate for it, signed by third parties that your OS trusts, and your browser does too."
"Now that we‚Äôve negotiated a secure channel, we‚Äôre ready to move on to more substantial exchanges."
"Because you‚Äôre using a modern browser, it supports HTTP/2, and so do we, thanks to . That means the exchange is all binary, and I can‚Äôt show what it would look like without whipping out some sort of protocol analyzer like ."
"Any HTTP requests you send over that connection are handled by a  service created especially for you, and of course there‚Äôs a bunch of concurrency limits involved: some set in the app configuration, and some global, just so everything stays nice and fast for everyone."
"Because we occasionally need to look into how  operates, or how a certain request was handled, a lot of internals are instrumented with , which generates spans and log events that we funnel to a large store we can later query."
"(We‚Äôre able to turn up the verbosity for single requests, which is what we do when you report a problem and we‚Äôre trying to reproduce it! There‚Äôs no special ‚Äúdebug‚Äù build of , it‚Äôs all dynamically configured.)"
"So we get your request, and if there‚Äôs an instance of the app running on the same node, we‚Äôre able to serve it directly. And if not, we proxy it to a nearby node that  have a running instance: taking into account things like the round-trip time to that node, and how busy it is."
"Eventually, just as the request was, the response is proxied all the way back to your computer, your browser gets a bunch of HTML (maybe compressed, maybe not), and before it‚Äôs even done parsing it, it immediately fires up a half-dozen new requests, re-using the same connection."
"And then we leak a bunch of memory."
""
"Well, we used to!"
"It wasn‚Äôt, like, a lot. But it added up. That‚Äôs the thing with leaks: when request volume goes up, you expect resource utilization to go up, too. But when request volume goes down, and utilization doesn‚Äôt go down too, well‚Ä¶I mean that  an incentive to deploy often."
"And it‚Äôs surprising! Because in languages with manual memory management, you can  and forget to . You can , and forget to ."
"But in Go for example, you can‚Äôt! Because there‚Äôs a garbage collector, which periodically runs, looks at all the stuff, and frees the stuff no one remembers. It‚Äôs just like in Coco (2017), except less sad."
"Of course that‚Äôs a lie. Because it doesn‚Äôt look at all the things, it‚Äôs . And you can totally leak memory with a GC. All you need to do is stuff references to a bunch of big structs in a big map, and never take them out. That way they always remain reachable, are never collected, and memory usage goes weeeeeeeee."
"As for Rust, it‚Äôs RAII-ish, so when you hold a value, it‚Äôs fully initialized, and when it falls out of scope, the associated memory (and any other resources) gets freed. And if that‚Äôs not enough, you can do reference-counting via , or  if you need to share stuff across threads, and then you can have multiple things pointing to a single thing, which only gets freed when no things point to it any longer."
"That scheme has different performance characteristics than a GC: the cost is more ‚Äúspread out‚Äù (since stuff gets freed as soon as it‚Äôs no longer needed), there‚Äôs no pauses to worry about (even micro ones), people like it for real-time processing, high-performance network applications, and all sorts of other stuff."
"Except there too, same deal: if you  try, you can leak memory in Rust. Don‚Äôt believe us?"
"But we weren‚Äôt trying. And we didn‚Äôt really have an explanation we liked."
"And historically, things haven‚Äôt been so good on that front: there‚Äôs two problems you  didn‚Äôt want to have when you had a big Rust async application in production:"
"Something asynchronous is stuck somewhere"
"The first got a lot better with the advent of . You‚Äôre still not able to dump ‚Äúall async stack traces‚Äù the way Go lets you, for example. Instead you instrument some code: here we‚Äôre establishing a connection, here we‚Äôre sending HTTP headers, and your downstream crates do too (like hyper), and then you‚Äôre looking at something a litlte more semantic than a stack trace."
"But you also, still, can‚Äôt really dump it all. Something like  solves this and more, BUT it‚Äôs still early days, and not really something you can run in production today."
"As for the second (leaking resources), I remember struggling with it just a year ago. Because allocations and deallocations are very fast and it‚Äôs all very nice, but there‚Äôs absolutely no one keeping track of  or  anything was allocated."
"That wouldn‚Äôt be very zero-cost."
"And yet, sometimes RAII fails you. Sometimes you just keep stuffing items into a  or a  and never ever clean it up. The question is: where? And how are you going to find that out without exporting metrics for ?"
"Leak detectors have existed as long as we‚Äôve had leaks. The remarkable  tool suite comes with MemCheck, which has a  option. But it checks for a  of errors that simply can‚Äôt happen in safe Rust code, and makes your program run 20-30x slower, also using ‚Äúa lot more memory‚Äù."
"So, not an option for production web services."
"In fact, if you‚Äôre writing a production network service, chances are you‚Äôve switched away from the system memory allocator (glibc) to something like , which, on top of being (sometimes) faster, is also less prone to fragmentation, and comes with a wealth of tools to monitor memory usage."
"Including a heap profiler, which you can use to . It feels like Go‚Äôs , not a surprise since they‚Äôre both based on , which builds on the ideas in , in turn an extended version of the standard Unix prof tool."
"But at the end of the day, you‚Äôre either looking at extremely long text output that doesn‚Äôt really have any temporal information, or a gigantic file PDF that makes you wish you had a trackball mouse handy."
""
""
"is a memory profiler written in Rust, which works extremely well for Rust codebases (but, I‚Äôm assuming, C & C++ codebases too!). I had no hand in it ‚Äî I just think it‚Äôs extremely cool."
"For me, bytehound is the poster child for ‚ÄúNIH good? sometimes?‚Äù. Its custom stack unwinding implementation makes it orders of magnitude faster than competing tools. It‚Äôs designed to stream data to disk or over the network to some ‚Äúgatherer‚Äù process, which means its impact in production is minimal."
"(The non-NIH alternatives would be‚Ä¶something like , ‚Äôs memcheck tool, one of the ‚Äúchecking‚Äù malloc implementations like Dmalloc, or even swapping malloc with an actual GC like .)"
"It‚Äôs all runtime instrumentation, too ‚Äî I was able to inject it straight into  our production binary with : no recompilation needed here. And it supports !"
"In fact, of the whole hour I spent on this, 80% were spent fighting with  itself. Normally, it lets you inject just about any library into any executable, as long as the bitness matches up and all the dependencies are satisfied."
"But, in secure-execution mode:"
"is ignored (and so is )"
"So, long story short, moving  to a standard search path like  and invoking  on it did the trick."
"The last 20% was a breeze: by default, bytehound starts profiling immediately, writing to a  file on disk as it goes. I applied a touch of load with , another of my Rust favs, monitored memory usage in htop, it goes up, it goes up, it don‚Äôt go down, at least it‚Äôs easy to reproduce."
"I then restarted  (this is , never fear) opened the profile, and‚Ä¶no leaks."
"Well, none that matter:"
"Restarting  involves spinning up another instance, waiting until it‚Äôs ready to handle connections, then asking the previous instance to stop listening (then leaving it some time to handle established connections)."
"And the drop you can see right before 10:33:00 is when we stop listening: memory usage drops back to the ~40MB we use for internal state. According to bytehound, our inventory of nodes and services (and SQLite‚Äôs cache) are the only things we leak:"
"(Internal state on the left, SQLite mem cache on the right)"
"So RAII  working. And to be clear, I‚Äôm not really talking about the ‚Äúby the time you hold a value of a given type, the associated resource is fully initialized‚Äù part, I‚Äôm talking about the ‚Äúas soon as you let go of that value, associated resources get freed, too‚Äù part."
"For my second try, I did‚Ä¶exactly the same thing, except I stopped profiling by sending    restarting fly-proxy, so that bytehound would consider anything that hadn‚Äôt been freed  leaked."
"The ‚Äúonly leaked‚Äù flamegraph looks very different this time around:"
"Zooming in a little, we can see that almost all of it is allocated in :"
"But that‚Äôs not even the best view of it: the bytehound UI lets you filter/sort allocations any which way you like. For example, we can ask for ‚Äúonly leaked‚Äù, grouped by backtraces, sorted by largest leak first, with graphs:"
"And seeing this, there‚Äôs no question. And there‚Äôs no distractions like in the flamegraph: the internal state we leak (because of background tasks we don‚Äôt cancel properly before shutting down ‚Äî that one‚Äôs on me) looks very different:"
"That‚Äôs not the last of bytehound‚Äôs goodies: using just a little bit of :"
""
"We can plot exactly the graph we want to see‚Äîhere: does our  account for most of the leak?"
"Yes. Yes it does."
""
"Let me first say: the leak wasn‚Äôt in any code provided by  itself, or even any ."
"A long time ago, Fly.io‚Äôs traffic was low enough that we could afford to send  traces to Honeycomb."
"(Or at least we thought we could, until Honeycomb emailed saying ‚Äúhey, wtf!‚Äù. They have burst protection now; it was a different time.)"
"The tracing / OpenTelemetry ecosystem wasn‚Äôt as fleshed-out as . So we had to write custom code. And I say we, but I wasn‚Äôt there."
"When I started getting comfortable with ‚Äòs codebase, and after I was done making CI builds faster (switched linkers, split crates, adopted , set up incremental compilation caching, etc.), I noticed that custom  code, and wanted to remove it, but after all, it wasn‚Äôt even exporting traces any more, so what harm could it do?"
"The way  works is that you can instrument functions: this opens and enters a span when the function is called, exits that span when the function returns, and, if nothing else refers to that span, the span is closed, and eventually exported somewhere nice."
"It works almost the same way for  functions in Rust, except async functions are state machines that can be polled from any thread. So, the span is opened, and it‚Äôs entered+exited every time the async function is polled."
"(Wait, polling? Yes, but only when there‚Äôs work to be done: some socket is ready to be read from / written to, some timer has elapsed, some lock has been acquired, etc.)"
"Each span has a name, a target, and a bunch of fields, which a good tracing platform like  lets you use for filtering, sorting, heck, even monitoring. The duration of the span is tracked (from the time it‚Äôs opened to the time it‚Äôs closed), and when async functions are instrumented, we keep track of  too‚Äîhow much CPU time we spent on it, and ‚Äîhow long the task waited for something else to happen."
""
"Thing is, if you instrument your  function‚Ä¶well not that, but a similarly high-level function, like , that span opens, is entered and exited a bunch of times, but never closes until you stop listening."
"‚Ä¶sounds familiar?"
"And our custom, should-have-thrown-it-out-along-time-ago  had something along the lines of:  whenever a span was closed. Which means  was leaking a tiny bit of memory."
""
"When the proxy was restarted, that top-level task was ‚Äútripped‚Äù, exited, the associated span closed and freed, on some nodes, tens of gigabytes of memory ‚Äî letting most heap profilers think everything was just peachy."
"The PR to fix it was the most satisfying kind: sending old code into retirement."
"But did it fix the issue?"
"Absolutely. Memory usage barely went over 50MB during the load test."
"What‚Äôs that? ‚ÄúLeaked memory usage‚Äù keeps growing ever so slightly? Let‚Äôs focus on the part where it  stable:"
"Why yes, that line does go up, still."
"Showing leaked allocations, grouped by backtraces, with graphs, but this time only between two precise timestamps, we can see what‚Äôs happening. And it‚Äôs not hard to explain!"
"Take that one:"
"That‚Äôs a queue. Under load, backing storage is grown to accomodate more items being, well, queued. It‚Äôs never shrunk again, that would just be extra work. This is fine as long as it‚Äôs bounded in some way."
"Same deal here:"
"Because we keep track of latency for all requests, load generates a bunch of data points there ‚Äî we need to keep some data around to compute various percentiles, until an interval was elapsed and we send them out to Prometheus."
""
"you can leak memory, even in Rust. For even medium-sized long-running applications, lots of graphs from a good memory profiler can make life better. And they‚Äôll probably help you find the memory leak too."
""
""
""
"Here‚Äôs our latest changelog. This week we‚Äôre putting the in-browser UI updates a little closer to all the other ones, to see if they‚Äôll play nicely together."
"Our WireGuard peers sync a lot faster with the kernel‚Äôs wg state, by adding only peers that have changed. This should make userspace WireGuard features dramatically faster and eliminate API timeout issues some users were seeing‚Äîespecially significant for GitHub Actions and other CI processes that may create a new WireGuard peer every time."
""
""
""
"Here‚Äôs our latest changelog. Looking back over the week, our  has been quite a driver of (logged) change. When you‚Äôre done here,  to be a part of it!"
"Created an  to demonstrate how to expose multiple internal ports on separate public ports. (Related  with additional helpful info from charsleysa.)"
"Our  still needs its own section:"
"Livebook apps created with the Fly.io  can now be upgraded via a button in the app‚Äôs Image Details section. If the image is v0.6.0 or older, the Livebook interface itself will offer a link to our UI to update it:"
""
""
""
"Work leading up to the Fly Machines launch involved a multitude of changes by many of the cogs in this corporate machine, but that‚Äôs not to say the other production lines have been idle. For one thing, our web UI has been transforming before our eyes. We‚Äôve grouped its updates at the end, for easy digestion (and so we don‚Äôt have to type ‚Äúweb UI‚Äù so many times)."
"Here‚Äôs our latest changelog:"
"You can now specify  to have our proxy send a proxy protocol v2 header line when establishing connections to your app."
"Web UI improvements! We have a revamped  and , and more:"
"Shipped the new  with a redesign, new pages and more information for users."
""
""
""
""
"Fly Machines are VMs with a fast REST API that can boot instances in about 300ms."
"Our proxy can boot Fly Machines for you, and you can shut them down when they‚Äôre idle. Which means you can cost-effectively create VMs and keep them standing by to handle new requests."
""
"We built Machines for us. Our customers want their apps to scale to zero, mostly to save money. Also because it feels right. An app that isn‚Äôt doing anything shouldn‚Äôt be running. Fly Machines will help us ship apps that scale to zero sometime this year."
"Fly Machines may be useful to you, too. A lot of y'all want to build your own functions-as-a-service. ."
""
"We said we want our VMs to boot fast. They already do;  to boot a given executable on a given host. Our job is to get our own plumbing out of your way, and get you close to local-Firecracker speeds."
"Spinning up a VM as fast as possible  is an exercise in reducing infrastructure latency. We need to play latency whack-a-mole."
"When you ask for a VM, you wait for network packets to travel to an API somewhere. Then you wait for them to come back. The API is also, at minimum, talking to the host your job will run on. If all your users are in Virginia and your API is in Virginia and the hardware running Firecrackers is in Virginia, this might take 20-50ms."
"If your users are in Sydney and the hardware for the Firecrackers are in Sydney and the API is in Virginia, ‚Äúboot me a VM‚Äù takes more like 300ms. Three tenths of a second just waiting for light to move around is not fast."
"We‚Äôre not done. You need something to run, right? Firecracker needs a root filesystem. For this, we download Docker images from our , which is backed by S3. This can be done in a few seconds if you‚Äôre near S3 and the image is smol. It might take several minutes (minutes!) if you‚Äôre far away and the image is chonk."
"We solve this by making you create machines ahead of time. Accountants (not the TikTok kind; actual accountants) call this ‚Äúamortization‚Äù ‚Äì¬†pay the cost up front, yield the benefit over time."
""
"Here‚Äôs what happens when you call the :"
"If you‚Äôre an app developer in Los Angeles and you want a machine in S√£o Paulo, your request gets routed to your friendly local API server. We run API servers in every region, so this part of the process is fast."
"The API server makes a preflight request to our centralized database in Virginia, which gives back a yay (or nay!) and an immutable Docker image URL."
"Our database in Virginia has to be looped in on machine creation. We want a strongly-consistent record that machines exist. We also want to make sure you can‚Äôt create a machine if you‚Äôre 8 months behind on bills or got banned for mining cryptocurrency with a stolen credit card."
"The Los Angeles API instance then broadcasts a NATS message to the available hosts in S√£o Paulo saying ‚Äúhey, reserve me a machine with these specs‚Äù. Hosts with resources to spare reserve a slice of their capacity and reply with information about what they have to offer."
"The API server evaluates each host‚Äôs offer, picks one, and says ‚ÄúOK, host, create a machine for reservation X‚Äù. The API server then records a machine record in our centralized database. The other hosts garbage-collect the unused reservations a few seconds later."
"You might be thinking ‚Äúif I‚Äôm in Los Angeles and I request a machine in S√£o Paulo, won‚Äôt it take like a second for that whole dance to happen?‚Äù It would, yes."
"You might also be thinking ‚Äúpulling that image from a remote repository was probably soul-crushingly slow, right?‚Äù Also true! You don‚Äôt want to do that any more times than you need to."
"We made machines really cheap to create and keep stopped. In fact, right now, you pay for image storage; that‚Äôs it. What we want you do is: create machines ahead of time and start them when you need them."
""
"You should create machines just before you need them. Slightly earlier than just-in-time. All the stuff I just told you about is necessary to get to this point, but the protein is here: we designed Fly Machines for fast ."
"When you‚Äôre ready, you start a machine in S√£o Paulo with a request to the nearest API server. This time, though, there‚Äôs no need to wait on our database in Virginia. The central accounting is done and the API server knows exactly which host it needs to talk to. And the OCI image for the VM‚Äôs filesystem is ready to go."
"Here‚Äôs what the  does:"
"the start is fast. How fast?"
"When you run¬†, the API server knows that  is owned by a host in S√£o Paulo. It then sends a message directly to that host saying ‚Äú‚Äù. This message travels as fast as physics allows."
"The host receives the start message‚Ä¶and starts the machine. It already has the image stored locally, so it doesn‚Äôt need to wait on an image pull."
"If you‚Äôre in Los Angeles and start your machine in S√£o Paulo, the ‚Äústart‚Äù message gets where it needs to go in ~150ms. But if you‚Äôre in Los Angeles and start a machine in Los Angeles, the ‚Äústart‚Äù message might arrive in ~10ms."
"The lesson here is ‚Äústart machines close to your users‚Äù; the operation is very fast. Here‚Äôs something cool about this, though:  don‚Äôt necessarily start the machine from where you are; an  can do it for you. In fact, this is kind of the point. Your application logic should be close to your users‚Äô machines."
"Or, you can forego the app and let  boot machines when HTTP requests arrive. It can do all this for you."
"I should clarify: our infrastructure is fast to run start operations. Your application boot time is something you should optimize. We can‚Äôt help with that (yet!)"
""
"Stop commands are fast too. You may not want to issue stop commands, though. If your machine should stop when it‚Äôs idle, there‚Äôs a better way."
"Fly.io users have been requesting ‚Äúscale to zero‚Äù since January 1st, 1970 at 00:00:00 UTC. Scaling up is pretty easy; it‚Äôs usually safe to boot a new VM and add it to a load balancer. Scaling down is harder‚Äîstop a VM at the wrong time and shit breaks."
"So here‚Äôs how we modeled this: when you use Fly.io machines to run apps that need to scale down, make your process exit when it‚Äôs idle. That‚Äôs it. You‚Äôve exited the container, effectively stopping the machine, but it‚Äôs intact to pick up a future start request from a clean slate."
"This works because your in-machine process has a strongly-consistent view of local activity and can confidently detect ‚Äúidle‚Äù."
""
""
"One thing you may have noticed about our design: machines are pinned to specific hardware in our datacenters. This is a tradeoff that buys simplicity at the risk of your patience."
"Pinning machines to specific hardware means that if the PSU on that host goes pop, your machine won‚Äôt work (kind of; we run redundant PSUs). Capacity issues will create more surprising failures. If you create a biggish 64GB RAM machine and leave it stopped, we might be out of capacity on that specific host when you attempt to start it back up."
"We will mostly shield you from capacity issues, but you should  be prepared for the eventuality that your first-choice hardware is indisposed. Which really just means: plan to have two machines for redundancy."
"The good news is that our API is pretty fast. Creating a machine is relatively slow, but you can do it in a pinch. If a machine fails to start, you can usually get another one running in a few seconds."
"The best way to use machines is to think of a list of operations in priority order. If you‚Äôre trying to run some user code, come up with a list like this:"
"Start machine X in Chicago. If that fails,"
"This cycle will account for all the predictable failures and should get you a machine any time you want one."
""
"Running machines costs the same as . The same goes for bandwidth, RAM, and persistent disks."
"Stopped machines, though, are something we could use your feedback on. There‚Äôs a cost to keeping these things around. Right now, we just charge you for storage when a machine isn‚Äôt running. Like $0.15/mo for a 1GB Docker image."
"Questions? Comments? Pricing ideas? Vitriol? Comment ."
""
""
""
"Provisioned new servers in , , and  which were very full. Added capacity should mean customers should no longer get provisioning issues when trying to deploy to these regions."
""
""
""
"The conventional wisdom of full-stack applications is the n-tier architecture, which is now so common that it‚Äôs easy to forget it even has a name. It‚Äôs what you‚Äôre doing when you run an ‚Äúapplication server‚Äù like Rails, Django, or Remix alongside a ‚Äúdatabase server‚Äù like Postgres. According to the conventional wisdom, SQLite has a place in this architecture: as a place to run unit tests."
"The conventional wisdom could use some updating. I think that for many applications ‚Äì¬†production applications, with large numbers of users and high availability requirements ‚Äì¬†SQLite has a better place, in the center of the stack, as the core of your data and persistence layer."
"It‚Äôs a big claim. It may not hold for your application. But you should consider it, and I‚Äôm here to tell you why."
""
"50 years is not a long time. In that time, we‚Äôve seen a staggering amount of change in how our software manages data."
"In the beginning of our story, back in the ‚Äò70s, there were  defining what we now call ‚Äú‚Äù, also known today as ‚Äúdatabases‚Äù. You know them, even if you don‚Äôt: all data lives in tables; tables have columns, and rows are addressable with keys; C.R.U.D.; schemas; a textual language to convey these concepts. The language, of course, is SQL, which prompted a Cambrian explosion of SQL databases, from Oracle to DB2 to Postgres to MySQL, throughout the '80s and '90s."
"It hasn‚Äôt all been good. The 2000s got us XML databases. But our industry atoned  by building some  during the same time. By the 2010s, we saw dozens of large-scale, open-source distributed database projects come to market.  Now anyone can spin up a cluster and query terabytes of data."
"As databases evolved, so too did the strategies we use to plug them in to our applications. Almost since Codd, we‚Äôve divided those apps into tiers. First came the database tier. Later, with  and , we got the caching tier. We‚Äôve got  and we‚Äôve got  and distribution tiers. The tutorials pretend that there are 3 tiers, but we all know it‚Äôs called ‚Äún-tier‚Äù because nobody can predict how many tiers we‚Äôre going to end up with."
"You know where we‚Äôre going with this. Our scientists were so preoccupied with whether or not they could, and so on."
"See, over these same five decades, we‚Äôve also seen CPUs, memory, & disks become hundreds of times faster and cheaper. A term that practically defines database innovation in the 2010s is ‚Äúbig data‚Äù. But hardware improvements have made that concept slippery in the 2020s. Managing a 1 GB database in 1996? A big deal. In 2022? Run it on your laptop, or a t3.micro."
"When we think about new database architectures, we‚Äôre hypnotized by scaling limits. If it can‚Äôt handle petabytes, or at least terabytes, it‚Äôs not in the conversation. But most applications will never see a terabyte of data, even if they‚Äôre successful. We‚Äôre using jackhammers to drive finish nails."
""
"There‚Äôs a database that bucks a lot of these trends. It‚Äôs one of the most popular SQL databases in the world, so standardized it‚Äôs an , it‚Äôs renowned for its reliability and its , and its performance is so good that citing its metrics on a message board invariably starts an argument about whether it should be disqualified. I probably don‚Äôt have to name it for you, but, for the one person in the back with their hand raised, I‚Äôm talking about ."
"SQLite is an embedded database. It doesn‚Äôt live in a conventional architectural tier; it‚Äôs just a library, linked into your application server‚Äôs process. It‚Äôs the standard bearer of the ‚Äú‚Äù: the server that runs on its own, without relying on nine other sidecar servers to function."
"I got interested in these kinds of applications because I build databases. I wrote , which is a popular embedded K/V store in the Go ecosystem. BoltDB is reliable and, as you‚Äôd expect from an in-process database, it performs like a nitro-burning funny car. But BoltDB has limitations: its schema is defined in Go code, and so it‚Äôs hard to migrate databases. You have to build your own tooling for it; there isn‚Äôt even a REPL."
"If you‚Äôre careful, using this kind of database can get you a lot of performance. But for general-purpose use, you don‚Äôt want to run your database off the open headers like a funny car. I thought about the kind of work I‚Äôd have to do to make BoltDB viable for more applications, and the conclusion I quickly reached was: that‚Äôs what SQLite is for."
"SQLite, as you are no doubt already typing into the message board comment, is not without its own limitations. The biggest of them is that a single-process application has a single point of failure: if you lose the server, you‚Äôve lost the database. That‚Äôs not a flaw in SQLite; it‚Äôs just inherent to the design."
""
"There are two big reasons everyone doesn‚Äôt default to SQLite. The first is resilience to storage failures, and the second is concurrency at scale. Litestream has something to say about both concerns."
"How Litestream works is that it takes control of SQLite‚Äôs . In WAL mode, write operations append to a log file stored alongside SQLite‚Äôs main database file. Readers check both the WAL file and the main database to satisfy queries. Normally, SQLite automatically checkpoints pages from the WAL back to the main database. Litestream steps in the middle of this: we open an indefinite read transaction that prevents automatic checkpoints. We then capture WAL updates ourselves, replicate them, and trigger the checkpointing ourselves."
""
"It sounds complicated, but it‚Äôs incredibly simple in practice, and  you‚Äôll see that it ‚Äújust works‚Äù. You run the Litestream binary on the server your database lives on in ‚Äúreplicate‚Äù mode:"
""
"And then you can ‚Äúrestore‚Äù it to another location:"
""
"Now commit a change to your database; if you restore again then you‚Äôll see the change on your new copy."
""
"The ordinary way people use Litestream today is to replicate their SQLite database to S3 (it‚Äôs remarkably cheap for most SQLite databases to live-replicate to S3). That, by itself, is a huge operational win: your database is as resilient as you ask it to be, and easily moved, migrated, or mucked with."
"But you can do more than that with Litestream. The upcoming release of Litestream will let you live-replicate SQLite directly between databases, which means you can set up a write-leader database with distributed read replicas. Read replicas can ; most applications are read-heavy, and this setup gives those applications a globally scalable database."
""
""
"One of my first jobs in tech in the early 2000s was as an Oracle Database Administrator (DBA) for an Oracle9i database. I remember spending hours poring over books and documentation to learn the ins  and  outs of the Oracle database. And there were a lot. The  was almost a thousand pages‚Äîand that was just one of over ."
"Learning what knobs to turn to optimize queries or to improve writes could make a big difference back then. We had disk drives that could only read tens of megabytes per second so utilizing a better index could change a 5-minute query into a 30 second query."
"But database optimization has become less important for typical applications. If you have a 1 GB database, an NVMe disk can slurp the whole thing into memory in under a second. As much as I love tuning SQL queries, it‚Äôs becoming a dying art for most application developers. Even poorly tuned queries can execute in under a second for ordinary databases."
"Modern Postgres is a miracle. I‚Äôve learned a ton by reading its code over the years. It includes a slew of features like a genetic query optimizer, row-level security policies, and a half dozen different types of indexes. If you need those features, you need them. But most of you probably don‚Äôt."
"And if you don‚Äôt need the Postgres features, they‚Äôre a liability. For example, even if you don‚Äôt use multiple user accounts, you‚Äôll still need to configure and debug host-based authentication. You have to firewall off your Postgres server. And more features mean more documentation, which makes it difficult to understand the software you‚Äôre running. The documentation for Postgres 14 is nearly ."
"SQLite has a subset of the Postgres feature set. But that subset is 99.9% of what I typically need. Great SQL support, , , , . And when it lacks a feature, the data is already next to my application. So there‚Äôs little overhead to pull it in and process it in my code."
"Meanwhile, the complicated problems I really need to solve aren‚Äôt really addressed by core database functions. Instead, I want to optimize for just two things: latency & developer experience."
"So one reason to take SQLite seriously is that it‚Äôs operationally much simpler. You spend your time writing application code, not designing intricate database tiers. But then there‚Äôs the other problem."
""
"We‚Äôre beginning to hit theoretical limits. In a vacuum, light travels about 186 miles in 1 millisecond. That‚Äôs the distance from Philadelphia to New York City and back. Add in layers of network switches, firewalls, and application protocols and the latency increases further."
"The per-query latency overhead for a Postgres query within a single AWS region can be up to a millisecond. That‚Äôs not Postgres being slow‚Äîit‚Äôs you hitting the limits of how fast data can travel. Now, handle an HTTP request in a modern application. A dozen database queries and you‚Äôve burned over 10ms before business logic or rendering."
"There‚Äôs a magic number for application latency: . Snappy applications make happy users. 100ms seems like a lot, but it‚Äôs easy to carelessly chew it up. The 100ms threshold is so important that people   just to reduce latency."
"We‚Äôd rather just move our data close to our application.  How much closer? Really close."
"SQLite isn‚Äôt just on the same machine as your application, but actually built into your application process. When you put your data right next to your application, you can see per-query latency drop to 10-20 microseconds. That‚Äôs micro, with a Œº. A 50-100x improvement over an intra-region Postgres query."
"But wait, there‚Äôs more. We‚Äôve effectively eliminated per-query latency. Our application is fast, but it‚Äôs also simpler. We can break up larger queries into many smaller, more manageable queries, and spend the time we‚Äôve been using to hunt down corner-casey N+1 patterns building new features."
"Minimizing latency isn‚Äôt just for production either. Running integration tests with a traditional client/server database easily grows to take minutes locally and the pain continues once you push to CI. Reducing the feedback loop from code change to test completion doesn‚Äôt just save time but also preserves our focus while developing. A one-line change to SQLite will let you run it in-memory so you can run integration tests in seconds or less."
""
"Litestream is distributed and replicated and, most importantly, still easy to get your head around. Seriously, . There‚Äôs just not much to know."
"My claim is this: by building reliable, easy-to-use replication for SQLite, we make it attractive for all kinds of full-stack applications to run entirely on SQLite. It was reasonable to overlook this option 170 years ago, when  was first written. But SQLite today can keep up with the write load of most applications, and replicas can scale reads out to as many instances as you choose to load-balance across."
"Litestream has limitations. I built it for single-node applications, so it won‚Äôt work well on ephemeral, serverless platforms or when using rolling deployments. It needs to restore all changes sequentially which can make database restores take minutes to complete. We‚Äôre , but the separate-process model restricts us to course-grained control over replication guarantees."
"We can do better. For the past year, what I‚Äôve been doing is nailing down the core of Litestream and keeping a focus on correctness. I‚Äôm happy with where we‚Äôve landed. It started as a simple, streaming back up tool but it‚Äôs slowly evolving into a reliable, distributed database. Now it‚Äôs time to make it faster and more seamless, which is my whole job at Fly.io. There are improvements coming to Litestream ‚Äî improvements that aren‚Äôt at all tied to Fly.io! ‚Äî that I‚Äôm psyched to share."
"Litestream has a new home at Fly.io, but it is and always will be an open-source project. My plan for the next several years is to keep making it more useful, no matter where your application runs, and see just how far we can take the SQLite model of how databases can work."
""
""
""
"Features and fixes are flying like dodgeballs in a school gym, and the Fly.io Changelog Enforcer could probably have done a better job patrolling‚Äîbut let‚Äôs have a look at our haul of updates since our ."
"There‚Äôs a fair amount of protein in this week‚Äôs mix. Let‚Äôs kick it off with improved remote builders you can activate for your organization!"
"We updated remote builders for faster first deployments and fewer full disks. Builders will now:

This behavior is the default for new builders. Existing builders must be destroyed with  to get the new behavior."
""
""
""
""
"Hey, everyone.  we talked a bit about what accessibility is, why it‚Äôs important, and how you can incorporate it into your process. Today, using the time-travel superpowers of Git, I‚Äôll take you along as I start making LiveBeats more accessible for screen reader users."
"is a reference Phoenix LiveView app with real-time social features. We‚Äôd be reckless not to make sure all the parts are in good working order before real-time updates start moving them around on us. Let‚Äôs set our time machines to ‚Äîor mid-November. Thanksgiving is on the horizon, winter is coming, and I‚Äôm starting to dig into this little app called LiveBeats ‚Ä¶"
""
"Sometimes, setting out to make an app accessible feels like surveying fog-shrouded terrain. Is that supposed to be a button? What‚Äôs all that clutter over there? Fortunately, we can clear away a lot of the murk with some easy early wins."
"Labels are a great way to give some definition to the landscape. You‚Äôve got a few tools to help with this, each of which has its own use cases:"
"The faithful  attribute is essential for images that have meaning, whether they‚Äôre beautiful photos or actionable controls."
"So, back to . We use  here to add accessible labels to controls; for example, this button that skips to the previous track in the playlist:"
""
""
"Ideally, you‚Äôd just add text as a child of the button, particularly since users with cognitive disabilities may struggle with what a given icon means. If you‚Äôre using an image for your button, add an  attribute. Where neither is the case,  is the ticket."
"Labeling meaningful elements is only part of the story, however.  irrelevant images can be just as important. If my screen reader presents a thing, then it should be relevant to me. Decorations and placeholders usually aren‚Äôt, and should be hidden, either by applying  to the element, or by adding a blank  attribute to images."
"You can see an example of hiding icons in :"
""
"Hiding a decorative icon saves my screen reader from reading what appears to be an empty element. It‚Äôs a small thing, but half a dozen small things add up."
""
"We‚Äôve labeled some things and hidden others. The fog is burning away, and we have a slightly clearer view of the land around us. It‚Äôs now time to fill in the details."
"Roles are powerful tools that make one thing appear to be another. Say you have a  tag that needs to work as a button. You can make it  like a button like so:"
""
"Unfortunately, the above is the equivalent of slapping on a fake mustache and glasses. To my screen reader, it now  like a button. But the role alone doesn‚Äôt make it  like a button; it doesn‚Äôt focus when I tab, and doesn‚Äôt click when I press  or ."
"It‚Äôs better to use a  and get this button behavior built in. But if you can‚Äôt, or if you‚Äôre building a widget like a dropdown menu or , roles are crucial."
"Roles are great for signposting semantic regions on pages. Here are the most important:"
": Use this, or a  element, for application menus."
"All of the above roles have semantic HTML equivalents. This isn‚Äôt universally true‚Äîthere isn‚Äôt a semantic HTML equivalent of a tree control, for instance‚Äîbut you should prefer HTML where possible."
"There‚Äôs a lot to unpack there. But as an example,  combines some of what we‚Äôve discussed to achieve more intuitive navigation within LiveBeats."
"We use the  element to surround the page content that changes when new routes are visited. Using  would serve the same purpose, though less elegantly."
"Then, we use another technique to associate names with areas of the page:"
""
"This last snippet does a couple of things. Adding a new region landmark to the page with  gives us easier navigation into and out of it, via hotkey. In , I can jump between this and other interesting regions of the page by pressing .  Then, the  attribute ties the label ‚ÄúPlayer‚Äù with that region, such that navigating into or out of the player explicitly announces the focus entering or leaving the player."
"If you find yourself writing documentation with phrases like ‚ÄúIn the player, click ‚Äù or ‚ÄúFind this in the messages section of the dashboard,‚Äù named regions help make those instructions more relevant to screen reader users. Styling may make the player region visually obvious, but the  role and ‚ÄúPlayer‚Äù label makes it very apparent when the caret enters the audio player."
"Roles are powerful in large part because they‚Äôre promises. If you promise your user that a thing is a button, then it needs a  for keyboard focus, as well as handlers to activate it when  or  is pressed. If you‚Äôre curious about what these promises are, the  document is an exhaustive source of all commonly expected keyboard behaviors for a bunch of widget types. Want to know how a list box should behave when arrowing down past the last element? This resource has you covered."
"That said, it is very possible to overuse roles in your application. Here are two examples of role misuse I often find in the wild."
""
"is not intended for every list of links in your app that might possibly be a menu if you tilt your head and the sunlight lands just so. These are either application menus like you‚Äôd find in a menu bar, or standalone dropdown menus that capture keyboard focus and expand when you click on them. Misusing  won‚Äôt necessarily make a given control unusable, but it does cause confusion by presenting an element as something it isn‚Äôt."
""
""
"This one gets its own section because it‚Äôs  bad. If you want your app to be so inaccessible that most screen reader users turn away in the first few seconds, slap  on one of the top-level elements. Explaining just why this is takes a bit of effort, so please bear with me."
"Broadly speaking, screen reader users browse the web in one of two modes. Caret browsing mode presents pages as if they‚Äôre documents. We can arrow through their contents line by line or character by character, select and copy text, etc. You can experience a limited version of this by pressing  in most browsers, though screen readers enable this mode by default. They also add conveniences like jumping between headings with , buttons with , landmarks with , etc."
"Focus mode, sometimes called ‚Äúforms mode,‚Äù because it enables automatically when form fields are highlighted, passes keys directly through to the application. This is generally what you want when typing into forms, or when using keyboard commands that you don‚Äôt want filtered out by caret browsing. Incidentally, focus mode is closest to how native applications behave; you don‚Äôt normally read application screens as if they were documents, or jump between controls by element type."
"That, more or less, is what  enforces. It enables focus mode by default, meaning your screen reader users can‚Äôt explore via caret browsing and its associated commands. It also changes the way the site presents itself to screen reader users, such that it appears to be a native app, and not a web document with a built-in interaction model. It‚Äôs a promise that you‚Äôll supply it all; you‚Äôve gone through the extraordinary effort to ensure all your controls are focusable, they all have sensible keyboard behaviors, and that your users won‚Äôt be struggling to read text that changes."
"You might feel you have to use  just because, well, you‚Äôre making an application. But this is often not the right choice. If you‚Äôve ever been annoyed by an Electron app‚Äôs non-native behavior, multiply that by about 11 and you‚Äôre in the ballpark of how frustrating  can be when it‚Äôs not backed up by thorough and consistent handling of every interaction. While I‚Äôve got this podium: Slack, you‚Äôre one of the biggest perpetrators of this, and need to cut it out. Most of my usability issues with Slack spring from its use of  everywhere, with haphazard and nonstandard workarounds in place to patch in what HTML provides for free."
""
"While this post has been light on the real-time aspects of LiveBeats, harvesting this low-hanging fruit is an important step to making any web app accessible. We certainly don‚Äôt want it in the way next time, when we‚Äôll start going live, exploring the challenges and methods to accessibly presenting changes as they roll in over the wire. Meanwhile, if you have questions or topics you‚Äôd like covered, drop a line  and I‚Äôll try to work them in. Thanks for reading!"
""